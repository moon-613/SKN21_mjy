{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/30(화) 14:20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 개요\n",
    "> **Agent: 대형 언어 모델을 두뇌로 사용해, 목표를 스스로 이해하고 외부 도구와 상호작용하며 실제 작업을 자율적으로 수행하는 지능형 인공지능 시스템.**\n",
    "\n",
    "- Agent: **대형 언어 모델(LLM, Large Language Model)과 다양한 도구(Tool)를 결합해, 사용자의 복잡한 요청을 스스로 분석하고 처리하도록 설계된 지능형 인공지능 시스템.**\n",
    "기존의 단순한 챗봇이 “질문 → 답변” 구조로 동작한다면, \n",
    "  - Agent는 **목표 설정 → 판단 → 실행 → 결과 반영**의 전 과정을 스스로 수행하는 구조를 가진다.\n",
    "\n",
    "- Agent는 주어진 목표를 달성하기 위해 자율적으로 **외부 환경(도구, API, 데이터베이스, 파일 시스템 등)과 상호작용하며 의사 결정을 내리고 실제 행동을 수행.**\n",
    "이때 Agent의 **핵심적인 의사 결정과 추론 과정은 대형 언어 모델(LLM)이 담당**하며, **사람의 개입은 최소화**한다.\n",
    "\n",
    "- 즉, Agent는 단순히 정보를 말해주는 존재가 아니라, **\"문제를 이해하고, 해결 방법을 계획하고, 직접 실행까지 담당하는 인공지능 작업 수행자\".**\n",
    "\n",
    "- AI 시스템을 구현할 때, **워크플로우**(**Workflow**)는 사전에 정의된 절차에 따라 실행 단계가 고정적인 구현 방식이라면, **에이전트**(**Agent**)는 주어진 목표를 달성하기 위해 스스로 계획을 수립하고, 상황을 판단하여 행동을 결정·실행하는 자율적인 방식.\n",
    "\n",
    "\n",
    "\n",
    "## Agent의 주요 특징\n",
    "\n",
    "1. **자율성** (Autonomy)\n",
    "   - Agent는 **사전 정의된 규칙**(Rule-based)에 의존하지 않고, LLM을 통해 현재 상황을 인지하고 추론하여 스스로 결정을 내리고 다음 행동을 계획할 수 있다.\n",
    "   - 즉, 사용자가 일일이 수행 단계를 지시하지 않아도, Agent는 **현재 상황을 해석하고 다음 행동을 동적으로 결정.**\n",
    "\n",
    "2. **목표 지향성** (Goal-Oriented)\n",
    "    - Agent는 단순히 질문에 답변하는 **단순한 대화 상대가 아니라, 특정 목표와 복잡한 작업을 달성하기 위해 설계된 시스템**으로 최종 목표에 도달할 때 까지 반복적으로 행동.\n",
    "    - Agent는 어떤 처리를 할 때 항상 **\"이 행동이 목표 달성에 도움이 되는가\"를 기준**으로 판단.\n",
    "\n",
    "3. **도구 활용** (Tool Utilization)\n",
    "    - Agent는 대형 언어 모델의 언어 이해 능력, 사전 학습 정보에만 의존하지 않고, 다양한 **외부 도구와 API를 함께 활용하여 실제 작업을 수행**.\n",
    "    - 이를 통해 LLM이 처리할 수없는 **최신 정보 검색, 복잡한 계산, 외부 시스템 제어**등과 같은 작업이 가능. 이를 통해 Agent는 **\"말만 하는 AI\"가 아니라 \"실제로 일을 처리하는 AI\"로 기능.**\n",
    "\n",
    "4. **인간 개입 최소화** (Human-in-the-loop 최소화)\n",
    "    - Agent는 **문제 분석, 의사 결정, 행동 실행의 대부분을 스스로 결정하고 수행하도록 설계.**\n",
    "    - 사람은 **초기 목표 제시, 결과 확인 및 실행 최종 승인** 정도에 만 개입."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다양한 Agent 활용 사례\n",
    "\n",
    "- **미국 국세청(IRS) 세무처리에 도입된 AI 에이전트**\n",
    "    - 미국 국세청(IRS)은 Salesforce Agentforce 기반 AI 에이전트를 도입해 세무 업무에서의 보조·분석 기능을 강화하고 업무 효율을 높이고 있다.\n",
    "\n",
    "-  **고객 추천 및 개인화된 콘텐츠 제공**\n",
    "    - Netflix, Amazon 같은 OTT 플랫폼은 사용자의 취향 변화에 따라 추천 시스템을 적응시키는 학습형 에이전트를 활용해 콘텐츠/제품 추천을 개선해 나간다.\n",
    "\n",
    "- **영업 지원용 AI 에이전트**\n",
    "    - Oracle은 영업 전문가를 위한 AI 에이전트를 도입해 고객 미팅 후 CRM 업데이트, 고객 데이터 분석·보고서 생성 같은 반복 작업을 자동화하고 있다.\n",
    "\n",
    "- **물류 최적화 및 배송 계획**\n",
    "    - Uber Freight, J.B. Hunt 등에서는 AI 에이전트를 활용해 실시간 교통·날씨 데이터 분석을 통해 가장 효율적인 배송 경로를 계산한다.\n",
    "\n",
    "- **AWS의 클라우드 자동화 에이전트**\n",
    "    - Amazon Web Services는 보안, DevOps, 일반 작업을 자동화하는 AI 에이전트들을 출시하며 클라우드 인프라 운영과 보안 모니터링을 강화하고 있다.\n",
    "\n",
    "- **삼성SDS AI 에이전트 플랫폼**\n",
    "    - 삼성SDS는 **사용자 개입 없이 스스로 판단·문제 해결이 가능한 AI 에이전트 플랫폼 ‘패브릭스(Fabrics)’**를 공개. 이를 통해 기업 내부에서 자동화된 의사결정과 작업 실행을 지원."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct 패턴\n",
    "- Agent 구현의 바탕이 되는 이론.\n",
    "\n",
    "## 1. 개요\n",
    "\n",
    "ReAct: **Reasoning**(추론)과 **Acting**(행동)을 결합한 AI Agent의 프롬프팅 패턴이다. 대형 언어 모델(LLM)이 단순히 답변을 생성하는 것이 아니라, 문제를 분석하고(Reasoning)하고 그에 따라 필요한 도구를 선택하여 실행하며(Acting), 결과를 관찰하고(Observation) 다음 추론에 반영하는 과정을 반복하면서 문제를 해결하는  Agent 설계 방식.\n",
    "\n",
    "### ReAct의 핵심 개념\n",
    "\n",
    "전통적인 프롬프팅 방식은 질문에 대해 즉시 답변을 생성한다. 하지만 **ReAct 패턴**은 다음과 같은 순환 구조를 따른다:\n",
    "\n",
    "```\n",
    "질문 → 생각(Thought) → 행동(Action) → 관찰(Observation) → 생각 → 행동 →  관찰 → ... → 답변\n",
    "```\n",
    "\n",
    "- 예)\n",
    "  - 질문: \"현재 서울의 날씨와 미세먼지 농도를 알려줘\":\n",
    "\n",
    "    - **Thought(생각)**: 날씨 정보를 얻기 위해 날씨 API를 호출해야겠다\n",
    "    - **Action(행동)**: WeatherAPI.get_weather(\"서울\")\n",
    "    - **Observation(관찰)**: 기온 15도, 맑음\n",
    "    - **Thought(생각)**: 이제 미세먼지 정보도 필요하다\n",
    "    - **Action(행동)**: AirQualityAPI.get_pm(\"서울\")\n",
    "    - **Observation(관찰)**: PM10 농도 20㎍/㎥, 좋음\n",
    "    - **Answer(답변)**: 서울의 현재 날씨는 기온 15도로 맑고, 미세먼지 농도는 30㎍/㎥로 좋은 상태이다\n",
    "\n",
    "이처럼 ReAct는 Agent가 **사고 과정을 명시적으로 드러내면서** 외부 도구를 활용하여 복잡한 문제를 해결할 수 있도록 한다.\n",
    "\n",
    "### ReAct의 장점\n",
    "\n",
    "1. **투명성**: Agent의 사고 과정을 추적할 수 있어 디버깅이 용이하다\n",
    "2. **정확성**: 외부 지식과 도구를 활용하여 환각(hallucination)을 줄인다\n",
    "3. **유연성**: 다양한 도구를 조합하여 복잡한 작업을 수행할 수 있다\n",
    "4. **해석 가능성**: 각 단계의 추론 과정을 이해할 수 있다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 동작 단계\n",
    "ReAct 패턴은 크게 **5단계**의 순환 구조로 동작.\n",
    "\n",
    "1. **질문 입력** (Question)\n",
    "     - 사용자로부터 해결해야 할 질문이나 작업을 입력받는다.\n",
    "     - 예시\n",
    "    ```bash\n",
    "     User Input: \"2024년 노벨 물리학상 수상자는 누구이고, 그들의 주요 업적은 무엇인가?\"\n",
    "    ```\n",
    "\n",
    "2. **사고 단계** (Thought)\n",
    "     - 언어 모델이 사용자의 질문(요청)을 분석하고, 문제 해결을 위해 다음에 무엇을 해야 할지 추론.(계획을 세운다.) \n",
    "     - 이 단계에서 Agent는:\n",
    "         - 문제를 이해하고 분해한다\n",
    "         - 필요한 정보가 무엇인지 파악한다\n",
    "         - 어떤 도구를 사용해야 할지 결정한다\n",
    "         - 충분한 정보가 모였는지 판단한다\n",
    "\n",
    "       ```bash\n",
    "       Thought: 2024년 노벨 물리학상 정보는 내 학습 데이터에 없을 수 있다. 최신 정보를 검색해야 한다.\n",
    "       ```\n",
    "\n",
    "3. **행동 단계** (Action)\n",
    "     - 사고 단계에서 결정된 계획을 바탕으로 실제 행동을 실행한다. 행동은 일반적으로 외부 도구(Tool) 호출.   \n",
    "\n",
    "        ```bash\n",
    "        Action: 검색엔진.검색(\"2024 노벨 물리학상 수상자\")\n",
    "        ```\n",
    "\n",
    "4. **관찰 단계** (Observation)\n",
    "     - 행동(Acttion)의 결과를 관찰하고 얻은 정보를 확인.\n",
    "\n",
    "       ```bash\n",
    "       Observation: 2024년 노벨 물리학상은 John Hopfield와 Geoffrey Hinton에게 수여되었다. \n",
    "       ```\n",
    "\n",
    " 5. **반복 또는 종료**\n",
    "       - 관찰한 정보가 사용자 질문에 대한 답변을 하는데 충분하지 않다면 2번의 사고 단계로 돌아가 추가 행동을 계획.(사고→행동→관찰 반복) \n",
    "       - 충분한 정보가 모였다면 그 정보를 바탕으로 최종 답변을 생성한다.\n",
    "\n",
    "          ```bash\n",
    "          Thought: 수상자 이름은 알았지만 구체적인 업적 내용이 필요하다.\n",
    "\n",
    "          Action: Search(\"John Hopfield Geoffrey Hinton 노벨상 업적\")\n",
    "\n",
    "          Observation: Hopfield는 연상 메모리를 위한 Hopfield 네트워크를 개발했고, Hinton은 딥러닝의 역전파 알고리즘과 볼츠만 머신을 연구했다.\n",
    "\n",
    "          Thought: 이제 질문에 답할 충분한 정보가 모였다.\n",
    "\n",
    "          Action: Finish(\"2024년 노벨 물리학상은 John Hopfield와 Geoffrey Hinton에게 수여되었다. Hopfield는 연상 메모리를 위한 Hopfield 네트워크를 개발했고, Hinton은 딥러닝의 역전파 알고리즘과 볼츠만 머신 연구로 인공신경망 발전에 기여했다.\")\n",
    "          ```\n",
    "\n",
    "### 동작 흐름도\n",
    "![ReAct](figures/agent-ReAct.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOOL\n",
    "- **Tool: 하나의 기능을 처리하는 함수.**\n",
    "    - Tool: 하나의 명확한 기능을 수행하도록 정의된 함수(Function) 형태의 외부 실행 수단.\n",
    "    - 대형 언어 모델(LLM)은 본래 텍스트를 생성하는 모델이므로, 실제 계산, 검색, 파일 처리, 데이터베이스 조회와 같은 현실 세계의 작업을 직접 수행할 수는 없다. 이런 실제 작업을 대신 수행하는 단위가 Tool 이다.\n",
    "- **AI Model은 Tool을 이용해 자체 지식의 한계(Knowlege cutoff)를 넘어서는 정보를 제공할 수 있다.**\n",
    "> **Knowledge Cutoff**:\n",
    "> - Knowledge cutoff는 AI 모델이 학습한 데이터가 마지막으로 업데이트된 시점을 의미하며, 그 이후에 발생한 정보나 사건에 대해서는 AI 모델이 학습한 지식으로는 알지 못하는 한계를 가지게 된다.\n",
    "\n",
    "## Tool Calling 개요\n",
    "- **도구 호출**(Tool Calling)은 LLM이 자체적으로 수행할 수 없는 작업을 외부 도구나 API를 활용하여 처리할 수 있게 하는 핵심 기능이다. 이를 통해 **LLM은 자체 지식의 한계를 넘어서는 최신 정보, 정확한 계산, 외부 시스템 제어 등의 능력을 확보**할 수 있다.\n",
    "\n",
    "- **도구 호출(Tool Calling)의 3단계**\n",
    "    1. 도구 바인딩 (Tool Binding): **LLM에 사용가능한 tool들을 등록한다.** \n",
    "        - LLM에게 사용 가능한 도구 목록과 각 도구의 기능(설명) 및 필요한 입력 매개변수를 미리 정의하여 제공한다.\n",
    "            - Tool 함수\n",
    "            - Tool 이름\n",
    "            - Tool이 수행하는 기능 설명\n",
    "            - 입력 파라미터 type과 설명\n",
    "    2. **사용자 질의가 들어오면 LLM이 도구 사용 여부를 판단**한다.\n",
    "        - LLM 자체 추론으로 해결가능한 문제인지 Tool을 호출해야 처리할 수있는 문제 인지를 확인한다.\n",
    "        - **Tool 사용이 필요한 문제** 라고 판단하면 \n",
    "          - 도구를 호출 하는 것이 아니라 어떻게 호출해야 하는지 요청정보를 생성한다.\n",
    "            - 어떤 Tool을 사용해야 하는지, 그 Tool에 어떤 값을 전달해야하는지를 응답으로 생성한다.\n",
    "    3.  **시스템이 Tool 호출 요청정보에 따라 Tool을 실행하고 그 결과를 LLM 에게 전달**한다.\n",
    "\n",
    "     ![toolcalling_concept](figures/toolcalling_concept.png)\n",
    "\n",
    "- **TOOL Calling 예**\n",
    "    - LLM이 수학 계산을 수행해야 할 때, 직접 계산하는 대신 미리 정의된 '계산' 도구를 호출하여 정확한 결과를 얻을 수 있다.\n",
    "  \t- LLM에 최신 정보를 요청하는 질문이 들어왔을 때 '검색' 도구나 'Database 연동' 도구를 사용해 최신 뉴스를 검색하거나, 특정 데이터베이스에서 정보를 조회하는 등의 작업을 수행할 수 있다.\n",
    "  \t- LLM 이 작성한 결과를 google docs와 같은 문서도구나 SNS에 등록한다.\n",
    "\n",
    "## Langchain 과 Tool calling\n",
    "- Tool calling은 대부분의 LLM 서비스가 지원한다.\n",
    "  - [Tool Calling을 지원하는 LLM 모델](https://docs.langchain.com/oss/python/integrations/chat)만 사용할 수 있다.\n",
    "- LangChain은 다양한 모델들의 도구 호출 방식을 표준화하여 일관된 인터페이스로 제공한다. 이를 통해 개발자들은 다양한 모델과 도구들을 쉽게 통합할 수있다.\n",
    "  - [Langchain Tool Calling Concept](https://docs.langchain.com/oss/python/langchain/tools)\n",
    "- Langchain 제공 Built-in tools\n",
    "    -  https://docs.langchain.com/oss/python/integrations/tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Built-in Tools 사용으로 Tool Calling 이해\n",
    "\n",
    "- Langchain은 다양한 도구들을 미리 구현해서 제공, builtin tool이라고 한다. \n",
    "  - [Langchain 지원 Built tools](https://docs.langchain.com/oss/python/integrations/tools)\n",
    "- Built-In tool 뿐만 아니라 사용자 정의 Tool들을 직접 구현할 수있는 방법도 제공.\n",
    "\n",
    "## Tavily API 검색 Tool\n",
    "> Tavily 웹 검색 도구 사용해 Tool calling을 이해한다.\n",
    "- **Tavily** Service: AI을 위한 웹 검색 API Service.\n",
    "- https://tavily.com/\n",
    "-  LLM과 RAG 시스템에 최적화된 검색 엔진.\n",
    "   -  기존의 일반 검색 엔진들과 달리, Tavily는 AI 애플리케이션의 요구사항에 맞춰 설계되었다.\n",
    "   -  Tavily는 최대 20개 이상의 신뢰도 높은 웹사이트에서 관련정보를 수집한다. \n",
    "   -  수집된 데이터는 AI가 관련성, 신뢰도, 최신성 등을 기준으로 평가해 가장 적합한 정보만 선별해서 요약한다. \n",
    "   -  최종적으로 이 정보는 LLM이 바로 활용할 수있도록 컨텐츠 스티펫, 요약, 출처 등의 구조화된 형태로 반환한다.\n",
    "   -  월 1000회 무료 사용 가능.\n",
    "- **Tavily API Key 받기**\n",
    "  - 회원가입 후 로그인 한다.\n",
    "  - Overview 화면에서 API Key 생성 \n",
    "    - default API key 사용할 수있다.\n",
    "  - 환경변수에 등록한다.\n",
    "      - 변수이름: `TAVILY_API_KEY`\n",
    "\n",
    "### TavilySearch\n",
    "- Langchain에서 제공하는 tool로 Tavily 의 검색 엔진 API를 사용해 검색을 수행한다.\n",
    "- 설치\n",
    "  - `pip install langchain-tavily`\n",
    "- https://python.langchain.com/docs/integrations/tools/tavily_search/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[37m⠹\u001b[0m \u001b[2morjson==3.11.5                                                                \u001b[0m\u001b[2mResolved \u001b[1m41 packages\u001b[0m \u001b[2min 435ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m     0 B/30.00 KiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)m-------------\u001b[0m\u001b[0m 16.00 KiB/30.00 KiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----------\u001b[2m\u001b[0m\u001b[0m 30.00 KiB/30.00 KiB         \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 34ms\u001b[0m\u001b[0m                                                   \u001b[1A\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m.2.16                             \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-tavily\u001b[0m\u001b[2m==0.2.16\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !uv pip install langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_tavily import TavilySearch     # Tavily 검색 tool\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성 - 검색 옵션을 파라미터로 설정\n",
    "tavily_search = TavilySearch(\n",
    "    max_results=3,          # 최대 검색 개수\n",
    "    # include_raw_content = True,   # 원본 내용도 포함.\n",
    "    # include_answer=True,    # 검색 결과를 바탕으로 Tavily AI가 종합적 답변을 하도록 한다.\n",
    "    # include_images=True,    # 검색한 문서 내의 이미지 (경로)들을 반환.\n",
    "    # time_range=\"year\",      # day, week, month, year - 현재 시점 기준으로 지정한 기간 내의 문서들만 검색 결과로 제공.\n",
    ")\n",
    "# 검색\n",
    "query = \"2025년 한국 시리즈 우승팀은?\"\n",
    "# result = tavily_search.invoke(query)\n",
    "result = tavily_search.invoke(\n",
    "    {\n",
    "        \"query\":query,\n",
    "        \"include_image\": True    # 옵션들을 \"key\" : value로 설정해서 실행 시 동적으로 설정.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': '2025년 한국 시리즈 우승팀은?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': ['https://blogthumb.pstatic.net/MjAyNTAzMjNfNjYg/MDAxNzQyNzE4ODAxNzkw.oSUS641rn-u5mmRK9X90k3cOu6mV_S-lXEroFC41xc0g.ifwCdPWPHpTasTUsv1lLbaYgl6z8MXOE4Ezbpu0y2WUg.PNG/������-�Է����ּ���__���纻-_27_-001.png?type=w2',\n",
       "  'https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIwYdP22bQ2HL4mmF0rsT9O2cpYw8iRkBY4AkpbjujNUkhyphenhyphen-k1BICpkEpj1u1EejbsLIaOld7q40ZSmna-vLCXKj1XNTr8rRHDAB1QhsT-BNRjZkZGPzqPDGc501RlSJyXAx7_HJX2KDCcpZtRWBiUFWbOy6x-MVWIYlHTxsNi6iKnX7ZMjJzvPu6q38jK/s1024/ChatGPT+Image+2025년+10월+11일+오전+11_20_52.png',\n",
       "  'https://img.etoday.co.kr/pto_db/2024/10/20241029063224_2094589_999_567.jpg',\n",
       "  'https://img8.yna.co.kr/etc/graphic/YH/2025/10/24/GYH2025102400110004400_P4.jpg',\n",
       "  'https://blog.kakaocdn.net/dn/boRtrn/btsMgUfWOwB/t7Xx4EoLVFU5OrsilmFCmK/img.jpg'],\n",
       " 'results': [{'url': 'https://sports.news.nate.com/view/20251031n37442',\n",
       "   'title': '[속보] LG 트윈스, 2025 한국시리즈 우승…2년만에 왕좌 탈환',\n",
       "   'content': '프로야구 LG 트윈스가 한화 이글스를 꺾고 2025년 한국시리즈 우승을 차지했습니다. LG는 조금 전 대전에서 열린 한국시리즈 5차전에서 4대1로 승리,',\n",
       "   'score': 0.9999349,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.youtube.com/watch?v=MmcDtgJ1zqs',\n",
       "   'title': '[속보] LG 트윈스, 2025 한국시리즈 우승…2년만에 왕좌 탈환 ...',\n",
       "   'content': '프로야구 LG 트윈스가 한화 이글스를 꺾고 2025년 한국시리즈 우승을 차지했습니다. LG는 조금 전 대전에서 열린 한국시리즈 5차전에서 4대1로 승리,',\n",
       "   'score': 0.9998859,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.facebook.com/kbo1982/posts/2025-kbo-%ED%95%9C%EA%B5%AD%EC%8B%9C%EB%A6%AC%EC%A6%88-%EC%9A%B0%EC%8A%B9-lg%ED%8A%B8%EC%9C%88%EC%8A%A4%EC%9E%85%EB%8B%88%EB%8B%A41031-lg%ED%95%9C%ED%99%94%EC%95%BC%EA%B5%AC-baseball-kbo-%ED%8F%AC%EC%8A%A4%ED%8A%B8%EC%8B%9C%EC%A6%8C-%ED%95%9C%EA%B5%AD%EC%8B%9C%EB%A6%AC%EC%A6%88_5%EC%B0%A8%EC%A0%84-lg%ED%8A%B8%EC%9C%88%EC%8A%A4-%EC%9A%B0%EC%8A%B9-kbo2/1315789490588357/',\n",
       "   'title': '2025 KBO 한국시리즈 우승! LG트윈스입니다!(10.31. ...',\n",
       "   'content': '2025 KBO 한국시리즈 우승! LG트윈스입니다!(10.31. LG: 한화) #야구 #baseball #KBO #포스트시즌 #한국시리즈_5차전 #LG트윈스 #우승 #kbo20251031.',\n",
       "   'score': 0.9995859,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 3.67,\n",
       " 'request_id': '582d6da1-3959-431b-9943-685a4e50f1a8'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도구 이름 tavily_search\n",
      "도구 설명:\n",
      "A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "# 도구 - 도구 이름, 도구 설명 ==> llm이 도구 사용 여부를 판단할 때 근거.\n",
    "# Tavily (built-in) 도구 정보를 확인\n",
    "###########################################################\n",
    "print(\"도구 이름\", tavily_search.name)\n",
    "print(\"도구 설명:\")\n",
    "print(tavily_search.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additionalProperties': True,\n",
       " 'description': 'Input for [TavilySearch]',\n",
       " 'properties': {'query': {'description': 'Search query to look up',\n",
       "   'title': 'Query',\n",
       "   'type': 'string'},\n",
       "  'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "    {'type': 'null'}],\n",
       "   'default': [],\n",
       "   'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        ',\n",
       "   'title': 'Include Domains'},\n",
       "  'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "    {'type': 'null'}],\n",
       "   'default': [],\n",
       "   'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        ',\n",
       "   'title': 'Exclude Domains'},\n",
       "  'search_depth': {'anyOf': [{'enum': ['basic',\n",
       "      'advanced',\n",
       "      'fast',\n",
       "      'ultra-fast'],\n",
       "     'type': 'string'},\n",
       "    {'type': 'null'}],\n",
       "   'default': 'basic',\n",
       "   'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        \\n        Use \"fast\" for optimized low latency with high relevance.\\n        \\n        Use \"ultra-fast\" when latency is prioritized above all else.\\n        ',\n",
       "   'title': 'Search Depth'},\n",
       "  'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "   'default': False,\n",
       "   'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        ',\n",
       "   'title': 'Include Images'},\n",
       "  'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'],\n",
       "     'type': 'string'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        ',\n",
       "   'title': 'Time Range'},\n",
       "  'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'],\n",
       "     'type': 'string'},\n",
       "    {'type': 'null'}],\n",
       "   'default': 'general',\n",
       "   'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        ',\n",
       "   'title': 'Topic'},\n",
       "  'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        ',\n",
       "   'title': 'Start Date'},\n",
       "  'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        ',\n",
       "   'title': 'End Date'}},\n",
       " 'required': ['query'],\n",
       " 'title': 'TavilySearchInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = tavily_search.args_schema.model_json_schema()\n",
    "schema\n",
    "# 도구 스키마\n",
    "## 도구 호출 시 전달 파라미터 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'Search query to look up',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'},\n",
       " 'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "   {'type': 'null'}],\n",
       "  'default': [],\n",
       "  'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        ',\n",
       "  'title': 'Include Domains'},\n",
       " 'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "   {'type': 'null'}],\n",
       "  'default': [],\n",
       "  'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        ',\n",
       "  'title': 'Exclude Domains'},\n",
       " 'search_depth': {'anyOf': [{'enum': ['basic',\n",
       "     'advanced',\n",
       "     'fast',\n",
       "     'ultra-fast'],\n",
       "    'type': 'string'},\n",
       "   {'type': 'null'}],\n",
       "  'default': 'basic',\n",
       "  'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        \\n        Use \"fast\" for optimized low latency with high relevance.\\n        \\n        Use \"ultra-fast\" when latency is prioritized above all else.\\n        ',\n",
       "  'title': 'Search Depth'},\n",
       " 'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "  'default': False,\n",
       "  'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        ',\n",
       "  'title': 'Include Images'},\n",
       " 'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'],\n",
       "    'type': 'string'},\n",
       "   {'type': 'null'}],\n",
       "  'default': None,\n",
       "  'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        ',\n",
       "  'title': 'Time Range'},\n",
       " 'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'],\n",
       "    'type': 'string'},\n",
       "   {'type': 'null'}],\n",
       "  'default': 'general',\n",
       "  'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        ',\n",
       "  'title': 'Topic'},\n",
       " 'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "  'default': None,\n",
       "  'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        ',\n",
       "  'title': 'Start Date'},\n",
       " 'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "  'default': None,\n",
       "  'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        ',\n",
       "  'title': 'End Date'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM ToolCalling 흐름\n",
    "\n",
    "### 1. Tool 생성 및 LLM Model에 tool binding\n",
    "- `LLM-Model.bind_tools(tools=[tool_1, tool_2, ...])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tavily_search = TavilySearch(max_results=5)\n",
    "model = ChatOpenAI(model=\"gpt-5-mini\")   # 뇌 -> 성능 좋은 모델을 사용 (판단자.)\n",
    "toolkit = [tavily_search]  # 툴들 모음\n",
    "# model에 tool들을 binding\n",
    "tool_model = model.bind_tools(tools=toolkit)\n",
    "print(type(tool_model), type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tool 호출\n",
    "- LLM 모델이 tool 요청을 결정한 경우 **어떤 tool을 어떻게 호출할 지** AIMessage의 `tool_calls` 속성에 넣어 반환한다.\n",
    "- `tool_calls` 의 호출 정보를 넣어 `tool.invoke()` 호출한다.\n",
    "   - `tool.invoke(result.tool_calls[0])`\n",
    "   - **반환타입**: `ToolMessage`\n",
    "     - Tool의 처리결과를 담는 Message Type 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tool_call 이 여러개일 경우 \n",
    "- 질의에 대해 tool을 여러번 호출 해야 하는 경우 tool_calling 정보를 여러개 반환할 수 있다.\n",
    "    - 예) 검색할 키워드가 여러개인 경우. \n",
    "- `tool.batch([tool_call1, tool_call2, ..])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tool의 처리(응답) 결과를 LLM 요청시 사용\n",
    "- ToolMessage를 prompt 에 추가하여 LLM에 요청한다.\n",
    "- ToolMessage 는 Tool Calling 정보를 가진 AIMessage 다음에 들어와야 한다.\n",
    "- Prompt 순서\n",
    "    1. 일반 prompt (system, 대화 history, .., human)\n",
    "    2. AIMessage: tool calling 정보를 가진 AIMessage. (tool_model에 질의 받은 tool calling 정보가 있는 응답)\n",
    "    3. ToolMessage:  Tool의 처리 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용자 정의 Tool 구현\n",
    "\n",
    "## @tool 사용\n",
    "- 함수로 구현하고 `@tool` 데코레이터를 사용해 tool(StructuredTool)로 정의한다.\n",
    "    - `langchain_core.tools` 모듈에 있다.\n",
    "- tool name\n",
    "    - 함수의 이름이 tool의 이름이 된다.\n",
    "- parameters\n",
    "    - 함수의 파라미터가 tool의 파라미터가 된다.\n",
    "    - **type hint**를 이용해 타입을 지정한다.  \n",
    "- description\n",
    "    - doctring이 description이 된다.\n",
    "    - RunnableBinding이 tool을 잘 찾을 수 있도록 하려면 **tool의 기능을 최대한 구체적**으로 작성한다.\n",
    "- **@tool이 적용된 함수(StructuredTool)이 tool**이므로 model에 binding 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable을 tool로 정의\n",
    "- `Runnable객체.as_tool()`\n",
    "    - name, description, args_schema 파라미터를 이용해 tool의 이름, 설명, 스키마를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store(Vector 저장소) tool\n",
    "\n",
    "### text loading -> Document 생성\n",
    "- 레스토랑 메뉴를 vector store에 저장한다.\n",
    "1. 메뉴 text 를 로딩한다.\n",
    "2. 각 메뉴의 내용(음식이름, 메뉴설명, 파일명)을 넣어 Document를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 Load\n",
    "import os\n",
    "# 메뉴읽어 오기\n",
    "menu_file_path = \"data/restaurant_menu.txt\"\n",
    "with open(menu_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    menu = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split - 메뉴별로 분리하기 위해 직접 처리\n",
    "from langchain_core.documents import Document\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "def create_documents(menu_all: str, file_name) -> list[Document]:\n",
    "    \"\"\"메뉴별로 분리 한뒤 Document로 변환. 변환된 Document들을 리스트로 반환\n",
    "    metadata: 메뉴이름, 주요 재료, 가격, source(파일이름)\n",
    "    \"\"\"\n",
    "    menu_list = menu_all.split(\"\\n\\n\")\n",
    "    menu_documents = []\n",
    "    for menu_item in menu_list:\n",
    "\n",
    "        # 메뉴 이름 추출\n",
    "        menu_name_pattern = r\"(^\\d+.\\s)([가-힣a-zA-Z\\d ]+)\"\n",
    "        menu_name_result = re.search(menu_name_pattern, menu_item)\n",
    "        menu_name = menu_name_result.group(2).strip()  # 메뉴 이름 추출 # 1은 번호\n",
    "\n",
    "        # 주요재료 추출 - text로 indexing.\n",
    "        menu_ingredient_pattern = r\"(?<=주요 재료: ).+\"\n",
    "        ingredients = re.search(menu_ingredient_pattern, menu_item).group().strip()\n",
    "    \n",
    "        # 가격추출\n",
    "        price_pattern = r\"(?<=가격: )[\\d,]+(?=원)\"\n",
    "        price_result = re.search(price_pattern, menu_item)\n",
    "        price = int(price_result.group().replace(\",\", \"\"))\n",
    "\n",
    "        \n",
    "        # 메뉴 이름을 제외한 나머지는 메뉴 설명으로 간주\n",
    "        menu_doc = Document(\n",
    "            page_content=menu_item,     # 메뉴 설명을 page_content에 넣는다. metadata는 나중에 따로 따로 payload filtering 할 수있기 때문에 \n",
    "            metadata={\n",
    "                \"menu_name\": menu_name, # 메뉴 이름\n",
    "                \"price\": price,         # 가격\n",
    "                \"ingredients\": ingredients, # 재료 리스트\n",
    "                \"source\": file_name     # 메뉴가 저장된 파일 이름\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "    return menu_documents\n",
    "\n",
    "\n",
    "menu_documents = create_documents(menu, menu_file_path)\n",
    "print(len(menu_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorDB 저장 및 VectorStore 생성\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "COLLECTION_NAME = \"restaurant_menu\"\n",
    "VECTOR_SIZE = 1536  # OpenAIEmbeddings의 벡터 크기\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "if client.collection_exists(COLLECTION_NAME):\n",
    "    client.delete_collection(COLLECTION_NAME)\n",
    "\n",
    "# Collection 생성\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    # 벡터 저장소에 대한 설정. - vector_config는 default이므로 이름을 안줘도 됨(default 로 잡힘) 이름을 줄 거면 {\"이름\":VectorParams()} 설정\n",
    "    vectors_config=VectorParams(\n",
    "        size=VECTOR_SIZE, \n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=client, # QdrantClient\n",
    "    embedding=embeddings, # Embedding Model\n",
    "    collection_name=COLLECTION_NAME # 연결할 Collection 지정.\n",
    ")\n",
    "ids = vectorstore.add_documents(menu_documents)\n",
    "print(f\"저장된 문서 개수: {len(ids)}\")\n",
    "##################################################\n",
    "# Retriever 생성\n",
    "##################################################\n",
    "menu_retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}  # 검색할 결과 개수\n",
    ")\n",
    "\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "retriever = menu_retriever.configurable_fields(\n",
    "    search_type=ConfigurableField(\n",
    "        id=\"search_type\"\n",
    "    ),\n",
    "    search_kwargs=ConfigurableField(\n",
    "        id=\"search_kwargs\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create_agent() 를 이용한 Agent 구현\n",
    "\n",
    "- create_agent()\n",
    "  - Agent 생성 및 실행을 표준화, 단순화 하기 위헤 Langchain 1.0에서 도입된 함수\n",
    "  - 0.x 버전까지는 Agent 생성 함수는 \n",
    "    1. model과 tool들을 넣어 Agent를 생성하고 \n",
    "    2. 그것을 실행하는 Executor를 생성하는 방식으로\n",
    "  - 여러 단계를 거쳐야 했다.\n",
    "  - create_agent()는 이러한 단계를 1단계로 축약한 API이다.\n",
    "\n",
    "- create_agent 설계 철학\n",
    "    1. Agent를 구성하는 모든 실행단위는 Runnable 이다.\n",
    "    2. Agent도 Runnable 이다.\n",
    "    3. Agent는 하나의 표준 팩토리 함수(생성함수)로 통합한다.\n",
    "\n",
    "## 주요 파라미터\n",
    "- https://reference.langchain.com/python/langchain/agents/\n",
    "- `model`: LLM 모델. Agent의 두뇌 역할을 하며 추론(Reasoning), 도구 선택, 최종 응답을 담당한다.\n",
    "- `tools`: Agent가 사용할 외부 도구모음. \n",
    "- `system_prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain에서 MCP 연동\n",
    "\n",
    "## MCP란\n",
    "\n",
    "- **MCP**(**Model Context Protocol**)는 Anthropic이 주도하여 2024년 말에 발표한 개방형 표준으로, LLM 애플리케이션이 외부 데이터 소스나 도구에 접근하는 방식을 표준화 하는 프로토콜이다.\n",
    "  - Agent가 이용할 수 있는 tool을 구현하는 방법은 framework 마다 다르기 때문에 서로 호환 되지 않는 문제가 있다. \n",
    "  - MCP는 이런 문제를 해결하기 위해 만든 표준 프로토콜이다.\n",
    "\n",
    "## MCP 아키텍처 구성 요소\n",
    "- **MCP 호스트**\n",
    "  -  AI 애플리케이션(예: LLM 채팅 애플리케이션)으로 MCP 클라이언트를 통해 여러 서버에 연결한다.\n",
    "\n",
    "- **MCP 클라이언트**\n",
    "  -  각 MCP 서버와의 연결을 유지하는 구성요소로, 서버로부터 도구/리소스/프롬프트를 가져와 LLM 모델에게 전달한다.\n",
    "\n",
    "- **MCP 서버**\n",
    "  -  외부 데이터 소스나 Tool들을 제공하는 프로그램이다. 서버는 도구, 리소스, 프롬프트를 노출하고 클라이언트와 JSON‑RPC 2.0 메시지로 통신한다.\n",
    "  -  MCP는 서버 클라이언트 간의 **로컬 프로세스 간 통신을 위한 STDIO**와 **원격 서버 접속을 위한 Streamable HTTP** 두 가지 전송 방식을 지원한다\n",
    "  -  **MCP 서버가 제공하는 것**\n",
    "     -  **도구**(**Tools**): LLM이 호출할 수 있는 함수형 작업이다. 예를 들어 “queryDatabase”, “sendEmail” 등이 있으며 각 도구는 이름, 설명, 입력 스키마를 포함한다.\n",
    "     -  **리소스**(**Resources**): 읽기 전용 데이터 소스로, 검색 색인·파일시스템·데이터베이스 등에서 컨텍스트를 제공한다.\n",
    "     -  **프롬프트**(**Prompts**): LLM 프롬프트 템플릿이나 예시를 서버에서 제공해 AI 모델의 질의를 돕는다.\n",
    "  \n",
    "\n",
    "## 사용 가능한 MCP 툴 찾기\n",
    "\n",
    "- MCP 생태계에는 수천 개의 툴 서버가 이미 공개되어 있으며, 원하는 기능의 툴을 검색하여 사용할 수 있다. \n",
    "- MCP 검색 및 서비스 사이트\n",
    "  - [PulseMCP](pulsemcp.com)\n",
    "  - [MCP 마켓](https://mcpmarket.com/ko)\n",
    "  - [MCP Servers](https://mcp.so/)\n",
    "  - [smithery](https://smithery.ai/servers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## LangChain에서 MCP 툴 연동하기\n",
    "\n",
    "- LangChain에서 MCP 서버와 연동하기 위해서는 Adapter lib 설치가 필요하다.\n",
    "  - `pip install langchain-mcp-adapters`\n",
    "\n",
    "###  MultiServerMCPClient \n",
    "- **MCP 클라이언트 객체**로, LangChain에서 **하나 이상의 MCP 서버를 연결하고 Tool 목록을 가져오기 위해 사용**한다.\n",
    "    - 여러 개의 MCP 서버를 **동시에 등록하고 연결**할 수 있다.\n",
    "    - 서버 설정들을 **하나의 딕셔너리**(**Dictionary**)로 묶어 전달하며, **각 개별 서버 역시 Dictionary로 설정**한다.\n",
    "    - MCP 클라이언트에 등록된 모든 서버는 이후 `get_tools()` 호출을 통해 서버가 제공하는 tool들을 **LangChain의 Tool 객체로 자동 변환해 Agent가 호출**(**사용**)할 수있게 한다.\n",
    "\n",
    "#### 개별 서버 설정 Key 정의\n",
    "- **`dict[str: 서버 별칭, dict: 서버 설정]`**\n",
    "\n",
    "| 설정 Key        | 의미                                                                  | 사용 예                            |\n",
    "| --------------- | --------------------------------------------------------------------- | ---------------------------------- |\n",
    "| **`transport`** | 서버와 통신하는 방식                                                  | `\"stdio\"` 또는 `\"streamable-http\"` |\n",
    "| **`command`**   | MCP 서버를 실행할 프로그램(프로세스)                                  | `\"python\"` 또는 `\"npx\"`            |\n",
    "| **`args`**      | command에 전달할 세부 실행 인자를 **리스트(List)**에 문자열로 순서대로 배치 | `[\"-m\", \"mcp_server_time\"]`  |\n",
    "\n",
    "- **transport 값에 따른 동작 구분**\n",
    "    - `\"stdio\"`: 로컬에서 실행되는 서버 연결\n",
    "    - `\"streamable-http\"`: 원격 MCP 서버(서비스형) 연결\n",
    "    \n",
    "    ```json\n",
    "        {\n",
    "            \"time\": {\n",
    "                \"transport\": \"stdio\",\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"-m\", \"mcp_server_time\"]\n",
    "            }\n",
    "        \n",
    "            \"github\": {\n",
    "                \"transport\": \"streamable-http\",\n",
    "                \"url\": \"https://server.smithery.ai/github\",\n",
    "            }\n",
    "        }\n",
    "    ```\n",
    "\n",
    "#### command + args 와 실행 명령어 관계\n",
    "\n",
    "| 실제 실행 명령                    | 설정으로 표현되는 방식                                             |\n",
    "| --------------------------- | -------------------------------------------------------- |\n",
    "| `python -m mcp_server_time` | `\"command\": \"python\", \"args\": [\"-m\", \"mcp_server_time\"]` |\n",
    "| `npx -y @org/server`        | `\"command\": \"npx\", \"args\": [\"-y\", \"@org/server\"]`        |\n",
    "\n",
    "* **command는 실행 프로그램**, args는 **명령 뒤에 붙는 옵션을 순서 그대로 리스트에 나열**한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
