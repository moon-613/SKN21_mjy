{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/30(화) 14:20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent 개요\n",
    "> **Agent: 대형 언어 모델을 두뇌로 사용해, 목표를 스스로 이해하고 외부 도구와 상호작용하며 실제 작업을 자율적으로 수행하는 지능형 인공지능 시스템.**\n",
    "\n",
    "- Agent: **대형 언어 모델(LLM, Large Language Model)과 다양한 도구(Tool)를 결합해, 사용자의 복잡한 요청을 스스로 분석하고 처리하도록 설계된 지능형 인공지능 시스템.**\n",
    "기존의 단순한 챗봇이 “질문 → 답변” 구조로 동작한다면, \n",
    "  - Agent는 **목표 설정 → 판단 → 실행 → 결과 반영**의 전 과정을 스스로 수행하는 구조를 가진다.\n",
    "\n",
    "- Agent는 주어진 목표를 달성하기 위해 자율적으로 **외부 환경(도구, API, 데이터베이스, 파일 시스템 등)과 상호작용하며 의사 결정을 내리고 실제 행동을 수행.**\n",
    "이때 Agent의 **핵심적인 의사 결정과 추론 과정은 대형 언어 모델(LLM)이 담당**하며, **사람의 개입은 최소화**한다.\n",
    "\n",
    "- 즉, Agent는 단순히 정보를 말해주는 존재가 아니라, **\"문제를 이해하고, 해결 방법을 계획하고, 직접 실행까지 담당하는 인공지능 작업 수행자\".**\n",
    "\n",
    "- AI 시스템을 구현할 때, **워크플로우**(**Workflow**)는 사전에 정의된 절차에 따라 실행 단계가 고정적인 구현 방식이라면, **에이전트**(**Agent**)는 주어진 목표를 달성하기 위해 스스로 계획을 수립하고, 상황을 판단하여 행동을 결정·실행하는 자율적인 방식.\n",
    "\n",
    "\n",
    "\n",
    "## Agent의 주요 특징\n",
    "\n",
    "1. **자율성** (Autonomy)\n",
    "   - Agent는 **사전 정의된 규칙**(Rule-based)에 의존하지 않고, LLM을 통해 현재 상황을 인지하고 추론하여 스스로 결정을 내리고 다음 행동을 계획 가능.\n",
    "   - 즉, 사용자가 일일이 수행 단계를 지시하지 않아도, Agent는 **현재 상황을 해석하고 다음 행동을 동적으로 결정.**\n",
    "\n",
    "2. **목표 지향성** (Goal-Oriented)\n",
    "    - Agent는 단순히 질문에 답변하는 **단순한 대화 상대가 아니라, 특정 목표와 복잡한 작업을 달성하기 위해 설계된 시스템**으로 최종 목표에 도달할 때 까지 반복적으로 행동.\n",
    "    - Agent는 어떤 처리를 할 때 항상 **\"이 행동이 목표 달성에 도움이 되는가\"를 기준**으로 판단.\n",
    "\n",
    "3. **도구 활용** (Tool Utilization)\n",
    "    - Agent는 대형 언어 모델의 언어 이해 능력, 사전 학습 정보에만 의존하지 않고, 다양한 **외부 도구와 API를 함께 활용하여 실제 작업을 수행**.\n",
    "    - 이를 통해 LLM이 처리할 수없는 **최신 정보 검색, 복잡한 계산, 외부 시스템 제어**등과 같은 작업이 가능. 이를 통해 Agent는 **\"말만 하는 AI\"가 아니라 \"실제로 일을 처리하는 AI\"로 기능.**\n",
    "\n",
    "4. **인간 개입 최소화** (Human-in-the-loop 최소화)\n",
    "    - Agent는 **문제 분석, 의사 결정, 행동 실행의 대부분을 스스로 결정하고 수행하도록 설계.**\n",
    "    - 사람은 **초기 목표 제시, 결과 확인 및 실행 최종 승인** 정도에 만 개입."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다양한 Agent 활용 사례\n",
    "\n",
    "- **미국 국세청(IRS) 세무처리에 도입된 AI 에이전트**\n",
    "    - 미국 국세청(IRS)은 Salesforce Agentforce 기반 AI 에이전트를 도입해 세무 업무에서의 보조·분석 기능을 강화하고 업무 효율을 높이고 있다.\n",
    "\n",
    "-  **고객 추천 및 개인화된 콘텐츠 제공**\n",
    "    - Netflix, Amazon 같은 OTT 플랫폼은 사용자의 취향 변화에 따라 추천 시스템을 적응시키는 학습형 에이전트를 활용해 콘텐츠/제품 추천을 개선해 나간다.\n",
    "\n",
    "- **영업 지원용 AI 에이전트**\n",
    "    - Oracle은 영업 전문가를 위한 AI 에이전트를 도입해 고객 미팅 후 CRM 업데이트, 고객 데이터 분석·보고서 생성 같은 반복 작업을 자동화하고 있다.\n",
    "\n",
    "- **물류 최적화 및 배송 계획**\n",
    "    - Uber Freight, J.B. Hunt 등에서는 AI 에이전트를 활용해 실시간 교통·날씨 데이터 분석을 통해 가장 효율적인 배송 경로를 계산.\n",
    "\n",
    "- **AWS의 클라우드 자동화 에이전트**\n",
    "    - Amazon Web Services는 보안, DevOps, 일반 작업을 자동화하는 AI 에이전트들을 출시하며 클라우드 인프라 운영과 보안 모니터링을 강화하고 있다.\n",
    "\n",
    "- **삼성SDS AI 에이전트 플랫폼**\n",
    "    - 삼성SDS는 **사용자 개입 없이 스스로 판단·문제 해결이 가능한 AI 에이전트 플랫폼 ‘패브릭스(Fabrics)’**를 공개. 이를 통해 기업 내부에서 자동화된 의사결정과 작업 실행을 지원."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct 패턴\n",
    "- Agent 구현의 바탕이 되는 이론.\n",
    "\n",
    "## 1. 개요\n",
    "\n",
    "ReAct: **Reasoning**(추론)과 **Acting**(행동)을 결합한 AI Agent의 프롬프팅 패턴이다. 대형 언어 모델(LLM)이 단순히 답변을 생성하는 것이 아니라, 문제를 분석하고(Reasoning)하고 그에 따라 필요한 도구를 선택하여 실행하며(Acting), 결과를 관찰하고(Observation) 다음 추론에 반영하는 과정을 반복하면서 문제를 해결하는  Agent 설계 방식.\n",
    "\n",
    "### ReAct의 핵심 개념\n",
    "\n",
    "전통적인 프롬프팅 방식은 질문에 대해 즉시 답변을 생성한다. 하지만 **ReAct 패턴**은 다음과 같은 순환 구조를 따른다:\n",
    "\n",
    "```\n",
    "질문 → 생각(Thought) → 행동(Action) → 관찰(Observation) → 생각 → 행동 →  관찰 → ... → 답변\n",
    "```\n",
    "\n",
    "- 예)\n",
    "  - 질문: \"현재 서울의 날씨와 미세먼지 농도를 알려줘\":\n",
    "\n",
    "    - **Thought(생각)**: 날씨 정보를 얻기 위해 날씨 API를 호출해야겠다\n",
    "    - **Action(행동)**: WeatherAPI.get_weather(\"서울\")\n",
    "    - **Observation(관찰)**: 기온 15도, 맑음\n",
    "    - **Thought(생각)**: 이제 미세먼지 정보도 필요하다\n",
    "    - **Action(행동)**: AirQualityAPI.get_pm(\"서울\")\n",
    "    - **Observation(관찰)**: PM10 농도 20㎍/㎥, 좋음\n",
    "    - **Answer(답변)**: 서울의 현재 날씨는 기온 15도로 맑고, 미세먼지 농도는 30㎍/㎥로 좋은 상태이다\n",
    "\n",
    "이처럼 ReAct는 Agent가 **사고 과정을 명시적으로 드러내면서** 외부 도구를 활용하여 복잡한 문제를 해결할 수 있도록 한다.\n",
    "\n",
    "### ReAct의 장점\n",
    "\n",
    "1. **투명성**: Agent의 사고 과정을 추적할 수 있어 디버깅이 용이하다\n",
    "2. **정확성**: 외부 지식과 도구를 활용하여 환각(hallucination)을 줄인다\n",
    "3. **유연성**: 다양한 도구를 조합하여 복잡한 작업을 수행할 수 있다\n",
    "4. **해석 가능성**: 각 단계의 추론 과정을 이해할 수 있다\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 동작 단계\n",
    "ReAct 패턴은 크게 **5단계**의 순환 구조로 동작.\n",
    "\n",
    "1. **질문 입력** (Question)\n",
    "     - 사용자로부터 해결해야 할 질문이나 작업을 입력받는다.\n",
    "     - 예시\n",
    "    ```bash\n",
    "     User Input: \"2024년 노벨 물리학상 수상자는 누구이고, 그들의 주요 업적은 무엇인가?\"\n",
    "    ```\n",
    "\n",
    "2. **사고 단계** (Thought)\n",
    "     - 언어 모델이 사용자의 질문(요청)을 분석하고, 문제 해결을 위해 다음에 무엇을 해야 할지 추론.(계획을 세운다.) \n",
    "     - 이 단계에서 Agent는:\n",
    "         - 문제를 이해하고 분해한다\n",
    "         - 필요한 정보가 무엇인지 파악한다\n",
    "         - 어떤 도구를 사용해야 할지 결정한다\n",
    "         - 충분한 정보가 모였는지 판단한다\n",
    "\n",
    "       ```bash\n",
    "       Thought: 2024년 노벨 물리학상 정보는 내 학습 데이터에 없을 수 있다. 최신 정보를 검색해야 한다.\n",
    "       ```\n",
    "\n",
    "3. **행동 단계** (Action)\n",
    "     - 사고 단계에서 결정된 계획을 바탕으로 실제 행동을 실행한다. 행동은 일반적으로 외부 도구(Tool) 호출.   \n",
    "\n",
    "        ```bash\n",
    "        Action: 검색엔진.검색(\"2024 노벨 물리학상 수상자\")\n",
    "        ```\n",
    "\n",
    "4. **관찰 단계** (Observation)\n",
    "     - 행동(Acttion)의 결과를 관찰하고 얻은 정보를 확인.\n",
    "\n",
    "       ```bash\n",
    "       Observation: 2024년 노벨 물리학상은 John Hopfield와 Geoffrey Hinton에게 수여되었다. \n",
    "       ```\n",
    "\n",
    " 5. **반복 또는 종료**\n",
    "       - 관찰한 정보가 사용자 질문에 대한 답변을 하는데 충분하지 않다면 2번의 사고 단계로 돌아가 추가 행동을 계획.(사고→행동→관찰 반복) \n",
    "       - 충분한 정보가 모였다면 그 정보를 바탕으로 최종 답변을 생성한다.\n",
    "\n",
    "          ```bash\n",
    "          Thought: 수상자 이름은 알았지만 구체적인 업적 내용이 필요하다.\n",
    "\n",
    "          Action: Search(\"John Hopfield Geoffrey Hinton 노벨상 업적\")\n",
    "\n",
    "          Observation: Hopfield는 연상 메모리를 위한 Hopfield 네트워크를 개발했고, Hinton은 딥러닝의 역전파 알고리즘과 볼츠만 머신을 연구했다.\n",
    "\n",
    "          Thought: 이제 질문에 답할 충분한 정보가 모였다.\n",
    "\n",
    "          Action: Finish(\"2024년 노벨 물리학상은 John Hopfield와 Geoffrey Hinton에게 수여되었다. Hopfield는 연상 메모리를 위한 Hopfield 네트워크를 개발했고, Hinton은 딥러닝의 역전파 알고리즘과 볼츠만 머신 연구로 인공신경망 발전에 기여했다.\")\n",
    "          ```\n",
    "\n",
    "### 동작 흐름도\n",
    "![ReAct](figures/agent-ReAct.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOOL\n",
    "- **Tool: 하나의 기능을 처리하는 함수.**\n",
    "    - Tool: 하나의 명확한 기능을 수행하도록 정의된 함수(Function) 형태의 외부 실행 수단.\n",
    "    - 대형 언어 모델(LLM)은 본래 텍스트를 생성하는 모델이므로, 실제 계산, 검색, 파일 처리, 데이터베이스 조회와 같은 현실 세계의 작업을 직접 수행할 수는 없다. 이런 실제 작업을 대신 수행하는 단위가 Tool 이다.\n",
    "- **AI Model은 Tool을 이용해 자체 지식의 한계를 넘어서는 정보를 제공할 수 있다.**\n",
    "> **Knowledge Cutoff**:\n",
    "> - Knowledge cutoff는 AI 모델이 학습한 데이터가 마지막으로 업데이트된 시점을 의미하며, 그 이후에 발생한 정보나 사건에 대해서는 AI 모델이 학습한 지식으로는 알지 못하는 한계를 가지게 된다.\n",
    "\n",
    "## Tool Calling 개요\n",
    "- **도구 호출**(Tool Calling)은 LLM이 자체적으로 수행할 수 없는 작업을 외부 도구나 API를 활용하여 처리할 수 있게 하는 핵심 기능이다. 이를 통해 **LLM은 자체 지식의 한계를 넘어서는 최신 정보, 정확한 계산, 외부 시스템 제어 등의 능력을 확보**할 수 있다.\n",
    "\n",
    "- **도구 호출(Tool Calling)의 3단계**\n",
    "    1. 도구 바인딩 (Tool Binding): **LLM에 사용가능한 tool들을 등록한다.** \n",
    "        - LLM에게 사용 가능한 도구 목록과 각 도구의 기능(설명) 및 필요한 입력 매개변수를 미리 정의하여 제공한다.\n",
    "            - Tool 함수\n",
    "            - Tool 이름\n",
    "            - Tool이 수행하는 기능 설명\n",
    "            - 입력 파라미터 type과 설명\n",
    "    2. **사용자 질의가 들어오면 LLM이 도구 사용 여부를 판단**한다.\n",
    "        - LLM 자체 추론으로 해결가능한 문제인지 Tool을 호출해야 처리할 수있는 문제 인지를 확인한다.\n",
    "        - **Tool 사용이 필요한 문제** 라고 판단하면 \n",
    "          - 도구를 호출 하는 것이 아니라 어떻게 호출해야 하는지 요청정보를 생성한다.\n",
    "            - 어떤 Tool을 사용해야 하는지, 그 Tool에 어떤 값을 전달해야하는지를 응답으로 생성한다.\n",
    "    3.  **시스템이 Tool 호출 요청정보에 따라 Tool을 실행하고 그 결과를 LLM 에게 전달**한다.\n",
    "\n",
    "     ![toolcalling_concept](figures/toolcalling_concept.png)\n",
    "\n",
    "- **TOOL Calling 예**\n",
    "    - LLM이 수학 계산을 수행해야 할 때, 직접 계산하는 대신 미리 정의된 '계산' 도구를 호출하여 정확한 결과를 얻을 수 있다.\n",
    "  \t- LLM에 최신 정보를 요청하는 질문이 들어왔을 때 '검색' 도구나 'Database 연동' 도구를 사용해 최신 뉴스를 검색하거나, 특정 데이터베이스에서 정보를 조회하는 등의 작업을 수행할 수 있다.\n",
    "  \t- LLM 이 작성한 결과를 google docs와 같은 문서도구나 SNS에 등록한다.\n",
    "\n",
    "## Langchain 과 Tool calling\n",
    "- Tool calling은 대부분의 LLM 서비스가 지원한다.\n",
    "  - [Tool Calling을 지원하는 LLM 모델](https://docs.langchain.com/oss/python/integrations/chat)만 사용할 수 있다.\n",
    "- LangChain은 다양한 모델들의 도구 호출 방식을 표준화하여 일관된 인터페이스로 제공한다. 이를 통해 개발자들은 다양한 모델과 도구들을 쉽게 통합할 수있다.\n",
    "  - [Langchain Tool Calling Concept](https://docs.langchain.com/oss/python/langchain/tools)\n",
    "- Langchain 제공 Built-in tools\n",
    "    -  https://docs.langchain.com/oss/python/integrations/tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Built-in Tools 사용으로 Tool Calling 이해\n",
    "\n",
    "- Langchain은 다양한 도구들을 미리 구현해서 제공, builtin tool이라고 한다. \n",
    "  - [Langchain 지원 Built tools](https://docs.langchain.com/oss/python/integrations/tools)\n",
    "- Built-In tool 뿐만 아니라 사용자 정의 Tool들을 직접 구현할 수있는 방법도 제공.\n",
    "\n",
    "## Tavily API 검색 Tool\n",
    "> Tavily 웹 검색 도구 사용해 Tool calling을 이해한다.\n",
    "- **Tavily** Service: AI을 위한 웹 검색 API Service.\n",
    "- https://tavily.com/\n",
    "-  LLM과 RAG 시스템에 최적화된 검색 엔진.\n",
    "   -  기존의 일반 검색 엔진들과 달리, Tavily는 AI 애플리케이션의 요구사항에 맞춰 설계되었다.\n",
    "   -  Tavily는 최대 20개 이상의 신뢰도 높은 웹사이트에서 관련정보를 수집한다. \n",
    "   -  수집된 데이터는 AI가 관련성, 신뢰도, 최신성 등을 기준으로 평가해 가장 적합한 정보만 선별해서 요약한다. \n",
    "   -  최종적으로 이 정보는 LLM이 바로 활용할 수있도록 컨텐츠 스티펫, 요약, 출처 등의 구조화된 형태로 반환한다.\n",
    "   -  월 1000회 무료 사용 가능.\n",
    "- **Tavily API Key 받기**\n",
    "  - 회원가입 후 로그인 한다.\n",
    "  - Overview 화면에서 API Key 생성 \n",
    "    - default API key 사용할 수있다.\n",
    "  - 환경변수에 등록한다.\n",
    "      - 변수이름: `TAVILY_API_KEY`\n",
    "\n",
    "### TavilySearch\n",
    "- Langchain에서 제공하는 tool로 Tavily 의 검색 엔진 API를 사용해 검색을 수행한다.\n",
    "- 설치\n",
    "  - `pip install langchain-tavily`\n",
    "- https://python.langchain.com/docs/integrations/tools/tavily_search/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_tavily import TavilySearch     # Tavily 검색 tool\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성 - 검색 옵션을 파라미터로 설정\n",
    "tavily_search = TavilySearch(\n",
    "    max_results=3,          # 최대 검색 개수\n",
    "    # include_raw_content = True,   # 원본 내용도 포함.\n",
    "    # include_answer=True,    # 검색 결과를 바탕으로 Tavily AI가 종합적 답변을 하도록 한다.\n",
    "    # include_images=True,    # 검색한 문서 내의 이미지 (경로)들을 반환.\n",
    "    # time_range=\"year\",      # day, week, month, year - 현재 시점 기준으로 지정한 기간 내의 문서들만 검색 결과로 제공.\n",
    ")\n",
    "# 검색\n",
    "query = \"2025년 한국 시리즈 우승팀은?\"\n",
    "# result = tavily_search.invoke(query)\n",
    "result = tavily_search.invoke(\n",
    "    {\n",
    "        \"query\":query,\n",
    "        \"include_image\": True    # 옵션들을 \"key\" : value로 설정해서 실행 시 동적으로 설정.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': '2025년 한국 시리즈 우승팀은?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.chosun.com/sports/baseball/2025/10/31/MQMV676MQJHLNGD7JEIAKWFMEQ/',\n",
       "   'title': 'LG, 한화 꺾고 2년 만에 한국시리즈 우승 - 조선일보',\n",
       "   'content': '2025 KBO(한국야구위원회)리그 최강자가 가려졌다. 2023시즌 29년만의 통합우승을 이뤄낸 LG가 2시즌 만에 정규시즌과 한국시리즈 우승을 모두 탈환, 한국',\n",
       "   'score': 0.9996567,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.instagram.com/p/DQefaPkEwxQ/',\n",
       "   'title': \"'돌아온 챔피언', 서울 LG트윈스 2025시즌 한국시리즈 ... - Instagram\",\n",
       "   'content': 'LG 트윈스(@lgtwinsbaseballclub)가 2025 KBO 한국시리즈에서 우승을 차지했습니다. LG는 정규 시즌에서도 우승을 차지해 2025 KBO 통합 우승을 달성',\n",
       "   'score': 0.9996018,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.facebook.com/kbo1982/posts/2025-kbo-%ED%95%9C%EA%B5%AD%EC%8B%9C%EB%A6%AC%EC%A6%88-%EC%9A%B0%EC%8A%B9-lg%ED%8A%B8%EC%9C%88%EC%8A%A4%EC%9E%85%EB%8B%88%EB%8B%A41031-lg%ED%95%9C%ED%99%94%EC%95%BC%EA%B5%AC-baseball-kbo-%ED%8F%AC%EC%8A%A4%ED%8A%B8%EC%8B%9C%EC%A6%8C-%ED%95%9C%EA%B5%AD%EC%8B%9C%EB%A6%AC%EC%A6%88_5%EC%B0%A8%EC%A0%84-lg%ED%8A%B8%EC%9C%88%EC%8A%A4-%EC%9A%B0%EC%8A%B9-kbo2/1315789490588357/',\n",
       "   'title': '2025 KBO 한국시리즈 우승! LG트윈스입니다!(10.31. LG:한화) #야구 ...',\n",
       "   'content': '2025 KBO 한국시리즈 우승! LG트윈스입니다!(10.31. LG: 한화) #야구 #baseball #KBO #포스트시즌 #한국시리즈_5차전 #LG트윈스 #우승 #kbo20251031.',\n",
       "   'score': 0.99955577,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.57,\n",
       " 'request_id': 'e61bd9d9-3fb7-4f87-b09d-58727a1be4fd'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도구 이름 tavily_search\n",
      "도구 설명:\n",
      "A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "# 도구 - 도구 이름, 도구 설명 ==> llm이 도구 사용 여부를 판단할 때 근거.\n",
    "# Tavily (built-in) 도구 정보를 확인\n",
    "###########################################################\n",
    "print(\"도구 이름\", tavily_search.name)\n",
    "print(\"도구 설명:\")\n",
    "print(tavily_search.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additionalProperties': True,\n",
       " 'description': 'Input for [TavilySearch]',\n",
       " 'properties': {'query': {'description': 'Search query to look up',\n",
       "   'title': 'Query',\n",
       "   'type': 'string'},\n",
       "  'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "    {'type': 'null'}],\n",
       "   'default': [],\n",
       "   'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        ',\n",
       "   'title': 'Include Domains'},\n",
       "  'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "    {'type': 'null'}],\n",
       "   'default': [],\n",
       "   'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        ',\n",
       "   'title': 'Exclude Domains'},\n",
       "  'search_depth': {'anyOf': [{'enum': ['basic',\n",
       "      'advanced',\n",
       "      'fast',\n",
       "      'ultra-fast'],\n",
       "     'type': 'string'},\n",
       "    {'type': 'null'}],\n",
       "   'default': 'basic',\n",
       "   'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        \\n        Use \"fast\" for optimized low latency with high relevance.\\n        \\n        Use \"ultra-fast\" when latency is prioritized above all else.\\n        ',\n",
       "   'title': 'Search Depth'},\n",
       "  'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "   'default': False,\n",
       "   'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        ',\n",
       "   'title': 'Include Images'},\n",
       "  'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'],\n",
       "     'type': 'string'},\n",
       "    {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        ',\n",
       "   'title': 'Time Range'},\n",
       "  'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'],\n",
       "     'type': 'string'},\n",
       "    {'type': 'null'}],\n",
       "   'default': 'general',\n",
       "   'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        ',\n",
       "   'title': 'Topic'},\n",
       "  'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        ',\n",
       "   'title': 'Start Date'},\n",
       "  'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "   'default': None,\n",
       "   'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        ',\n",
       "   'title': 'End Date'}},\n",
       " 'required': ['query'],\n",
       " 'title': 'TavilySearchInput',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = tavily_search.args_schema.model_json_schema()\n",
    "schema\n",
    "# 도구 스키마\n",
    "## 도구 호출 시 전달 파라미터 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'Search query to look up',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'},\n",
       " 'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "   {'type': 'null'}],\n",
       "  'default': [],\n",
       "  'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        ',\n",
       "  'title': 'Include Domains'},\n",
       " 'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'},\n",
       "   {'type': 'null'}],\n",
       "  'default': [],\n",
       "  'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        ',\n",
       "  'title': 'Exclude Domains'},\n",
       " 'search_depth': {'anyOf': [{'enum': ['basic',\n",
       "     'advanced',\n",
       "     'fast',\n",
       "     'ultra-fast'],\n",
       "    'type': 'string'},\n",
       "   {'type': 'null'}],\n",
       "  'default': 'basic',\n",
       "  'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        \\n        Use \"fast\" for optimized low latency with high relevance.\\n        \\n        Use \"ultra-fast\" when latency is prioritized above all else.\\n        ',\n",
       "  'title': 'Search Depth'},\n",
       " 'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}],\n",
       "  'default': False,\n",
       "  'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        ',\n",
       "  'title': 'Include Images'},\n",
       " 'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'],\n",
       "    'type': 'string'},\n",
       "   {'type': 'null'}],\n",
       "  'default': None,\n",
       "  'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        ',\n",
       "  'title': 'Time Range'},\n",
       " 'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'],\n",
       "    'type': 'string'},\n",
       "   {'type': 'null'}],\n",
       "  'default': 'general',\n",
       "  'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        ',\n",
       "  'title': 'Topic'},\n",
       " 'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "  'default': None,\n",
       "  'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        ',\n",
       "  'title': 'Start Date'},\n",
       " 'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
       "  'default': None,\n",
       "  'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        ',\n",
       "  'title': 'End Date'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM ToolCalling 흐름\n",
    "\n",
    "### 1. Tool 생성 및 LLM Model에 tool binding\n",
    "- `LLM-Model.bind_tools(tools=[tool_1, tool_2, ...])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableBinding'> <class 'langchain_openai.chat_models.base.ChatOpenAI'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tavily_search = TavilySearch(max_results=5)\n",
    "model = ChatOpenAI(model=\"gpt-5-mini\")   # 뇌 -> 성능 좋은 모델을 사용 (판단자.)\n",
    "toolkit = [tavily_search]  # 툴들 모음\n",
    "# model에 tool들을 binding\n",
    "tool_model = model.bind_tools(tools=toolkit)\n",
    "print(type(tool_model), type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 호출 결과 (AIMessage)로 사용자에게 응답을 할지, tool을 호출할지 결정\n",
    "## tool_calls \n",
    "## tool_calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문에 따른 응답 차이\n",
    "## tool이 필요없는 질문\n",
    "## content = \"답변 내용\"\n",
    "## tool_calls = []  # 빈 리스트\n",
    "result = tool_model.invoke(\"안녕하세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 만나서 반갑습니다. 무엇을 도와드릴까요?\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(result.content)   # LLM의 응답\n",
    "print(result.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tool이 필요한 질문\n",
    "# 답변: content=\"\", tool_calls = list[dictionary - 호출 방식]\n",
    "result2 = tool_model.invoke(\"2025년 12월 30일 서울 날씨는 어때?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 314, 'prompt_tokens': 1284, 'total_tokens': 1598, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CsjoyvXitxwaSv3XMpyLPiy3jctIJ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b730e-6b3d-7093-ba2f-9e7e5edab2dd-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': '2025년 12월 30일 서울 날씨 관측 기상청 서울 2025-12-30', 'search_depth': 'advanced', 'topic': 'news'}, 'id': 'call_udHEYwwyfwOkysspVQr03awA', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1284, 'output_tokens': 314, 'total_tokens': 1598, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답 메세지: \n",
      "tool calls:  [{'name': 'tavily_search', 'args': {'query': '2025년 12월 30일 서울 날씨 관측 기상청 서울 2025-12-30', 'search_depth': 'advanced', 'topic': 'news'}, 'id': 'call_udHEYwwyfwOkysspVQr03awA', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "# vars(result2) # vars(객체) -> 객체의 속성들을 dictionary로 반환. \n",
    "print(\"응답 메세지:\", result2.content)  # \"\"\n",
    "print(\"tool calls: \", result2.tool_calls)  # list[dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tool 호출\n",
    "- LLM 모델이 tool 요청을 결정한 경우 **어떤 tool을 어떻게 호출할 지** AIMessage의 `tool_calls` 속성에 넣어 반환한다.\n",
    "- `tool_calls` 의 호출 정보를 넣어 `tool.invoke()` 호출한다.\n",
    "   - `tool.invoke(result.tool_calls[0])`\n",
    "   - **반환타입**: `ToolMessage`\n",
    "     - Tool의 처리결과를 담는 Message Type 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 응답 (AIMessage)에 tool_calls가 있을 경우 Tool을 호출\n",
    "search_result = tavily_search.invoke(result2.tool_calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"query\": \"2025년 12월 30일 서울 날씨 관측 기상청 서울 2025-12-30\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.cbsnews.com/minnesota/video/4-p-m-minnesota-forecast-from-dec-30-2025-next-weather/\", \"title\": \"4 p.m. Minnesota forecast from Dec. 30, 2025 | NEXT Weather - CBS News\", \"score\": 0.70578504, \"published_date\": \"Tue, 30 Dec 2025 22:21:00 GMT\", \"content\": \"from Dec. 28, 2025 03:01 Dec 28, 2025 [...] 08:13 Dec 13, 2025 [...] The roads should be fine for New Year’s Eve plans, but it will be cold, WCCO meteorologist Mike Augustyniak reports.17m ago\\\\n\\\\n   Twitter\\\\n   Facebook\\\\n   Email\\\\n   Embed  embed code copied  \\\\n\\\\nLive Now\", \"raw_content\": null}, {\"url\": \"https://www.cbsnews.com/minnesota/video/with-twin-cities-roads-icy-after-winter-blast-repair-shops-are-slammed/\", \"title\": \"With Twin Cities roads icy after winter blast, repair shops are slammed - CBS News\", \"score\": 0.44360042, \"published_date\": \"Tue, 30 Dec 2025 18:20:00 GMT\", \"content\": \"27, 2025 ### NEXT WEATHER | Saturday morning forecast for Dec. 27, 2025 04:03 Dec 27, 2025 [...] patient on Christmas has died, officials say ### Hospital security guard attacked by a patient on Christmas has died, officials say 02:08 Dec 28, 2025Image 65: NEXT Weather: 7:30 a.m. forecast from Dec. 28, 2025 ### NEXT Weather: 7:30 a.m. forecast from Dec. 28, 2025 03:01 Dec 28, 2025Image 66: NEXT WEATHER | 6 p.m. weather report for Saturday Dec. 27, 2025 ### NEXT WEATHER | 6 p.m. weather report for Saturday Dec. 27, 2025 04:09 Dec 28, 2025Image 67: Winter sports lovers are excited about a [...] 30, 2025 | NEXT Weather ### 9 a.m. Minnesota forecast from Dec. 30, 2025 | NEXT Weather 03:50 3h agoImage 30: 4 things to know from Dec. 30, 2025 ### 4 things to know from Dec. 30, 2025 01:14 5h agoImage 31: NEXT Weather: 6:30 a.m. report for Minnesota from Dec. 30, 2025 ### NEXT Weather: 6:30 a.m. report for Minnesota from Dec. 30, 2025 02:10 5h agoImage 32: More fallout from fraud in Minnesota, and more headlines ### More fallout from fraud in Minnesota, and more headlines 04:22 6h agoImage\", \"raw_content\": null}, {\"url\": \"https://www.cbsnews.com/minnesota/video/more-americans-auto-loans-are-worth-more-than-the-value-of-their-cars/\", \"title\": \"More Americans\\' auto loans are worth more than the value of their cars - CBS News\", \"score\": 0.067546695, \"published_date\": \"Tue, 30 Dec 2025 18:59:00 GMT\", \"content\": \"security guard attacked by a patient on Christmas has died, officials say 02:08 Dec 28, 2025Image 68: NEXT Weather: 7:30 a.m. forecast from Dec. 28, 2025 ### NEXT Weather: 7:30 a.m. forecast from Dec. 28, 2025 03:01 Dec 28, 2025Image 69: NEXT WEATHER | 6 p.m. weather report for Saturday Dec. 27, 2025 ### NEXT WEATHER | 6 p.m. weather report for Saturday Dec. 27, 2025 04:09 Dec 28, 2025Image 70: Winter sports lovers are excited about a snowier winter ahead ### Winter sports lovers are excited [...] 9 a.m. forecast for Minnesota from Dec. 29, 2025 | NEXT Weather ### 9 a.m. forecast for Minnesota from Dec. 29, 2025 | NEXT Weather 04:07 Dec 29, 2025Image 60: Snowstorm fallout snarls travel, and more headlines ### Snowstorm fallout snarls travel, and more headlines 05:34 Dec 29, 2025Image 61: Holiday travelers encountering headaches at MSP Airport amid winter storm disruptions ### Holiday travelers encountering headaches at MSP Airport amid winter storm disruptions 02:11 Dec 29, 2025Image 62: [...] from Dec. 30, 2025 | NEXT Weather 03:50 3h agoImage 33: 4 things to know from Dec. 30, 2025 ### 4 things to know from Dec. 30, 2025 01:14 6h agoImage 34: NEXT Weather: 6:30 a.m. report for Minnesota from Dec. 30, 2025 ### NEXT Weather: 6:30 a.m. report for Minnesota from Dec. 30, 2025 02:10 6h agoImage 35: More fallout from fraud in Minnesota, and more headlines ### More fallout from fraud in Minnesota, and more headlines 04:22 7h agoImage 36: NEXT Weather: 5 a.m. report for Minnesota from Dec.\", \"raw_content\": null}, {\"url\": \"https://www.cbsnews.com/philadelphia/video/watch-for-black-ice-as-the-philadelphia-area-will-be-mostly-cloudy-cold-heading-into-sunday/\", \"title\": \"Watch for black ice as the Philadelphia area will be mostly cloudy, cold heading into Sunday - CBS News\", \"score\": 0.06233104, \"published_date\": \"Sun, 28 Dec 2025 04:49:00 GMT\", \"content\": \"tracking chance for rain on Christmas Day ### Warm start to winter in Philadelphia, tracking chance for rain on Christmas Day 03:24 Dec 21, 2025Image 92: Dry Sunday, followed by chilly but manageable conditions Monday ### Dry Sunday, followed by chilly but manageable conditions Monday 02:37 Dec 21, 2025Image 93: Mild week ahead, slim chance for a white Christmas ### Mild week ahead, slim chance for a white Christmas 03:49 Dec 20, 2025Image 94: Chance of rain, potential snow in Philadelphia area [...] the NEXT Weather forecast 03:33 Dec 26, 2025Image 76: How much will it snow today around the Philadelphia area? Tracking sleet, freezing rain ### How much will it snow today around the Philadelphia area? Tracking sleet, freezing rain 05:18 Dec 26, 2025Image 77: Latest snow and freezing rain totals for the Philadelphia region | NEXT Weather ### Latest snow and freezing rain totals for the Philadelphia region | NEXT Weather 03:49 Dec 26, 2025Image 78: Winter storm to bring snow, ice to [...] | NEXT Weather 03:52 Dec 23, 2025Image 86: NEXT big weather change brings snow, rain to Philadelphia area Tuesday morning ### NEXT big weather change brings snow, rain to Philadelphia area Tuesday morning 02:53 Dec 23, 2025Image 87: Wintry mix turning to rain Tuesday in Philadelphia area could make for messy travel ### Wintry mix turning to rain Tuesday in Philadelphia area could make for messy travel 02:40 Dec 23, 2025Image 88: Cold and sunny Monday in Philadelphia, overnight wintry mix to\", \"raw_content\": null}, {\"url\": \"https://www.cbsnews.com/minnesota/video/noon-minnesota-forecast-from-dec-30-2025-next-weather/\", \"title\": \"Noon Minnesota forecast from Dec. 30, 2025 | NEXT Weather - CBS News\", \"score\": 0.052618954, \"published_date\": \"Tue, 30 Dec 2025 19:05:00 GMT\", \"content\": \"Station Info\\\\n   WCCO-TV News Team\\\\n   Links & Numbers\\\\n   Contests & Promotions\\\\n   Galleries\\\\n   WCCO-TV Jobs\\\\n   Download WCCO\\'s App\\\\n   Advertise\\\\n   Memorials\\\\n\\\\n\\\\n\\\\nWatch CBS News\\\\n\\\\nImage 2\\\\n\\\\nNoon Minnesota forecast from Dec. 30, 2025 | NEXT Weather\\\\n\\\\nNew Year\\'s Eve will have falling temps with another inch of snow possible for the morning and afternoon, WCCO meteorologist Lisa Meadows reports.12m ago\\\\n\\\\n   Twitter\\\\n   Facebook\\\\n   Email\\\\n   Link  link copied [...] Noon Minnesota forecast from Dec. 30, 2025 | NEXT Weather - CBS Minnesota\\\\n\\\\n\\\\n\\\\n   Minnesota\\\\n   |\\\\n   News\\\\n   Weather\\\\n   Sports\\\\n   Video\\\\n   WCCO Shows & Specials\\\\n\\\\nImage 1 21°\\\\n\\\\n   All News\\\\n   Twin Cities News\\\\n   Greater Minnesota News\\\\n   Wisconsin News\\\\n   WCCO Investigates\\\\n   Community Journalism\\\\n   Politics\\\\n   Immigration\\\\n   Crime\\\\n   Health\\\\n   Your Money\\\\n   Good Question\\\\n   Finding Minnesota\\\\n\\\\n   NEXT Weather\\\\n   Live Radar\\\\n   Closings & Delays\\\\n   Weather Watcher Network [...] ©2025 CBS Broadcasting Inc. All Rights Reserved.\\\\n\\\\nView CBS News In\\\\n\\\\nCBS News AppOpen\\\\n\\\\nChrome SafariContinue\\\\n\\\\nYour Privacy Choices\", \"raw_content\": null}], \"response_time\": 0.86, \"request_id\": \"429cca4f-ceac-44e6-8c7d-08112cf3a632\"}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tool_call 이 여러 개일 경우 \n",
    "- 질의에 대해 tool을 여러번 호출 해야 하는 경우 tool_calling 정보를 여러개 반환할 수 있다.\n",
    "    - 예) 검색할 키워드가 여러개인 경우. \n",
    "- `tool.batch([tool_call1, tool_call2, ..])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='죄송하지만 저는 실시간 정보에 접근할 수 없고 지식이 2024년 6월까지만 업데이트되어 있어서 2025년 KBO·MLB·NPB 챔피언이 누구인지 알려드릴 수 없습니다.\\n\\n원하시면 다음 중 하나를 도와드릴 수 있습니다.\\n- 지금 바로 2025 우승팀을 인터넷에서 찾아드리기(원하시면 사용 가능한 웹사이트·검색어를 알려드립니다).\\n- 2025 시즌 우승팀에 대한 예측(각 리그의 유력 후보와 근거를 바탕으로 전망을 드립니다).\\n- 과거(예: 2023년까지)의 각 리그 우승팀과 간단한 배경 정보 제공.\\n\\n직접 확인하시려면 다음 공식/신뢰할 만한 곳을 참고하세요.\\n- KBO: KBO 공식 홈페이지(koreabaseball.com) 또는 주요 한국 스포츠 뉴스(네이버 스포츠, 다음 스포츠, 연합뉴스 등)\\n- MLB: MLB.com 또는 ESPN, Baseball-Reference\\n- NPB: NPB 공식 홈페이지(npb.jp) 또는 일본 주요 매체(야후재팬 스포츠 등)\\n검색어 예: “2025 KBO 챔피언”, “2025 World Series winner”, “2025 NPB Japan Series champion”\\n\\n어떤 것을 도와드릴까요 — 즉시 확인 방법을 알려드릴까요, 아니면 우승 예측을 원하시나요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 889, 'prompt_tokens': 26, 'total_tokens': 915, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 576, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Csjp4TMBBLfgUbZ1KgYodmRaUngbE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b730e-8455-77f3-b561-ab2d658a5478-0', usage_metadata={'input_tokens': 26, 'output_tokens': 889, 'total_tokens': 915, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 576}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### tool call이 여러 개인 경우.\n",
    "\n",
    "query = \"2025년 KBO, MLB, NPB 리그의 우승팀을 알려줘.\"\n",
    "model.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"2025년 KBO, MLB, NPB 리그의 우승팀을 알려줘.\"\n",
    "result = tool_model.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search',\n",
       "  'args': {'query': '2025 KBO 한국시리즈 우승 2025년 KBO 챔피언',\n",
       "   'search_depth': 'advanced',\n",
       "   'topic': 'general',\n",
       "   'include_images': False},\n",
       "  'id': 'call_dkZygHtOdZOieIWFmLMh8Zgv',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'tavily_search',\n",
       "  'args': {'query': '2025 MLB World Series champion 2025 World Series winner',\n",
       "   'search_depth': 'advanced',\n",
       "   'topic': 'general',\n",
       "   'include_images': False},\n",
       "  'id': 'call_DiAwln4wvtilHtRddM4wMVac',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'tavily_search',\n",
       "  'args': {'query': '2025 NPB 日本シリーズ 優勝 2025年 日本シリーズ 優勝チーム',\n",
       "   'search_depth': 'advanced',\n",
       "   'topic': 'general',\n",
       "   'include_images': False},\n",
       "  'id': 'call_SGrg6r78TKIBY0cMvwjdg7sy',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tool_call in result.tool_calls: # LLM이 여러 개의 툴을 가지고 있을 경우 반복문을 실행해라.\n",
    "#     tool_call.name => 호출할 툴 이름 조회\n",
    "#     tool.invoke(tool_call)\n",
    "\n",
    "# Runnable: invoke()/stream() - 개별 요청, batch(): 한 번에 여러 개 요청\n",
    "search_result_list = tavily_search.batch(result.tool_calls)   # [toolcall, toolcall, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolMessage(content='{\"query\": \"2025 KBO 한국시리즈 우승 2025년 KBO 챔피언\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"2025년 한국시리즈 - 위키백과, 우리 모두의 백과사전\", \"url\": \"https://ko.wikipedia.org/wiki/2025년_한국시리즈\", \"content\": \"2025 신한 SOL Bank KBO 한국시리즈는 2025년 10월 26일부터 10월 31일까지 펼쳐진 2025년 KBO 리그의 챔피언 결정전이다. 대진은 2025년 KBO 리그 정규 시즌 1위 팀으로 2023년 한국시리즈 이후 2년만에 한국시리즈 직행에 성공하며 이번 시즌 통합 우승이자 통산 4번째 우승에 도전하는 LG 트윈스와 정규시즌 2위이자 플레이오프 승리팀으로 2006년 한국시리즈 이후 19년만에 한국시리즈에 진출해 통산 2번째 우승에 도전하는 한화 이글스가 맞붙었다. 두 팀의 한국시리즈 맞대결은 이번 포스트시즌 역사상 첫 맞대결이었다.\\\\n\\\\n결과는 LG 트윈스가 시리즈 전적 4승 1패로 2023년 한국시리즈 이후 2년 만의 통합 우승을 이뤄내면서 팀 통산 4번째 우승을 기록했다. 한국시리즈 MVP는 시리즈 기간 17타수 9안타 8타점을 기록, 기자단 투표 89표 중 61를 득표한 LG 트윈스의 외야수 김현수 \\\\\"김현수 (1988년생 야구 선수)\\\\\")가 차지했다. [...] | 2025년 한국시리즈 |\\\\n| |  |  |  --- | |  |  | |\\\\n| |  |  |  --- | | 팀 | 승(무승부) | | LG 트윈스 | 4 | | 한화 이글스 | 1 | |\\\\n| 경기 정보 |\\\\n| 경기 일정 | 2025년 10월 26일 ~ 10월 31일 |\\\\n| MVP | 김현수 \\\\\"김현수 (1988년생 야구 선수)\\\\\") |\\\\n| 팀 정보 |\\\\n| LG 트윈스 |\\\\n| 감독 | 염경엽 |\\\\n| 시즌 성적 | 85승 3무 56패 (정규시즌 1위) |\\\\n| 한화 이글스 |\\\\n| 감독 | 김경문 |\\\\n| 시즌 성적 | 83승 4무 57패 (정규시즌 2위) |\\\\n| |  |  |  --- | | < 2024 |  | | [...] ## KBO 포스트시즌 대진표\\\\n\\\\n[편집]\\\\n\\\\n이 부분의 본문은 2025년 KBO 포스트시즌입니다.\\\\n\\\\n|  |  |  |  |  |  |  |  |  |  |  |\\\\n ---  ---  ---  ---  --- \\\\n|  | 와일드카드 결정전 |  |  | 준플레이오프 |  |  | 플레이오프 |  |  | 한국시리즈 |\\\\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\\\\n|  |  | 1 | LG 트윈스 | 4 |\\\\n|  |  | 2 | 한화 이글스 | 3 |  |  | 2 | 한화 이글스 | 1 |\\\\n|  |  | 3 | SSG 랜더스 | 1 |  |  | 4 | 삼성 라이온즈 | 2 |  |\\\\n|  | 4 | 삼성 라이온즈 | 1 |  |  | 4 | 삼성 라이온즈 | 3 |  |\\\\n|  | 5 | NC 다이노스 | 1 |  |\\\\n\\\\n### 와일드카드 결정전\\\\n\\\\n[편집]\", \"score\": 0.9184877, \"raw_content\": null}, {\"url\": \"https://ko.wikipedia.org/wiki/2025%EB%85%84_%ED%95%9C%EA%B5%AD%EC%8B%9C%EB%A6%AC%EC%A6%88\", \"title\": \"2025년 한국시리즈\", \"content\": \"2025 신한 SOL Bank KBO 한국시리즈는 2025년 10월 26일부터 10월 31일까지 펼쳐진 2025년 KBO 리그의 챔피언 결정전이다. 대진은 2025년 KBO 리그 정규 시즌 1위 팀으로 2023년 한국시리즈 이후 2년만에 한국시리즈 직행에 성공하며 이번 시즌 통합 우승이자 통산 4번째 우승에 도전하는 LG 트윈스와 정규시즌 2위이자 플레이오프 승리팀으로 2006년 한국시리즈 이후 19년만에 한국시리즈에 진출해 통산 2번째 우승에 도전하는 한화 이글스가 맞붙었다. 두 팀의 한국시리즈 맞대결은 이번 포스트시즌 역사상 첫 맞대결이었다.\\\\n\\\\n결과는 LG 트윈스가 시리즈 전적 4승 1패로 2023년 한국시리즈 이후 2년 만의 통합 우승을 이뤄내면서 팀 통산 4번째 우승을 기록했다. 한국시리즈 MVP는 시리즈 기간 17타수 9안타 8타점을 기록, 기자단 투표 89표 중 61를 득표한 LG 트윈스의 외야수 김현수 \\\\\"김현수 (1988년생 야구 선수)\\\\\")가 차지했다. [...] | 2025년 한국시리즈 |\\\\n| |  |  |  --- | |  |  | |\\\\n| |  |  |  --- | | 팀 | 승(무승부) | | LG 트윈스 | 4 | | 한화 이글스 | 1 | |\\\\n| 경기 정보 |\\\\n| 경기 일정 | 2025년 10월 26일 ~ 10월 31일 |\\\\n| MVP | 김현수 \\\\\"김현수 (1988년생 야구 선수)\\\\\") |\\\\n| 팀 정보 |\\\\n| LG 트윈스 |\\\\n| 감독 | 염경엽 |\\\\n| 시즌 성적 | 85승 3무 56패 (정규시즌 1위) |\\\\n| 한화 이글스 |\\\\n| 감독 | 김경문 |\\\\n| 시즌 성적 | 83승 4무 57패 (정규시즌 2위) |\\\\n| |  |  |  --- | | < 2024 |  | | [...] ## KBO 포스트시즌 대진표\\\\n\\\\n[편집]\\\\n\\\\n이 부분의 본문은 2025년 KBO 포스트시즌입니다.\\\\n\\\\n|  |  |  |  |  |  |  |  |  |  |  |\\\\n ---  ---  ---  ---  --- \\\\n|  | 와일드카드 결정전 |  |  | 준플레이오프 |  |  | 플레이오프 |  |  | 한국시리즈 |\\\\n|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\\\\n|  |  | 1 | LG 트윈스 | 4 |\\\\n|  |  | 2 | 한화 이글스 | 3 |  |  | 2 | 한화 이글스 | 1 |\\\\n|  |  | 3 | SSG 랜더스 | 1 |  |  | 4 | 삼성 라이온즈 | 2 |  |\\\\n|  | 4 | 삼성 라이온즈 | 1 |  |  | 4 | 삼성 라이온즈 | 3 |  |\\\\n|  | 5 | NC 다이노스 | 1 |  |\\\\n\\\\n### 와일드카드 결정전\\\\n\\\\n[편집]\", \"score\": 0.91563576, \"raw_content\": null}, {\"url\": \"https://www.dkilbo.com/news/articleView.html?idxno=520191\", \"title\": \"LG 트윈스, 2025 KBO 프로야구 한국시리즈 우승\", \"content\": \"## 상단영역\\\\n\\\\n최종편집 : 2025-11-05 12:22 (수)\\\\n\\\\n로그인 회원가입 제보 facebook blog instagram\\\\n\\\\n## 본문영역\\\\n\\\\nLG 트윈스, 2025 KBO 프로야구 한국시리즈 우승\\\\n\\\\n스크롤 이동 상태바\\\\n\\\\n### LG 트윈스, 2025 KBO 프로야구 한국시리즈 우승\\\\n\\\\n 기자명 김민지 기자\\\\n 입력 2025.10.31 21:37\\\\n 수정 2025.10.31 22:17\\\\n 댓글 0\\\\n\\\\n#### 정규리그 1위 이어 통합우승 2년 만에 다시 챔피언 왕좌 탈환\\\\n\\\\nLG 트윈스가 2년 만에 다시 한국시리즈 챔피언 자리에 올랐다.\\\\n\\\\nLG는 31일 대전 한화생명 볼파크에서 열린 2025 신한 SOL뱅크 KBO 한국시리즈 5차전에서 한화 이글스를 4-1로 제압했다.\\\\n\\\\n잠실에서 열린 1, 2차전을 모두 이긴 뒤 대전 원정으로 장소를 옮긴 LG는 4, 5차전까지 연승을 이어가며 시리즈 전적 4승 1패로 우승을 확정했다. [...] 이로써 2023년에 이어 2년 만에 정규시즌과 한국시리즈를 동시에 제패하는 ‘통합 챔피언’의 위업을 달성했다.\\\\n\\\\n이날 LG는 초반부터 분위기를 잡았다. 1회초 1사 후 신민재가 2루타로 포문을 열고 김현수가 좌전 안타를 이어가며 손쉽게 선취점을 만들었다.\\\\n\\\\n한화도 곧장 맞불을 놨다. 2회말 노시환의 안타, 하주석의 2루타, 최재훈의 볼넷으로 1사 만루를 만든 뒤 이원석의 내야 땅볼로 1-1을 만들었다. 그러나 이어진 2사 2, 3루에서 심우준이 포수 앞 땅볼로 물러나 역전엔 실패했다.\\\\n\\\\n선발 문동주가 1이닝만에 강판된 한화는 불펜을 총동원했지만 매회 위기를 맞았다. 3회초 LG는 신민재의 안타와 볼넷 두 개로 무사 만루를 만들고 오지환의 희생플라이로 다시 앞서갔다. 4회와 5회 연속 기회를 놓친 LG는 6회초 홍창기의 몸에 맞는 공으로 다시 흐름을 잡았다. [...] 신민재의 희생번트로 만든 1사 2루에서 김현수가 좌중간을 가르는 적시타를 날려 점수를 3-1로 벌렸다. 경기 흐름은 그 순간 완전히 LG 쪽으로 기울었다.\\\\n\\\\n한화는 류현진을 포함해 무려 7명의 투수를 마운드에 올리며 끝까지 추격의 끈을 놓지 않았지만, 득점권에서 잇따른 병살타로 스스로 찬스를 날렸다. 7회 하주석, 8회 손아섭의 병살타가 결정적이었다.\\\\n\\\\n9회초 LG는 1사 만루에서 홍창기의 외야 희생플라이로 쐐기점을 뽑으며 4-1로 승부를 갈랐다.\\\\n\\\\nLG 선발 앤더스 톨허스트는 7이닝 1실점으로 다시 한 번 완벽한 투구를 선보였다. 피안타 4개, 사사구 2개, 삼진 5개로 시리즈 2승을 챙겼다. 타선에서는 신민재·김현수·구본혁이 나란히 3안타를 몰아쳤고, 김현수는 2타점을 기록하며 MVP급 활약을 펼쳤다.\\\\n\\\\n이번 우승은 LG 구단 역사상 네 번째 한국시리즈 정상이다. 1990년, 1994년, 2023년에 이어 2025년 다시 한 번 왕좌를 되찾았다.\", \"score\": 0.90830135, \"raw_content\": null}, {\"url\": \"https://www.chosun.com/sports/baseball/2025/10/31/MQMV676MQJHLNGD7JEIAKWFMEQ/\", \"title\": \"LG, 한화 꺾고 2년 만에 한국시리즈 우승\", \"content\": \"스포츠야구\\\\n\\\\n대전=배준용 기자\\\\n\\\\n대전=강우석 기자\\\\n\\\\n입력 2025.10.31. 21:37업데이트 2025.11.03. 09:48\\\\n\\\\n26\\\\n\\\\n26\\\\n\\\\n2025 KBO(한국야구위원회)리그 최강자가 가려졌다. 2023시즌 29년만의 통합우승을 이뤄낸 LG가 2시즌 만에 정규시즌과 한국시리즈 우승을 모두 탈환, 한국 프로야구 최정상에 다시 섰다.\\\\n\\\\nLG는 31일 대전 한화생명볼파크에서 열린 한국시리즈 5차전에서 외인 선발 앤더슨 톨허스트의 눈부신 호투와 3안타 2타점을 몰아친 김현수의 활약으로 한화에 4대1 완승을 거두며 시리즈 전적 4승1패로 2025시즌 통합 챔피언에 등극했다. [...] 9회말 LG 마무리 유영찬이 마운드에 올랐다. 선두타자 리베라토를 3루수 플라이로 잡아냈다. 문현빈이 친 타구도 높게 솟으며 중견수 플라이가 됐다. 2사에 노시환이 좌전 안타로 출루했지만 이어진 채은성의 타구가 3루수 앞으로 힘없이 흘렀다. 유영찬이 이 타구를 재빨리 잡아 1루에 던졌고, 3아웃이 되면서 2025 한국 시리즈는 LG의 통합우승으로 대단원의 막을 내렸다. 5차전 MVP는 선발 투수로 완벽투를 펼친 톨허스트, 2025 한국시리즈 MVP는 지난 4차전 9회말 2사에 역전 적시 2루타를 포함 17타수 9안타(타율 0.529) 1홈런 8타점을 몰아친 김현수다.\\\\n\\\\n전문가 대부분은 올 시즌 후반기부터 가장 강력한 우승 후보로 LG를 꼽아왔다. 강팀의 기본 조건이라고 할 수 있는 투수력과 수비가 탁월하고 타선의 조화에 선수단의 뎁스까지 갖췄다는 게 지배적인 평가였다. 결국 정규시즌 우승에 이어 한국시리즈 우승까지 차지하며 ‘무적 LG’를 실력으로 입증했다.\", \"score\": 0.86441374, \"raw_content\": null}, {\"url\": \"https://www.threads.com/@kbo.official/post/DQeeog2k8UB/2025-kbo-%EB%A6%AC%EA%B7%B8-%ED%86%B5%ED%95%A9-%EC%B1%94%ED%94%BC%EC%96%B8-lg%ED%8A%B8%EC%9C%88%EC%8A%A42025-kbo-%EB%A6%AC%EA%B7%B8-%ED%86%B5%ED%95%A9-%EC%9A%B0%EC%8A%B9%EC%9D%98-%EC%A3%BC%EC%9D%B8%EA%B3%B5%EC%9D%80-lg%ED%8A%B8%EC%9C%88%EC%8A%A4%EC%9E%85%EB%8B%88%EB%8B%A42023-%ED%86%B5%ED%95%A9-%EC%9A%B0%EC%8A%B9%EC%97%90-%EC%9D%B4%EC%96%B4-2%EB%85%84-%EB%A7%8C%EC%97%90-lg%ED%8A%B8\", \"title\": \"[2025 KBO 리그 통합 챔피언] LG트윈스\", \"content\": \"# Thread\\\\n\\\\n2.2K views\\\\n\\\\nkbo.official\\\\n\\\\n[2025 KBO 리그 통합 챔피언] LG트윈스2025 KBO 리그 통합 우승의 주인공은 LG트윈스입니다!2023 통합 우승에 이어 2년 만에 LG트윈스가 다시 한 번 왕좌의 자리에 오릅니다!정규시즌부터 이어진 막강한 전력,\\\\n추운 가을 응원석을 뜨겁게 녹인 팬들이 모여\\\\n2025년 가을, 다시 한 번 트윈스의 시대를 열었습니다!2025년 KBO 리그를 정복하며, V4를 달성한 LG트윈스의 통합 우승을 축하드립니다!#야구 #baseball #KBO #KBO리그 #포스트시즌 #가을야구 #한국시리즈 #LG #LG트윈스 #우승 #챔피언\\\\n\\\\n149\\\\n\\\\n8\\\\n\\\\n9\\\\n\\\\n1\\\\n\\\\nnam\\\\\\\\_sun\\\\\\\\_2\\\\n\\\\n크으 행복합니다 무적엘지\\\\n\\\\nTranslate\\\\n\\\\n1\\\\n\\\\nsem1863\\\\n\\\\n스친 엘지야?? 우리도야 ㅋㅋㅋ\\\\n\\\\nTranslate\\\\n\\\\n1\\\\n\\\\n1\\\\n\\\\nnam\\\\\\\\_sun\\\\\\\\_2\\\\n\\\\n나 완전 엘지야 ㅋㅋㅋ 그래서 어제 우승파티도 다녀왔엉 ㅋㅋㅋㅋ\\\\n\\\\nTranslate\\\\n\\\\n1\", \"score\": 0.8573986, \"raw_content\": null}], \"response_time\": 6.65, \"request_id\": \"1cf13d48-0906-4e04-b53a-1b34dabcc8b5\"}', name='tavily_search', tool_call_id='call_dkZygHtOdZOieIWFmLMh8Zgv'),\n",
       " ToolMessage(content='{\"query\": \"2025 MLB World Series champion 2025 World Series winner\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://en.wikipedia.org/wiki/2025_World_Series\", \"title\": \"2025 World Series\", \"content\": \"The 2025 World Series (branded as the 2025 World Series presented by Capital One) was the championship series of Major League Baseball\\'s (MLB) 2025 season. The 121st edition of the World Series was a best-of-seven playoff series between the National League \\\\\"National League (baseball)\\\\\") (NL) champion and defending World Series champion Los Angeles Dodgers and the American League (AL) champion Toronto Blue Jays. The series lasted from October 24 to November 1, with the Dodgers defeating the Blue [...] The Dodgers won their ninth World Series championship and first repeat championship in franchise history, and they became the first team since the 2000 New York Yankees and first NL team since the 1976 Cincinnati Reds to repeat as champions. The Dodgers became the eighth franchise in MLB history to win back-to-back titles, with several sports outlets beginning to refer to the Dodgers as a dynasty following the series. The Blue Jays were subsequently handed their first World Series loss in [...] The Dodgers solidified their championship roster from the previous season by adding free agents starting pitcher Blake Snell, reliever Tanner Scott, and winning the bid to sign Japanese pitcher Roki Sasaki, while also re-signing Teoscar Hernández and Blake Treinen. As heavy favorites to repeat, the Dodgers became the first defending World Series champion to begin their season 8–0, besting the previous record held by the 1933 Yankees, who started their season 7–0. The Dodgers had a 56–32 record\", \"score\": 0.99963737, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=Hgac2yzbSFM\", \"title\": \"FINAL OUTS: The Los Angeles Dodgers win the 2025 World ...\", \"content\": \"# FINAL OUTS: The Los Angeles Dodgers win the 2025 World Series after an EPIC GAME 7! 🏆\\\\n## MLB\\\\n6940000 subscribers\\\\n31349 likes\\\\n\\\\n### Description\\\\n2306864 views\\\\nPosted: 2 Nov 2025\\\\nWHAT A FINISH! The Los Angeles Dodgers are 2025 World Series champions!\\\\n\\\\nDon\\'t forget to subscribe! \\\\n\\\\nFollow us elsewhere too:\\\\nTwitter: \\\\nInstagram: \\\\nFacebook: \\\\nTikTok: \\\\n\\\\nCheck out MLB.com daily to watch the MLB.TV Free Game of the Day! \\\\n\\\\nVisit our site for all baseball news, stats and scores!\", \"score\": 0.9983516, \"raw_content\": null}, {\"url\": \"https://www.baseball-reference.com/postseason/2025_WS.shtml\", \"title\": \"2025 World Series - Los Angeles Dodgers over Toronto ...\", \"content\": \"World Series Winners, 2025 World Series: Blue Jays vs Dodgers, 2024 World Series: Yankees vs Dodgers, 2023 World Series: Rangers vs Diamondbacks, World Series Batting Leaders, World Series Pitching Leaders, ...\\\\n Stathead\\\\n\\\\n  Player Finders: Season & Career Finder, Game Finder, Streak Finder, Span Finder, Split Finder, Versus Finder, ...\\\\n\\\\n  Team Finders: Season Finder, Game Finder, Streak Finder, Span Finder, Split Finder, Event Finder, ... [...] # 2025 World Series Los Angeles Dodgers over Toronto Blue Jays (4-3)\\\\n\\\\n2024 WS\\\\n\\\\nDates: October 24 - November 1, 2025\\\\n\\\\nWS MVP: Yoshinobu Yamamoto\\\\n\\\\nNLCS MVP: Shohei Ohtani\\\\n\\\\nALCS MVP: Vladimir Guerrero Jr.\\\\n\\\\nBecome a Stathead & surf this site ad-free.\\\\n\\\\n Postseason History\\\\n More Postseason Pages\\\\n\\\\n  2025 World Series\\\\n\\\\n  ALCS\\\\n\\\\n  NLCS\\\\n\\\\n  ALDS1\\\\n\\\\n  ALDS2\\\\n\\\\n  NLDS1\\\\n\\\\n  NLDS2\\\\n\\\\n  ALWC1\\\\n\\\\n  NLWC1\\\\n\\\\n  ALWC2\\\\n\\\\n  NLWC2\\\\n 2025 World Series\\\\n ALCS\\\\n NLCS\\\\n ALDS1\\\\n ALDS2\\\\n NLDS1\\\\n NLDS2\\\\n ALWC1\\\\n NLWC1\\\\n ALWC2\\\\n NLWC2 [...] NL East: Atlanta Braves, Miami Marlins, New York Mets, Philadelphia Phillies, Washington Nationals\\\\n\\\\n  NL Central: Chicago Cubs, Cincinnati Reds, Milwaukee Brewers, Pittsburgh Pirates, St. Louis Cardinals\\\\n\\\\n  NL West: Arizona Diamondbacks, Colorado Rockies, Los Angeles Dodgers , San Diego Padres, San Francisco Giants\\\\n\\\\n  AL East: Baltimore Orioles, Boston Red Sox, New York Yankees, Tampa Bay Rays, Toronto Blue Jays\", \"score\": 0.9946568, \"raw_content\": null}, {\"url\": \"https://www.mlb.com/news/dodgers-win-2025-world-series\", \"title\": \"Dodgers win 2025 World Series\", \"content\": \"When it was over, the Dodgers and Blue Jays were separated by a wall. And not much else. [...] third out while colliding with teammate Kiké Hernández. [...] > THEY STILL NOT LIKE US. #WORLDSERIES pic.twitter.com/g1zddo2NVW\\\\n>\\\\n> — Los Angeles Dodgers (@Dodgers) November 2, 2025\\\\n\\\\n“I\\'m just speechless, I really am,” Dodgers manager Dave Roberts said. “It’s going to go down as one for the ages.”\\\\n\\\\nSo, too, will this Dodgers team, which has now won three titles in six years (and nine overall) in a sport with an expanded postseason pool that makes consistent postseason success more difficult than ever to achieve.\", \"score\": 0.9939964, \"raw_content\": null}, {\"url\": \"https://www.mlb.com/news/dodgers-win-2025-world-series-repeating-as-champions\", \"title\": \"Dodgers win 2025 World Series, repeating as champions\", \"content\": \"From one dome to another, from Tokyo to Toronto, the Dodgers defended their World Series title in a Game 7 thriller, outlasting the Blue Jays, 5-4, in 11 innings on Saturday night at Rogers Centre to seal their ninth championship in franchise history.\\\\n\\\\nThere had not been a repeat champion since the Yankees\\' three-peat from 1998-2000. And this year, the Dodgers were reminded exactly why it is so difficult to defend a title. [...] Heading into this year, the Dodgers knew they had the opportunity to do something special. They knew they made it through 2024 with just enough pitching, but they wanted more than just enough. They were hoping to assemble the greatest pitching staff they had ever had in the postseason, and they swung big in the offseason to reach that goal. [...] Following the pandemic-shortened 2020 season -- the first championship of this era of L.A. baseball -- the Dodgers made another deep run but were eliminated in the 2021 NLCS. Then came back-to-back years in which they did not make it out of the NLDS, which sowed doubt regarding their postseason prowess.\", \"score\": 0.9908744, \"raw_content\": null}], \"response_time\": 1.5, \"request_id\": \"69f65b1b-bb48-47e1-b097-70c00ed2b113\"}', name='tavily_search', tool_call_id='call_DiAwln4wvtilHtRddM4wMVac'),\n",
       " ToolMessage(content='{\"query\": \"2025 NPB 日本シリーズ 優勝 2025年 日本シリーズ 優勝チーム\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://ja.wikipedia.org/wiki/2025%E5%B9%B4%E3%81%AE%E6%97%A5%E6%9C%AC%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA\", \"title\": \"2025年の日本シリーズ\", \"content\": \"2025年の日本シリーズ（2025ねんのにっぽんシリーズ）は、阪神タイガース（以下、阪神）と福岡ソフトバンクホークス（以下、ソフトバンク）による第76回日本選手権シリーズ（76th Nippon Series）。\\\\n\\\\n10月25日に開幕し、10月30日の第5戦まで行われた。\\\\n\\\\nソフトバンクが阪神を4勝1敗で破り、5年ぶり12度目（前身球団を含む、ソフトバンク単独では8度目）の日本一に輝いた。\\\\n\\\\n## 概要\\\\n\\\\n[編集]\\\\n\\\\n本大会の表題は「SMBC日本シリーズ2025」（エスエムビーシーにっぽんシリーズ2025）で、2014年以来12大会連続で三井住友銀行がタイトルスポンサーとなった。 [...] | 本記事を編集なさる場合、まずはPJ:BASE#NPBポストシーズン、プロジェクト:野球をご一読ください。（2023年7月） |\\\\n\\\\n| 2025年の日本シリーズ |\\\\n\\\\n| SMBC日本シリーズ2025 |\\\\n| MVPを受賞した山川穂高 |\\\\n| ゲームデータ |\\\\n| 日本一 福岡ソフトバンクホークス 5年ぶり12回目 4勝1敗 |\\\\n| スポンサー | SMBC |\\\\n| 試合日程 | 2025年10月25日 - 10月30日 |\\\\n| 最高殊勲選手 | 山川穂高 |\\\\n| 敢闘賞選手 | 佐藤輝明 |\\\\n| チームデータ |\\\\n| 福岡ソフトバンクホークス（パ） |\\\\n| 監督 | 小久保裕紀 |\\\\n| シーズン成績 | 87勝52敗4分 （シーズン1位/CS優勝） |\\\\n| 阪神タイガース（セ） |\\\\n| 監督 | 藤川球児 |\\\\n| シーズン成績 | 85勝54敗4分 （シーズン1位/CS優勝） |\\\\n| クライマックスシリーズ |\\\\n| セントラル・リーグ |\\\\n| パシフィック・リーグ |\\\\n| 日本シリーズ  « 2024 |\\\\n| テンプレートを表示 | [...] 今シリーズは、セントラル・リーグとパシフィック・リーグのレギュラーシーズン、並びにセ・リーグクライマックスシリーズとパ・リーグクライマックスシリーズを制した阪神とソフトバンクによる対戦で、優勝チーム同士の対決となった。阪神は2年ぶり8度目、ソフトバンクは2年連続22度目の出場（前身球団時代を含む）。ソフトバンクの出場回数は西武（前身球団を含む）を上回り、巨人（36度）に次ぐ単独2位となった。この両チームによる対戦は2014年の日本シリーズ以来11年ぶり4度目となる。\\\\n\\\\nソフトバンク監督の小久保裕紀は新人監督だった前年に続いて2年連続出場を果たした。これは、ソフトバンク（および前身球団）の監督としては初のことである。全体では、オリックスの中嶋聡（2021年に新人監督として出場し、2023年まで3年連続出場）以来である。また、阪神監督の藤川球児は、球団初の新人監督での日本シリーズ出場を果たした。\\\\n\\\\n### 試合日程\\\\n\\\\n[編集]\\\\n\\\\nSMBC日本シリーズ2025\", \"score\": 0.9454852, \"raw_content\": null}, {\"url\": \"https://pacificleague.com/video/4903810\", \"title\": \"SMBC日本シリーズ2025 優勝祝勝会 （ノーカット） 2025年 ...\", \"content\": \"【やっぱり唯一無二】圧倒的TONOSAKI 2025【珍プレー2025】\\\\n【気を抜けない】”恐怖”ベンチでも油断大敵【珍プレー2025】\\\\n【結果だけじゃない】注目すべき『打席での反応』【珍プレー2025】\\\\n【HBD】年に一度のアレ【珍プレー2025】\\\\nお立ち台事件簿【珍プレー2025】\\\\n怪我のないよう…ボールの行方にご注意ください【珍プレー2025】\\\\n【入団会見】ライオンズ・桑原将志 ファンの皆さまからのメッセージと似顔絵が描かれた寄せ書きを贈呈!! 2025年12月22日 埼玉西武ライオンズ\\\\n【入団会見】ライオンズ・桑原将志 入団の決め手は？ 2025年12月22日 埼玉西武ライオンズ\\\\n【誰しもが共通】間違ったときは一度微笑んでごまかしてみる【珍プレー2025】\\\\n『好だけど珍』であり『珍だけど好』【珍プレー2025】\\\\n\\\\nもっと見る\\\\n\\\\nバナー\\\\nバナー\\\\nバナー\\\\nバナー\\\\nバナー\\\\nバナー\\\\nバナー（別ウィンドウで開く）\\\\nバナー（別ウィンドウで開く）\\\\n\\\\n# SMBC日本シリーズ2025 優勝祝勝会 （ノーカット） 2025年10月30日 福岡ソフトバンクホークス [...] パリーグ.com\\\\n北海道日本ハムファイターズ（別ウィンドウで開く）\\\\n東北楽天ゴールデンイーグルス（別ウィンドウで開く）\\\\n埼玉西武ライオンズ（別ウィンドウで開く）\\\\n千葉ロッテマリーンズ（別ウィンドウで開く）\\\\nオリックス・バッファローズ（別ウィンドウで開く）\\\\n福岡ソフトバンクホークス（別ウィンドウで開く）\\\\nPERSOL | パ・リーグTV Shop（別ウィンドウで開く）\\\\nPLM Career（別ウィンドウで開く）\\\\n\\\\n利用規約\\\\n\\\\nプライバシーポリシー\\\\n\\\\n運営会社（別ウィンドウで開く）\\\\n\\\\nよくある質問\\\\n\\\\n特定商取引法の表示\\\\n\\\\nアルバイト募集（別ウィンドウで開く） [...] パーソル パ・リーグTV\\\\n北海道日本ハムファイターズ（別ウィンドウで開く）\\\\n東北楽天ゴールデンイーグルス（別ウィンドウで開く）\\\\n埼玉西武ライオンズ（別ウィンドウで開く）\\\\n千葉ロッテマリーンズ（別ウィンドウで開く）\\\\nオリックス・バッファローズ（別ウィンドウで開く）\\\\n福岡ソフトバンクホークス（別ウィンドウで開く）\\\\n\\\\n利用規約\\\\n\\\\nプライバシーポリシー\\\\n\\\\n運営会社（別ウィンドウで開く）\\\\n\\\\nよくある質問\\\\n\\\\n特定商取引法の表示\\\\n\\\\nアルバイト募集（別ウィンドウで開く）\\\\n\\\\nパ・リーグ公式x（別ウィンドウで開く）\\\\nパ・リーグ公式facebook（別ウィンドウで開く）\\\\nパ・リーグ公式youtube（別ウィンドウで開く）\\\\nパ・リーグ公式line（別ウィンドウで開く）\\\\nパ・リーグ公式instagram（別ウィンドウで開く）\\\\nBall Park Style\\\\n\\\\nHOME\\\\n\\\\n動画\\\\n\\\\n日程・結果\\\\n\\\\n順位表・成績\\\\n\\\\n選手名鑑\\\\n\\\\nニュース\", \"score\": 0.80844593, \"raw_content\": null}, {\"url\": \"https://pacificleague.com/game/event/1025103003\", \"title\": \"福岡ソフトバンク SMBC日本シリーズ2025優勝祝勝会\", \"content\": \"パリーグ.com\\\\n北海道日本ハムファイターズ（別ウィンドウで開く）\\\\n東北楽天ゴールデンイーグルス（別ウィンドウで開く）\\\\n埼玉西武ライオンズ（別ウィンドウで開く）\\\\n千葉ロッテマリーンズ（別ウィンドウで開く）\\\\nオリックス・バッファローズ（別ウィンドウで開く）\\\\n福岡ソフトバンクホークス（別ウィンドウで開く）\\\\nPERSOL | パ・リーグTV Shop（別ウィンドウで開く）\\\\nPLM Career（別ウィンドウで開く）\\\\n\\\\n利用規約\\\\n\\\\nプライバシーポリシー\\\\n\\\\n運営会社（別ウィンドウで開く）\\\\n\\\\nよくある質問\\\\n\\\\n特定商取引法の表示\\\\n\\\\nアルバイト募集（別ウィンドウで開く）\\\\n\\\\n検索\\\\nパーソル パ・リーグTV\\\\nパ・リーグ公式x（別ウィンドウで開く）\\\\nパ・リーグ公式facebook（別ウィンドウで開く）\\\\nパ・リーグ公式youtube（別ウィンドウで開く）\\\\nパ・リーグ公式line（別ウィンドウで開く）\\\\nパ・リーグ公式instagram（別ウィンドウで開く）\\\\nBall Park Style\\\\n\\\\n福岡ソフトバンクホークス\\\\n\\\\n## 福岡ソフトバンク SMBC日本シリーズ2025優勝祝勝会 [...] パーソル パ・リーグTV\\\\n北海道日本ハムファイターズ（別ウィンドウで開く）\\\\n東北楽天ゴールデンイーグルス（別ウィンドウで開く）\\\\n埼玉西武ライオンズ（別ウィンドウで開く）\\\\n千葉ロッテマリーンズ（別ウィンドウで開く）\\\\nオリックス・バッファローズ（別ウィンドウで開く）\\\\n福岡ソフトバンクホークス（別ウィンドウで開く）\\\\n\\\\n利用規約\\\\n\\\\nプライバシーポリシー\\\\n\\\\n運営会社（別ウィンドウで開く）\\\\n\\\\nよくある質問\\\\n\\\\n特定商取引法の表示\\\\n\\\\nアルバイト募集（別ウィンドウで開く）\\\\n\\\\nパ・リーグ公式x（別ウィンドウで開く）\\\\nパ・リーグ公式facebook（別ウィンドウで開く）\\\\nパ・リーグ公式youtube（別ウィンドウで開く）\\\\nパ・リーグ公式line（別ウィンドウで開く）\\\\nパ・リーグ公式instagram（別ウィンドウで開く）\\\\nBall Park Style\\\\n\\\\nHOME\\\\n\\\\n動画\\\\n\\\\n日程・結果\\\\n\\\\n順位表・成績\\\\n\\\\n選手名鑑\\\\n\\\\nニュース [...] ### SMBC日本シリーズ2025 優勝祝勝会 （ノーカット） 2025年10月30日 福岡ソフトバンクホークス\\\\n\\\\n2025年10月31日(金) 01:00\\\\n\\\\nSMBC日本シリーズ2025 優勝共同記者会見 （ノーカット） 2025年10月30日 福岡ソフトバンクホークス\\\\n\\\\n### SMBC日本シリーズ2025 優勝共同記者会見 （ノーカット） 2025年10月30日 福岡ソフトバンクホークス\\\\n\\\\n2025年10月31日(金) 00:20\\\\n\\\\n【ノーカット】福岡ソフトバンクホークス SMBC日本シリーズ2025優勝祝勝会\\\\n\\\\n### 【ノーカット】福岡ソフトバンクホークス SMBC日本シリーズ2025優勝祝勝会\\\\n\\\\n2025年10月31日(金) 00:00\\\\n\\\\nバナー\\\\nバナー\\\\nバナー\\\\nバナー\\\\nバナー\\\\nバナー\\\\nバナー（別ウィンドウで開く）\\\\nバナー（別ウィンドウで開く）\\\\n\\\\n# 日程・結果\", \"score\": 0.73505294, \"raw_content\": null}, {\"url\": \"https://npb.jp/nippons/\", \"title\": \"SMBC日本シリーズ2025 | NPB.jp 日本野球機構\", \"content\": \"【デイリーリポート・第5戦】ソフトバンクが勝負強さを発揮して逆転勝利し、5年ぶり12度目の日本一に輝く · SMBC日本シリーズ2025 表彰選手 · SMBC日本シリーズ2025 チケット\", \"score\": 0.6227582, \"raw_content\": null}, {\"url\": \"https://www.youtube.com/watch?v=bb3PlzvAATs\", \"title\": \"【2025日本一】SMBC 日本シリーズ 2025 優勝共同記者会見 ...\", \"content\": \"SMBC 日本シリーズ 2025 優勝！試合後に行われる共同記者会見を生配信・見逃し配信します♪ 日本一達成記念グッズ好評受注販売中！\", \"score\": 0.43093804, \"raw_content\": null}], \"response_time\": 3.47, \"request_id\": \"961cc107-8dee-4af5-9d6b-01e55d47de9e\"}', name='tavily_search', tool_call_id='call_SGrg6r78TKIBY0cMvwjdg7sy')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_result_list # list[ToolMessage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tool의 처리(응답) 결과를 LLM 요청시 사용\n",
    "- ToolMessage를 prompt 에 추가하여 LLM에 요청한다.\n",
    "- ToolMessage 는 Tool Calling 정보를 가진 AIMessage 다음에 들어와야 한다.\n",
    "- Prompt 순서\n",
    "    1. 일반 prompt (system, 대화 history, .., human)\n",
    "    2. AIMessage: tool calling 정보를 가진 AIMessage. (tool_model에 질의 받은 tool calling 정보가 있는 응답)\n",
    "    3. ToolMessage:  Tool의 처리 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", \"당신은 AI Assistant입니다. 제공된 정보를 바탕으로 답변을 해주세요.\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | tool_model \n",
    "final_result = chain.invoke(\n",
    "    {\n",
    "        \"query\": query,\n",
    "        \"tool_messages\":[result, *search_result_list]\n",
    "    }\n",
    ")\n",
    "# \"tool_messages\":[result: tool call 정보가 있는 AIMessage, *search_result_list: Tool Message - tool의 처리 결과] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.tool_calls   # -> tool 호출 -> llm 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################\n",
    "# Agent chain을 구성\n",
    "#############################\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_tavily import TavilySearch\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_search = TavilySearch()\n",
    "model = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "tool_model = model.bind_tools(tools=[tavily_search])   # model에 tool을 binding\n",
    "\n",
    "system_message = \"\"\"# Instruction\n",
    "당신은 다양한 질문에 답을 하는 Assistant입니다. \n",
    "사용자 질문에 대해 최신 정보를 바탕으로 답변해주세요.\n",
    "오늘 날짜는 {today}입니다.\n",
    "필요하다면 tool을 이용해 답변에 필요한 정보를 수집합니다.\n",
    "당신이 사용할 수 있는 TOOL은 다음과 같습니다.\n",
    "- tavily_search: 웹 검색 툴 \"\"\"\n",
    "today = date.today()\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", system_message),\n",
    "        (\"human\", \"{query}\"),\n",
    "        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\n",
    "    ], \n",
    "    partial_variables={\"today\":today}\n",
    ")\n",
    "\n",
    "tool_model_chain = prompt | tool_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='어떤 장소의 날씨를 알려드릴까요? (예: 서울, 부산, 또는 우편번호)  \\n원하시는 정보도 알려주세요 — 현재 기온만, 오늘/시간별, 3일/7일 예보 등.  \\n단위는 섭씨(C)로 드릴까요, 화씨(F)로 드릴까요?\\n\\n원하시면 지금 위치 접근 허용해 주시면 현재 위치 기준으로 바로 알려드릴게요.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 363, 'prompt_tokens': 1359, 'total_tokens': 1722, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CsjpeIIIU5IkBkFbTDH1ATqJllpcT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b730f-1093-7cc1-8457-39633e1c68ba-0', usage_metadata={'input_tokens': 1359, 'output_tokens': 363, 'total_tokens': 1722, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_model_chain.invoke({\"query\": \"날씨를 알려줘.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025년 12월 31일'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.today().strftime(\"%Y년 %m월 %d일\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 구현\n",
    "@chain\n",
    "def websearch_agent(query:str) -> tuple[str, list]:\n",
    "    \"\"\"\n",
    "    Agent 전체 흐름을 처리하는 Runnable\n",
    "    사용자 질문(query)를 받아서 tool_model(search_menu, search_wiki, tavily_search)과 tool을 이용해서 최종 응답을 반환한다.\n",
    "    ReAct 구조로 구성. (ReAct Loop)\n",
    "    \"\"\"\n",
    "    ai_message = tool_model_chain.invoke({\"query\":query}) # 반환: 1. 실제 응답 또는 2. tool calls 정보\n",
    "    messages = []  # tool call 메세지, ToolMessage들을 저장 리스트 (prompt tool_messages에 넣을 것)\n",
    "    while ai_message.tool_calls:  # 빈 리스트가 아니라면\n",
    "        # Tool 호출 \n",
    "##########\n",
    "# 이 부분 강사님 거 보고 적어야 함\n",
    "##########\n",
    "\n",
    "        messages.extend([ai_message, *tool_messages])\n",
    "        # Tool 호출 결과를 넣어서 tool_model에 다시 요청\n",
    "        ai_messages = tool_model_chain.invoke({\"query\":query, \"tool_messages\":messages})\n",
    "\n",
    "    messages.append(ai_message)  # 마지막 응답 결과 추가\n",
    "    return ai_message.content  # AIMessages\n",
    "\n",
    "# agent 로직 -> LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = websearch_agent.invoke(\"안녕하세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 무엇을 도와드릴까요? 예: 정보 찾기, 번역, 글쓰기, 일정/계획 세우기, 코드 도움 등 편하게 말씀해 주세요.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tool_messages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result2 = \u001b[43mwebsearch_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m서울 날씨가 어떤지 알려줘.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:4871\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4856\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this `Runnable` synchronously.\u001b[39;00m\n\u001b[32m   4857\u001b[39m \n\u001b[32m   4858\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4868\u001b[39m \n\u001b[32m   4869\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4870\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4872\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4873\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4875\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4876\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4877\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4878\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2058\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2054\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2056\u001b[39m         output = cast(\n\u001b[32m   2057\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2058\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2059\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2060\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2061\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2062\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2066\u001b[39m         )\n\u001b[32m   2067\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2068\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:4728\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input_, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4726\u001b[39m                 output = chunk\n\u001b[32m   4727\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4728\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4729\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4730\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4731\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mwebsearch_agent\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m     10\u001b[39m     messages = []  \u001b[38;5;66;03m# tool call 메세지, ToolMessage들을 저장 리스트 (prompt tool_messages에 넣을 것)\u001b[39;00m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m ai_message.tool_calls:  \u001b[38;5;66;03m# 빈 리스트가 아니라면\u001b[39;00m\n\u001b[32m     12\u001b[39m         \u001b[38;5;66;03m# Tool 호출 \u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m##########\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 이 부분 강사님 거 보고 적어야 함\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m##########\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m         messages.extend([ai_message, \u001b[43mtool_messages\u001b[49m])\n\u001b[32m     18\u001b[39m         \u001b[38;5;66;03m# Tool 호출 결과를 넣어서 tool_model에 다시 요청\u001b[39;00m\n\u001b[32m     19\u001b[39m         ai_messages = tool_model_chain.invoke({\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m:query, \u001b[33m\"\u001b[39m\u001b[33mtool_messages\u001b[39m\u001b[33m\"\u001b[39m:messages})\n",
      "\u001b[31mNameError\u001b[39m: name 'tool_messages' is not defined"
     ]
    }
   ],
   "source": [
    "result2 = websearch_agent.invoke(\"서울 날씨가 어떤지 알려줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용자 정의 Tool 구현\n",
    "\n",
    "## @tool 사용\n",
    "- 함수로 구현하고 `@tool` 데코레이터를 사용해 tool(StructuredTool)로 정의한다.\n",
    "    - `langchain_core.tools` 모듈에 있다.\n",
    "- tool name\n",
    "    - 함수의 이름이 tool의 이름이 된다.\n",
    "- parameters\n",
    "    - 함수의 파라미터가 tool의 파라미터가 된다.\n",
    "    - **type hint**를 이용해 타입을 지정한다.  \n",
    "- description\n",
    "    - doctring이 description이 된다.\n",
    "    - RunnableBinding이 tool을 잘 찾을 수 있도록 하려면 **tool의 기능을 최대한 구체적**으로 작성한다.\n",
    "- **@tool이 적용된 함수(StructuredTool)이 tool**이므로 model에 binding 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def plus(num1:int|float, num2:int|float):\n",
    "    \"\"\"두 개 수를 받아서 덧셈한 결과를 반환하는 툴\"\"\"  # docstring -> tool 설명 (description)\n",
    "    return num1 + num2\n",
    "@tool\n",
    "def minus(num1:int|float, num2:int|float):\n",
    "    \"\"\"두 개 수를 받아서 뺄셈한 결과를 반환하는 툴\"\"\"  \n",
    "    return num1 - num2\n",
    "@tool\n",
    "def multiply(num1:int|float, num2:int|float):\n",
    "    \"\"\"두 개 수를 받아서 곱셈한 결과를 반환하는 툴\"\"\"  \n",
    "    return num1 * num2\n",
    "\n",
    "# 파라미터에 대한 자세한 설명이 들어가야 하는 경우 -> Pydantic\n",
    "from pydantic import BaseModel, Field\n",
    "class DivideParameterSchema(BaseModel):\n",
    "    num1: int|float = Field(..., description=\"나눌 때 사용할 첫 번째 값\")\n",
    "    num2: int|float = Field(..., description=\"나눌 때 사용할 두 번째 값\")\n",
    "\n",
    "@tool(\"divide_tool\", args_schema=DivideParameterSchema)  # 함수명과 ___를 따로 줄 수 있다. \n",
    "def divide(num1:int|float, num2:int|float):\n",
    "    \"\"\"두 개 수를 받아서 나눗셈한 결과를 반환하는 툴\"\"\"  \n",
    "    return num1 / num2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n",
      "툴 이름: divide_tool\n",
      "툴 설명: 두 개 수를 받아서 나눗셈한 결과를 반환하는 툴\n",
      "args schema(파라미터 설명)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'num1': {'anyOf': [{'type': 'integer'}, {'type': 'number'}],\n",
       "   'description': '나눌 때 사용할 첫 번째 값',\n",
       "   'title': 'Num1'},\n",
       "  'num2': {'anyOf': [{'type': 'integer'}, {'type': 'number'}],\n",
       "   'description': '나눌 때 사용할 두 번째 값',\n",
       "   'title': 'Num2'}},\n",
       " 'required': ['num1', 'num2'],\n",
       " 'title': 'DivideParameterSchema',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(divide))\n",
    "print(\"툴 이름:\", divide.name)\n",
    "print(\"툴 설명:\", divide.description)\n",
    "print(\"args schema(파라미터 설명)\")\n",
    "divide.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 284, 'prompt_tokens': 322, 'total_tokens': 606, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Csjqwzc3HQfGi9znSXaFI2ospewUH', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b7310-48ad-7eb3-8bad-cc26d591320d-0', tool_calls=[{'name': 'plus', 'args': {'num1': 3, 'num2': 5}, 'id': 'call_MJTvgd4y2KLeuMz7GfbbefcC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 322, 'output_tokens': 284, 'total_tokens': 606, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_model = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(tools=[plus, minus, multiply, divide])\n",
    "calc_model.invoke(\"3 + 5 - 20은 얼마야? 계산에 이용할 툴이 있으면 툴을 이용해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable을 tool로 정의\n",
    "- `Runnable객체.as_tool()`\n",
    "    - name, description, args_schema 파라미터를 이용해 tool의 이름, 설명, 스키마를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader  # 위키백과 사전 내용을 크롤링해서 문서로 반환\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.runnables import chain\n",
    "import json\n",
    "\n",
    "@chain\n",
    "def wikipedia_search(inputs:dict) -> str:\n",
    "    \"\"\"사용자 query를 위키백과사전에서 검색하고 검색 결과 중 k개 문서를 반환한다. \n",
    "    Args:\n",
    "        inputs(dict): query - 검색할 키워드, max_results(int): '반환할 검색 결과 수'를 받는다.\n",
    "    Returns:\n",
    "        str - 검색 결과를 json으로 반환. \n",
    "              형식: {\"result\":[{검색 문서1}, {검색 문서2}, ...]}. 형식: {\"result\":[검색 문서1, 검색 문서2, ...]}. 검색 문서 (dict) - content, url, title로 구성\n",
    "              검색 결과가 없을 경우 : {\"result\":\"결과 없음\"} 반환.\n",
    "    \"\"\"\n",
    "\n",
    "    query = inputs[\"query\"]\n",
    "    max_results = inputs.get(\"max_results\", 5)\n",
    "    loader = WikipediaLoader(query=query, load_max_docs=max_results, lang=\"ko\")\n",
    "    docs = loader.load()\n",
    "\n",
    "    result_list = []\n",
    "    for doc in docs:\n",
    "        result_list.append({\"content\":doc.page_content, \n",
    "                            \"title\":doc.metadata.get('title'),\n",
    "                            \"url\":doc.metadata.get(\"source\")\n",
    "                            })\n",
    "        \n",
    "    if result_list:\n",
    "        result = {\"result\": result_list}\n",
    "    else: \n",
    "        result = {\"result\": \"검색 결과가 없습니다.\"}\n",
    "\n",
    "    # JSON  문자열로 반환해서 변환.   # json.load(): json 문자열 -> python 자료 구조, json.dump(): python 자료 구조 -> json\n",
    "    return json.dumps(result, ensure_ascii=False)   # ensure_ascii=False : 한글 문자가 나오도록 처리. True: 한글이 유니코드 escape문자로 나옴 (\\uxxxx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"result\": \"\\\\uac80\\\\uc0c9 \\\\uacb0\\\\uacfc\\\\uac00 \\\\uc5c6\\\\uc2b5\\\\ub2c8\\\\ub2e4.\"}'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps({\"result\": \"검색 결과가 없습니다.\"}, ensure_ascii=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': [{'content': 'FIFA 월드컵(영어: FIFA World Cup)은 축구 국제 기구인 국제 축구 연맹(FIFA)에 가맹한 축구 협회(연맹)의  축구 국가대표팀만 참가하는 국제 축구 대회이다.\\n4년마다 열리는 월드컵은 1930년에 첫 대회가 열렸다. 1942년과 1946년 대회는 제2차 세계 대전으로 인하여 열리지 못했다. 대회는 예선 무대와 본선 무대 등 두 부분으로 나뉜다. 예선 무대는 본선에 진출할 32팀을 가려내기 위해 본선 보다 3년 일찍 시작한다. 현재 본선은 개최국 경기장에서 한 달 남짓 32개 팀이 우승을 놓고 경쟁하는 방식으로 진행된다. 월드컵 결승전은 세계에서 가장 많은 사람이 시청하는 단일 스포츠 경기이다. 어림잡아 7억 1,510만 명이 2006년 FIFA 월드컵 결승전을 시청했다고 한다.\\n총 20번 대회가 열리는 동안 8팀이 우승을 차지했다. 가장 우승 횟수가 많은 팀은 브라질로 총 다섯 번의 우승컵을 들어올렸다. 그 다음으로 이탈리아와 독일이 네 번, 아르헨티나가 세 번, 그리고 초대 우승팀인 우루과이와 프랑스가 각각 두 차례씩, 잉글랜드와 스페인가 각각 한 차례씩 우승을 차지했다. 네덜란드는 준우승만 3번(1974·1978·2010)했다.대한민국은 4위가 최고 기록이다.(2002)\\n가장 최근에 열린 2022년 FIFA 월드컵은 카타르에서 열렸고, 아르헨티나가 우승했다. 2026년은 캐나다/멕시코/미국에서 개최된다.\\n세계적인 종합 스포츠 행사 중 하나인 올림픽과 달리 월드컵은 단일 종목 대회다. 그리고 올림픽은 고대 그리스의 전통을 따라 한 도시를 중심으로 개최되지만, 월드컵은 한 국가를 중심으로 열리며 대회 기간은 올림픽이 보통 2주 동안 열리는데 비해 월드컵은 약 한달 동안 진행된다.\\n\\n\\n== 역사 ==\\n\\n\\n=== 이전의 국제 대회들 ===\\n세계 최초의 A매치는 1872년 글래스고에서 열린 스코틀랜드 대 잉글랜드의 경기였으며, 1884년에 시작된 첫 국제 대회인 브리티시 홈 챔피언십(영국 정기전)의 계기가 되기도 했다. (이후 이 대회는 1984년까지 이어졌다.)  이때 축구는 영국과 아일랜드 외의 다른 나라에서는 찾아보기 어려웠다. 한 세기가 지나 다른 지역에서도 축구의 인기가 높아지면서 1900년, 1904년, 1906년 하계 올림픽에서 시범 종목으로 채택되었다. 이 대회에서 별도의 메달은 수여되지 않았다.\\n월드컵의 역사는\\nFIFA가 1904년에 설립된 이후로 FIFA가 주관하며 올림픽과는 별개로 국가대항 축구 대회를 만들고자 하는 시도가 1906년에 스위스에서 있었다. 하지만 FIFA의 공식적인 기록에 의하면 이 대회의 계획은 실패로 돌아갔다고 한다.\\n올림픽 대회가 아마추어 팀들 간에 계속 경쟁을 하는 방향으로 가는 가운데 1909년, 토머스 립튼은 토머스 립튼 트로피 선수권 대회를 토리노에서 개최한다. 립튼 선수권은 각기 한 국가를 대표하러 나온 개인 클럽간(국가 대표팀간이 아닌)의 대회였다. 대회는 때때로 첫 번째 월드컵이라고 묘사되곤 했으며, 이탈리아, 독일, 그리고 스위스의 일류 프로 클럽팀이 주로 참가했다. 그러나 잉글랜드 축구 협회는 이 대회에 관여하려 않았으며, 프로팀들을 보내달라는 제안을 거절했다. 립튼은 카운티 더럼에 있는 아마추어 팀인 웨스트 오클랜드를 잉글랜드 팀을 대표하여 대신 초대했다. 웨스트 오클랜드는 대회에서 우승했고, 1911년의 대회에서도 성공적으로 타이틀을 방어, 대회 규칙에 따라 트로피를 영원히 보유하게 되었다.\\n1914년에, FIFA는 올림픽에서의 축구 대회를 ‘세계 아마추어 축구 선수권대회’로서 승인해주었고, 대회의 관리를 맡게 되었다. 그 결과 1920년 하계 올림픽에서 세계 최초의 대륙 간 축구 대회가 열렸다. 이 대회에는 이집트와 13개의 유럽 팀들이 참가하였다. 금메달은 벨기에가 차지하였다.\\n1928년에 FIFA는 올림픽과는 별개로 직접 주관하는 대회를 개최하기로 한다. FIFA는 첫 번째 FIFA 월드컵 개최국을 1924년 하계 올림픽과 1928년 하계 올림픽의 축구 종목에서 금메달을 차지했고, 1930년에 독립 100주년을 맞이하게 되는 우루과이로 결정한다.\\n\\n\\n=== 첫 번째 월드컵 ===\\n\\n로스앤젤레스에서 열린 1932년 하계 올림픽에서는 개최국인 미국에서 미식축구의 인기 탓에 축구의 인기가 낮아 정식 종목으로 채택될 계획이 없었다. 또한, FIFA와 IOC의 아마추어 선수의 지위에 관한 의견이 일치하지 않았고 이에 따라 축구는 올림픽에서 제외되었다. 이어 당시 FIFA 회장이었던 쥘 리메는 첫 번째 월드컵 대회를 1930년 우루과이에서 개최하기로 했다. 각 국가의 축구 협회들은 대회 참가 초청을 받았지만, 유럽 지역의 팀들에는 우루과이가 대서양을 횡단해야 하는 먼 나라였기 때문에, 큰 지출과 오랜 여정이 불가피했다. 그런 이유에 따라 대회 2달 전까지도 팀을 보내겠다는 확약을 한 유럽 국가는 없었다. 결국, 쥘 리메는 유럽 팀들을 한 팀이라도 설득하기 위해 노력했으며 우루과이는 모든 체류비와 차비를 출전팀들에게 제공하겠다는 조건을 내건 끝에 여비 및 체류비용이 공짜라는 점과 쥘 리메의 눈치를 봐서 벨기에, 프랑스, 루마니아, 유고슬라비아가 대회 참가에 응했다. 이리하여 유럽에서 4팀, 북중미에서 2팀, 남미에서 7팀, 총 13개 팀이 대회에 참가하였다.\\n월드컵 개막식은 두 경기가 동시에 열렸으며, 프랑스와 미국이 각각 멕시코를 4-1로, 벨기에를 3-0으로 꺾고 승리했다. 월드컵 사상 첫 번째 득점은 프랑스의 루시앙 로랑이 기록했다.\\n우루과이는 몬테비데오에서 열린 결승전에서 93,000명의 관중 앞에서 아르헨티나를 4-2로 꺾으며 첫 번째 FIFA 월드컵 우승 팀이 되었다.\\n\\n\\n=== 월드컵 대회가 맞은 시련 ===\\n초창기 월드컵 대회가 직면했던 문제는 두 가지였다. 첫 번째는 대륙 간 장거리 여행의 어려움이었다. 첫 번째 대회가 우루과이에서 열렸을 때에는 유럽팀들이 장거리 여행의 어려움을 이유로 많은 팀이 불참했다면, 반대로 유럽에서 열린 두 번째, 세 번째 대회에서는 남미 팀들이 이와 같은 이유로 대회에 불참하였다.\\n두 번째는 전쟁 문제로, 네 번째 대회는 원래 1942년에 개최될 예정이었다. 1936년 8월 13일, 베를린에서 열린 제23차 FIFA 총회에서 독일이 공식적으로 개최 신청을 했다. 곧이어 브라질도 월드컵 개최를 신청하였다. 1939년 6월에는 아르헨티나도 개최 신청에 참여했다. 하지만, 제4회 대회의 개최국이 결정되기 전인 1939년 9월 1일, 독일이 폴란드를 침공하면서 제2차 세계 대전이 발발하여 결국 무산되었다. 이 탓에 다음 대회인 1946년 대회도 자동으로 무산되었다.\\n종전 후인 1946년 7월 26일 룩셈부르크 시에서 열린 FIFA 총회에서 제4회 대회를 1949년 브라질에서, 제5회 대회를 1953년 스위스에서 개최하기로 했다. 개최국이 결정된 다음날, 대회 준비를 이유로 개최가 한 해씩 미뤄져 제4회 대회는 1950년, 제5회 대회는 1954년 개최되게 되었다.\\n\\n\\n=== 시련 이후 계속되는 성장 ===\\n\\n1950년 FIFA 월드컵은 처음으로 영국의 팀들이 참가한 대회였다. 영국의 일부 팀들은 그들과 전쟁했던 나라들과의 대결하기를 꺼렸고 또 그들의 팀들이 다른 나라의 축구에 영향을 주는 것을 항의하고자 1920년에 FIFA에서 탈퇴했으나, 그러나 FIFA의 초청에 따라 1946년에 다시 가입했다. 추가로 1950년 월드컵은 한국 전쟁이 발발한 시각과 동일한 시각에 개막되었다. 그리고 1950년 대회에서는 또한, 제1회 대회의 우승국이었던 우루과이가 이전 두 대회의 참가 거부 끝에 복귀했다. 우루과이는 이 대회에서 다시 한 번 우승했고 이 대회는 마라카낭의 비극이라고 하는 역사상 유명한 경기로 후에 남게 되었다. 우루과이에 패배한 브라질은 그 굴욕을 참지 못해 유니폼의 색깔이 변경되었다.\\n1934년부터 1978년 대회까지는 1938년 대회에서 오스트리아가 나치 독일에 예선 통과 후에 흡수됨에 따라 15개 팀의 참가로 치러진 경우와, 1950년 대회에서 인도, 스코틀랜드, 터키가 기권해서 13개 팀의 참가로 치러진 경우를 제외하면 총 16개의 팀이 본선에서 경쟁을 치렀다. 가장 많은 참가를 한 국가들은 대부분 유럽과 남미에',\n",
       "   'title': 'FIFA 월드컵',\n",
       "   'url': 'https://ko.wikipedia.org/wiki/FIFA_%EC%9B%94%EB%93%9C%EC%BB%B5'}]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = wikipedia_search.invoke({\"query\":\"월드컵\", \"max_results\":1})\n",
    "json.loads(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c1/rj7tb8cj0031l588c7fyvw0w0000gn/T/ipykernel_8175/4223115613.py:7: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  search_wiki = wikipedia_search.as_tool(\n"
     ]
    }
   ],
   "source": [
    "# Runnable을 tool로 변환 -> as_tool (툴 설정)\n",
    "## args_schema 설정\n",
    "class WikiSearchParameterSchema(BaseModel):\n",
    "    query: str = Field(..., description=\"Wikipedia에서 검색할 keyword\") # ...: 필수니까 반드시 입력하라는 뜻\n",
    "    max_results: int = Field(description=\"검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.\")\n",
    "\n",
    "search_wiki = wikipedia_search.as_tool(\n",
    "    args_schema=WikiSearchParameterSchema,\n",
    "    name=\"search_wiki\", \n",
    "    description=\"\"\"이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\n",
    "사용자의 질문과 관련된 내용을 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\n",
    "일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다. \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_wiki\n",
      "이 도구는 위키피디아에서 정보를 검색할 때 사용한다.\n",
      "사용자의 질문과 관련된 내용을 위키피디아에서 검색해서 지정한 개수의 문서만큼 반환한다.\n",
      "일반적인 지식이나 백과사전 식 정보가 필요할 때 사용한다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'properties': {'query': {'description': 'Wikipedia에서 검색할 keyword',\n",
       "   'title': 'Query',\n",
       "   'type': 'string'},\n",
       "  'max_results': {'description': '검색할 결과 문서의 최대 개수. 생략하면 5개를 검색.',\n",
       "   'title': 'Max Results',\n",
       "   'type': 'integer'}},\n",
       " 'required': ['query', 'max_results'],\n",
       " 'title': 'WikiSearchParameterSchema',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(search_wiki.name)\n",
    "print(search_wiki.description)\n",
    "search_wiki.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "tool_model = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(tools=[search_wiki])\n",
    "\n",
    "res = tool_model.invoke(\"월드컵에 대한 내용을 위키백과사전에서 조회해서 정리해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'search_wiki',\n",
       "  'args': {'query': '월드컵', 'max_results': 5},\n",
       "  'id': 'call_gPdY7yfTg7nuy0owMOk3GQeC',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(res.content)\n",
    "res.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store(Vector 저장소) tool\n",
    "\n",
    "### text loading -> Document 생성\n",
    "- 레스토랑 메뉴를 vector store에 저장한다.\n",
    "1. 메뉴 text 를 로딩한다.\n",
    "2. 각 메뉴의 내용(음식이름, 메뉴설명, 파일명)을 넣어 Document를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서 Load\n",
    "import os\n",
    "# 메뉴읽어 오기\n",
    "menu_file_path = \"data/restaurant_menu.txt\"\n",
    "with open(menu_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    menu = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'menu_name': '라따뚜이', 'price': 17000, 'ingredients': '가지, 호박, 파프리카, 토마토 소스, 올리브 오일', 'source': 'data/restaurant_menu.txt'}, page_content='1. 라따뚜이\\n   - 가격: 17,000원\\n   - 주요 재료: 가지, 호박, 파프리카, 토마토 소스, 올리브 오일\\n   - 메뉴 설명: 프랑스 남부를 대표하는 전통 요리로, 신선한 채소를 얇게 썰어 층층이 쌓아 올리고 허브와 토마토 소스를 더해 구워냅니다. 채소 본연의 단맛과 상큼한 소스가 조화를 이룹니다. 비건 고객도 즐길 수 있는 건강한 메뉴입니다. 따뜻한 바게트와 함께 제공됩니다.')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split - 메뉴별로 분리하기 위해 직접 처리\n",
    "from langchain_core.documents import Document\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "def create_documents(menu_all: str, file_name) -> list[Document]:\n",
    "    \"\"\"메뉴별로 분리 한뒤 Document로 변환. 변환된 Document들을 리스트로 반환\n",
    "    metadata: 메뉴이름, 주요 재료, 가격, source(파일이름)\n",
    "    \"\"\"\n",
    "    menu_list = menu_all.split(\"\\n\\n\")\n",
    "    menu_documents = []\n",
    "    for menu_item in menu_list:\n",
    "\n",
    "        # 메뉴 이름 추출\n",
    "        menu_name_pattern = r\"(^\\d+.\\s)([가-힣a-zA-Z\\d ]+)\"\n",
    "        menu_name_result = re.search(menu_name_pattern, menu_item)\n",
    "        menu_name = menu_name_result.group(2).strip()  # 메뉴 이름 추출 # 1은 번호\n",
    "\n",
    "        # 주요 재료 추출 - text로 indexing.\n",
    "        menu_ingredient_pattern = r\"(?<=주요 재료: ).+\"\n",
    "        ingredients = re.search(menu_ingredient_pattern, menu_item).group().strip()\n",
    "    \n",
    "        # 가격 추출\n",
    "        price_pattern = r\"(?<=가격: )[\\d,]+(?=원)\"\n",
    "        price_result = re.search(price_pattern, menu_item)\n",
    "        price = int(price_result.group().replace(\",\", \"\"))\n",
    "\n",
    "        \n",
    "        # 메뉴 이름을 제외한 나머지는 메뉴 설명으로 간주\n",
    "        menu_doc = Document(\n",
    "            page_content=menu_item,     # 메뉴 설명을 page_content에 넣는다. metadata는 나중에 따로 따로 payload filtering 할 수있기 때문에 \n",
    "            metadata={\n",
    "                \"menu_name\": menu_name, # 메뉴 이름\n",
    "                \"price\": price,         # 가격\n",
    "                \"ingredients\": ingredients, # 재료 리스트\n",
    "                \"source\": file_name     # 메뉴가 저장된 파일 이름\n",
    "            }\n",
    "        )\n",
    "        menu_documents.append(menu_doc)\n",
    "    return menu_documents\n",
    "\n",
    "\n",
    "menu_documents = create_documents(menu, menu_file_path)\n",
    "print(len(menu_documents))\n",
    "menu_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 문서 개수: 15\n"
     ]
    }
   ],
   "source": [
    "# VectorDB 저장 및 VectorStore 생성\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "COLLECTION_NAME = \"restaurant_menu\"\n",
    "VECTOR_SIZE = 1536  # OpenAIEmbeddings의 벡터 크기\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "if client.collection_exists(COLLECTION_NAME):\n",
    "    client.delete_collection(COLLECTION_NAME)\n",
    "\n",
    "# Collection 생성\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    # 벡터 저장소에 대한 설정. - vector_config는 default이므로 이름을 안줘도 됨(default 로 잡힘) 이름을 줄 거면 {\"이름\":VectorParams()} 설정\n",
    "    vectors_config=VectorParams(\n",
    "        size=VECTOR_SIZE, \n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=client, # QdrantClient\n",
    "    embedding=embeddings, # Embedding Model\n",
    "    collection_name=COLLECTION_NAME # 연결할 Collection 지정.\n",
    ")\n",
    "ids = vectorstore.add_documents(menu_documents)\n",
    "print(f\"저장된 문서 개수: {len(ids)}\")\n",
    "##################################################\n",
    "# Retriever 생성\n",
    "##################################################\n",
    "menu_retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}  # 검색할 결과 개수\n",
    ")\n",
    "\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "retriever = menu_retriever.configurable_fields(\n",
    "    search_type=ConfigurableField(\n",
    "        id=\"search_type\"\n",
    "    ),\n",
    "    search_kwargs=ConfigurableField(\n",
    "        id=\"search_kwargs\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'menu_name': '트러플 피자', 'price': 26000, 'ingredients': '트러플 오일, 모짜렐라 치즈, 얇은 피자 도우, 루꼴라', 'source': 'data/restaurant_menu.txt', '_id': 'd0105c53-df59-4544-9af3-a4820835eb43', '_collection_name': 'restaurant_menu'}\n",
      "{'menu_name': '니스 샐러드', 'price': 18000, 'ingredients': '참치, 방울토마토, 올리브, 삶은 달걀, 그린빈', 'source': 'data/restaurant_menu.txt', '_id': 'd0d4c18d-4143-40ae-a53a-77b645bc6fe7', '_collection_name': 'restaurant_menu'}\n",
      "{'menu_name': '부르기뇽 스튜', 'price': 28000, 'ingredients': '쇠고기, 적포도주, 양파, 당근, 베이컨', 'source': 'data/restaurant_menu.txt', '_id': 'a0abf784-542f-4b01-96cc-8b94cc90af3d', '_collection_name': 'restaurant_menu'}\n"
     ]
    }
   ],
   "source": [
    "query = \"프랑스 음식을 추천해줘.\"\n",
    "query = \"스페인 음식을 추천해줘.\"\n",
    "result = retriever.invoke(query)\n",
    "\n",
    "for doc in result:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "# Retriever를 tool로 사용.\n",
    "# query를 입력 받아서 retriever로 검색해서 그 결과를 반환하는 tool을 직접 구현.\n",
    "\n",
    "@tool\n",
    "def search_menu(query:str) -> str:\n",
    "    \"\"\"VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\n",
    "    이 도구는 query에 맞는 음식 메뉴를 검색할 때 사용한다.\n",
    "\n",
    "    Args:\n",
    "        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\n",
    "    Return:\n",
    "        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\n",
    "    \"\"\"\n",
    "    result_list = []\n",
    "    docs = retriever.invoke(query)\n",
    "    for doc in docs:\n",
    "        result_list.append({\"content\":doc.page_content,\n",
    "                            \"title\":doc.metadata['menu_name'],\n",
    "                            \"url\": doc.metadata['source']})\n",
    "    if result_list:\n",
    "        result = {\"result\":result_list}\n",
    "    else:\n",
    "        result = {\"result\": \"검색된 메뉴가 없습니다.\"}\n",
    "    \n",
    "    return json.dumps(result, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_menu\n",
      "VectorStore(Vector Database)에 저장된 restaurant menu를 검색하는 tool.\n",
      "    이 도구는 query에 맞는 음식 메뉴를 검색할 때 사용한다.\n",
      "\n",
      "    Args:\n",
      "        query(str): vector db의 restaurant 메뉴에서 검색할 음식에 대한 query.\n",
      "    Return:\n",
      "        str: 검색 메뉴들에 대한 정보를 JSON 형식으로 반환한다.\n"
     ]
    }
   ],
   "source": [
    "print(search_menu.name)\n",
    "print(search_menu.description)\n",
    "# search_menu.args_schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_model = ChatOpenAI(model=\"gpt-5-mini\").bind_tools(tools=[search_menu])\n",
    "res = tool_model.invoke(\"식당 메뉴 중 면요리를 추천해줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search_menu',\n",
       "  'args': {'query': '면요리'},\n",
       "  'id': 'call_km5bA8GfUlVjpwEGL9GqPqCA',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Agent를 구현\n",
    "# Restaurant 메뉴 추천, 설명 agent\n",
    "\n",
    "# tool: tavily_search, search_wiki, search_menu => 검색 tool들\n",
    "##############################################################\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_tavily import TavilySearch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Tool kit 정의 \n",
    "tavily_search = TavilySearch(max_result=5)\n",
    "tools = [search_wiki, search_menu]\n",
    "\n",
    "system_prompt = \"\"\"        \n",
    "당신은 레스토랑 메뉴 정보와 일반적인 음식 관련 지식을 제공하는 AI Assistant입니다. \n",
    "주요 목표는 사용자의 요청에 대한 정확한 정보를 제공하고 메뉴를 추천하는 것입니다.\n",
    "\n",
    "주요 지침들(guidelines):\n",
    "1. 레스토랑의 메뉴관련 정보를 확인하려면 search_menu 도구를 사용하십시오. 이 도구는 레스토랑의 메뉴들의 가격, 음식의 특징들에 대한 정보를 제공합니다.\n",
    "2. 일반적인 음식 정보, 그 음식의 유래, 문화적 배경에 대한 정보는 search_wiki 도구를 사용하십시오. 이 도구는 wikipedia 에서 정보를 검색해서 제공합니다.\n",
    "3. 추가적인 웹 검색이 필요하거나 최신 정보를 얻고 싶을 때는 tavily_search 도구를 사용하십시오. 이 도구는 인터넷 검색을 통해 정보를 검색해서 제공합니다.\n",
    "4. 검색 결과를 기반으로 명확하고 간결한 답변을 제공하십시오.\n",
    "5. 요청 받은 질문이 모호하거나 필요한 정보가 부족한 경우 정중하게 설명을 요청하세요.\n",
    "6. 메뉴 정보를 제공할 때는 가격, 주재료, 특징 순으로 설명하세요\n",
    "7. 메뉴를 추천 할 때는 간단하게 추천 이유를 설명해주세요.\n",
    "8. 최종 응답은 챗봇과 같은 대화형 스타일을 유지하세요. 친근하고 매력적이며 자연스럽게 소통하되 전문성을 보이는 어조를 유지하세요.\n",
    "\n",
    "- 각 도구의 목적과 기능을 정확하게 이해하고 각 적절한 상황에서 사용하세요.\n",
    "- 각 도구들을 결합해서 사용자의 요청에 정확한 대답을 하세요.\n",
    "- 항상 가장 최신의 정확한 정보를 제공하기 위해 노력하세요.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{query}\"),\n",
    "        MessagesPlaceholder(variable_name=\"tool_messages\", optional=True)\n",
    "    ]\n",
    ")\n",
    "tool_model = ChatOpenAI (model=\"gpt-5.2\").bind_tools(tools=tools)\n",
    "tool_model_chain = prompt | tool_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tool_model_chain.invoke({\"query\":\"파스타 메뉴를 추천해주고 파스타 유래나 역사를 알려줘.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search_menu',\n",
       "  'args': {'query': '파스타'},\n",
       "  'id': 'call_GcUBLgfXurzEAsRDiHgdEg1q',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'search_wiki',\n",
       "  'args': {'query': '파스타 역사 유래', 'max_results': 3},\n",
       "  'id': 'call_hjkI1TTdI1IknubEXPtYxgZ2',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 구현\n",
    "@chain\n",
    "def menu_recommand_agent(query:str) -> tuple[str, list]:\n",
    "    \"\"\"\n",
    "    Agent 전체 흐름을 처리하는 Runnable\n",
    "    사용자 질문(query)를 받아서 tool_model(search_menu, search_wiki, tavily_search)과 tool을 이용해서 최종 응답을 반환한다.\n",
    "    ReAct 구조로 구성. (ReAct Loop)\n",
    "    \"\"\"\n",
    "    ai_message = tool_model_chain.invoke({\"query\":query}) # 반환: 1. 실제 응답 또는 2. tool calls 정보\n",
    "    messages = []  # tool call 메세지, ToolMessage들을 저장 리스트 (prompt tool_messages에 넣을 것)\n",
    "    while ai_message.tool_calls:  # 빈 리스트가 아니라면\n",
    "        # Tool 호출 \n",
    "        tool_messages = []  # 둘 호출 결과들을 담을 list\n",
    "        for tool_call in ai_message.tool_calls:\n",
    "            name = tool_call['name']  # .name 대신 ['name'] 사용\n",
    "            # if name == \"search_wiki\":\n",
    "            #     tool_msg = search_wiki.invoke(tool_call)\n",
    "            # elif name == \"search_menu\":\n",
    "            #     tool_msg = search_menu.invoke(tool_call)\n",
    "            # elif name == \"tavily_search\":\n",
    "            #     tool_msg = tavily_search.invoke(tool_call)\n",
    "            tool_msg = globals()[name].invoke(tool_call['args']) # 인자값도 ['args']로 전달\n",
    "            tool_messages.append(tool_msg)\n",
    "\n",
    "        messages.extend([ai_message, *tool_messages])\n",
    "        # Tool 호출 결과를 넣어서 tool_model에 다시 요청\n",
    "        ai_messages = tool_model_chain.invoke({\"query\":query, \"tool_messages\":messages})\n",
    "\n",
    "    messages.append(ai_message)  # 마지막 응답 결과 추가\n",
    "    return ai_message.content  # AIMessages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__builtin__', '__builtins__', '_ih', '_oh', '_dh', 'In', 'Out', 'get_ipython', 'exit', 'quit', 'open', '_', '__', '___', '__vsc_ipynb_file__', '__DW_SCOPE__', '_i', '_ii', '_iii', '_i1', '_i2', 'd', '_2', '_i3', '_i4', '_i5', 'ChatPromptTemplate', 'MessagesPlaceholder', 'ChatOpenAI', 'TavilySearch', 'load_dotenv', 'tavily_search', '_i6', '_i7', '_i8', '_8', '_i9', 'query', 'result', '_i10', '_10', '_i11', '_i12', 'schema', '_12', '_i13', '_13', '_i14', 'model', 'toolkit', 'tool_model', '_i15', '_i16', '_i17', '_i18', 'result2', '_i19', '_19', '_i20', '_i21', 'search_result', '_i22', '_22', '_i23', '_23', '_i24', '_i25', '_i26', '_26', '_i27', 'search_result_list', '_i28', '_28', '_i29', 'prompt', 'chain', 'final_result', '_i30', '_30', '_i31', 'date', '_31', '_i32', 'system_message', 'today', 'tool_model_chain', '_i33', '_33', '_i34', '_34', '_i35', 'websearch_agent', '_i36', '_i37', '_37', '_i38', '_38', '_i39', '_39', '_i40', '_40', '_i41', '_41', '_i42', '_42', '_i43', 'tool', 'plus', 'minus', 'multiply', 'BaseModel', 'Field', 'DivideParameterSchema', 'divide', '_i44', '_44', '_i45', 'calc_model', '_45', '_i46', 'WikipediaLoader', 'json', 'wikipedia_search', '_i47', '_47', '_i48', 'r', '_48', '_i49', 'WikiSearchParameterSchema', 'search_wiki', '_i50', '_50', '_i51', 'res', '_i52', '_52', '_i53', 'os', 'menu_file_path', 'f', 'menu', '_i54', 'Document', 're', 'pprint', 'create_documents', 'menu_documents', '_54', '_i55', 'QdrantVectorStore', 'OpenAIEmbeddings', 'QdrantClient', 'Distance', 'VectorParams', 'COLLECTION_NAME', 'VECTOR_SIZE', 'embeddings', 'client', 'vectorstore', 'ids', 'menu_retriever', 'ConfigurableField', 'retriever', '_55', '_i56', '_i57', 'doc', '_i58', 'search_menu', '_i59', '_i60', '_i61', '_61', '_i62', 'tools', 'system_prompt', '_i63', '_i64', '_64', '_i65', '_i66', '_66', '_i67', '_i68', 'menu_recommand_agent', '_i69', '_69', '_i70', '_i71', '_i72'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = globals()  # 전역변수로 등록된 모든 변수, 함수들을 dicionary 제공. key: \"이름\", value: 변수/함수/클래스\n",
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_p4jntFTEzkPHL0imYhX92UFd, call_QDtbhjkXOT8kM7GWme00tsto\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res = \u001b[43mmenu_recommand_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m파스타 메뉴를 추천해줘. 그리고 파스타의 유래에 대해 설명해줘.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:4871\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4856\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this `Runnable` synchronously.\u001b[39;00m\n\u001b[32m   4857\u001b[39m \n\u001b[32m   4858\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4868\u001b[39m \n\u001b[32m   4869\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4870\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4872\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4873\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4875\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4876\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4877\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4878\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2058\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   2054\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   2055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   2056\u001b[39m         output = cast(\n\u001b[32m   2057\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m2058\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2059\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   2060\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2061\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2062\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   2066\u001b[39m         )\n\u001b[32m   2067\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2068\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:4728\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input_, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4726\u001b[39m                 output = chunk\n\u001b[32m   4727\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4728\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4729\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4730\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4731\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:433\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    432\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mmenu_recommand_agent\u001b[39m\u001b[34m(query)\u001b[39m\n\u001b[32m     25\u001b[39m     messages.extend([ai_message, *tool_messages])\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# Tool 호출 결과를 넣어서 tool_model에 다시 요청\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     ai_messages = \u001b[43mtool_model_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_messages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m messages.append(ai_message)  \u001b[38;5;66;03m# 마지막 응답 결과 추가\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ai_message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3143\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3141\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3142\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3143\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3144\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3145\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5548\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5541\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5543\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5546\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5547\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5549\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5550\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5551\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1380\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1378\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1379\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1383\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1384\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1385\u001b[39m ):\n\u001b[32m   1386\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1375\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1368\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1369\u001b[39m             response,\n\u001b[32m   1370\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1371\u001b[39m             metadata=generation_info,\n\u001b[32m   1372\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1373\u001b[39m         )\n\u001b[32m   1374\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1375\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1376\u001b[39m         response = raw_response.parse()\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_p4jntFTEzkPHL0imYhX92UFd, call_QDtbhjkXOT8kM7GWme00tsto\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}}"
     ]
    }
   ],
   "source": [
    "res = menu_recommand_agent.invoke(\"파스타 메뉴를 추천해줘. 그리고 파스타의 유래에 대해 설명해줘.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[1][0].tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create_agent() 를 이용한 Agent 구현\n",
    "\n",
    "- create_agent()\n",
    "  - Agent 생성 및 실행을 표준화, 단순화 하기 위헤 Langchain 1.0에서 도입된 함수\n",
    "  - 0.x 버전까지는 Agent 생성 함수는 \n",
    "    1. model과 tool들을 넣어 Agent를 생성하고 \n",
    "    2. 그것을 실행하는 Executor를 생성하는 방식으로\n",
    "  - 여러 단계를 거쳐야 했다.\n",
    "  - create_agent()는 이러한 단계를 1단계로 축약한 API이다.\n",
    "\n",
    "- create_agent 설계 철학\n",
    "    1. Agent를 구성하는 모든 실행단위는 Runnable 이다.\n",
    "    2. Agent도 Runnable 이다.\n",
    "    3. Agent는 하나의 표준 팩토리 함수(생성함수)로 통합한다.\n",
    "\n",
    "## 주요 파라미터\n",
    "- https://reference.langchain.com/python/langchain/agents/\n",
    "- `model`: LLM 모델. Agent의 두뇌 역할을 하며 추론(Reasoning), 도구 선택, 최종 응답을 담당한다.\n",
    "- `tools`: Agent가 사용할 외부 도구모음. \n",
    "- `system_prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model = ChatOpenAI(\"gpt-5-mini\"), \n",
    "    tools=tools,\n",
    "    system_prompt = system_prompt  # systemprompt ㅇㅓㅉㅓ고 강사님 거 보고 적기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent 호출\n",
    "res = agent.invoke(\n",
    "    {\n",
    "        \"messages\":[\n",
    "            (\"human\", \"파스타 메뉴를 추천해줘. 그리고 파스타의 유래에 대해 설명해줘.\")\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain에서 MCP 연동\n",
    "\n",
    "## MCP란\n",
    "\n",
    "- **MCP**(**Model Context Protocol**)는 Anthropic이 주도하여 2024년 말에 발표한 개방형 표준으로, LLM 애플리케이션이 외부 데이터 소스나 도구에 접근하는 방식을 표준화 하는 프로토콜이다.\n",
    "  - Agent가 이용할 수 있는 tool을 구현하는 방법은 framework 마다 다르기 때문에 서로 호환 되지 않는 문제가 있다. \n",
    "  - MCP는 이런 문제를 해결하기 위해 만든 표준 프로토콜이다.\n",
    "\n",
    "## MCP 아키텍처 구성 요소\n",
    "- **MCP 호스트**\n",
    "  -  AI 애플리케이션(예: LLM 채팅 애플리케이션)으로 MCP 클라이언트를 통해 여러 서버에 연결.\n",
    "\n",
    "- **MCP 클라이언트**\n",
    "  -  각 MCP 서버와의 연결을 유지하는 구성요소로, 서버로부터 도구/리소스/프롬프트를 가져와 LLM 모델에게 전달.\n",
    "\n",
    "- **MCP 서버**\n",
    "  -  외부 데이터 소스나 Tool들을 제공하는 프로그램이다. 서버는 도구, 리소스, 프롬프트를 노출하고 클라이언트와 JSON‑RPC 2.0 메시지로 통신.\n",
    "  -  MCP는 서버 클라이언트 간의 **로컬 프로세스 간 통신을 위한 STDIO**와 **원격 서버 접속을 위한 Streamable HTTP** 두 가지 전송 방식을 지원한다\n",
    "  -  **MCP 서버가 제공하는 것**\n",
    "     -  **도구**(**Tools**): LLM이 호출할 수 있는 함수형 작업이다. 예를 들어 “queryDatabase”, “sendEmail” 등이 있으며 각 도구는 이름, 설명, 입력 스키마를 포함한다.\n",
    "     -  **리소스**(**Resources**): 읽기 전용 데이터 소스로, 검색 색인·파일시스템·데이터베이스 등에서 컨텍스트를 제공한다.\n",
    "     -  **프롬프트**(**Prompts**): LLM 프롬프트 템플릿이나 예시를 서버에서 제공해 AI 모델의 질의를 돕는다.\n",
    "  \n",
    "\n",
    "## 사용 가능한 MCP 툴 찾기\n",
    "\n",
    "- MCP 생태계에는 수천 개의 툴 서버가 이미 공개되어 있으며, 원하는 기능의 툴을 검색하여 사용할 수 있다. \n",
    "- MCP 검색 및 서비스 사이트\n",
    "  - [PulseMCP](pulsemcp.com)\n",
    "  - [MCP 마켓](https://mcpmarket.com/ko)\n",
    "  - [MCP Servers](https://mcp.so/)\n",
    "  - [smithery](https://smithery.ai/servers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## LangChain에서 MCP 툴 연동하기\n",
    "\n",
    "- LangChain에서 MCP 서버와 연동하기 위해서는 Adapter lib 설치 필요.\n",
    "  - `pip install langchain-mcp-adapters`\n",
    "\n",
    "###  MultiServerMCPClient \n",
    "- **MCP 클라이언트 객체**로, LangChain에서 **하나 이상의 MCP 서버를 연결하고 Tool 목록을 가져오기 위해 사용**.\n",
    "    - 여러 개의 MCP 서버를 **동시에 등록하고 연결**할 수 있다.\n",
    "    - 서버 설정들을 **하나의 딕셔너리**(**Dictionary**)로 묶어 전달하며, **각 개별 서버 역시 Dictionary로 설정**.\n",
    "    - MCP 클라이언트에 등록된 모든 서버는 이후 `get_tools()` 호출을 통해 서버가 제공하는 tool들을 **LangChain의 Tool 객체로 자동 변환해 Agent가 호출**(**사용**)할 수 있게 한다.\n",
    "\n",
    "#### 개별 서버 설정 Key 정의\n",
    "- **`dict[str: 서버 별칭, dict: 서버 설정]`**\n",
    "\n",
    "| 설정 Key        | 의미                                                                  | 사용 예                            |\n",
    "| --------------- | --------------------------------------------------------------------- | ---------------------------------- |\n",
    "| **`transport`** | 서버와 통신하는 방식                                                  | `\"stdio\"` 또는 `\"streamable-http\"` |\n",
    "| **`command`**   | MCP 서버를 실행할 프로그램(프로세스)                                  | `\"python\"` 또는 `\"npx\"`            |\n",
    "| **`args`**      | command에 전달할 세부 실행 인자를 **리스트(List)**에 문자열로 순서대로 배치 | `[\"-m\", \"mcp_server_time\"]`  |\n",
    "\n",
    "- **transport 값에 따른 동작 구분**\n",
    "    - `\"stdio\"`: 로컬에서 실행되는 서버 연결\n",
    "    - `\"streamable-http\"`: 원격 MCP 서버(서비스형) 연결\n",
    "    \n",
    "    ```json\n",
    "        {\n",
    "            \"time\": {\n",
    "                \"transport\": \"stdio\",\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"-m\", \"mcp_server_time\"]\n",
    "            }\n",
    "        \n",
    "            \"github\": {\n",
    "                \"transport\": \"streamable-http\",\n",
    "                \"url\": \"https://server.smithery.ai/github\",\n",
    "            }\n",
    "        }\n",
    "    ```\n",
    "\n",
    "#### command + args 와 실행 명령어 관계\n",
    "\n",
    "| 실제 실행 명령                    | 설정으로 표현되는 방식                                             |\n",
    "| --------------------------- | -------------------------------------------------------- |\n",
    "| `python -m mcp_server_time` | `\"command\": \"python\", \"args\": [\"-m\", \"mcp_server_time\"]` |\n",
    "| `npx -y @org/server`        | `\"command\": \"npx\", \"args\": [\"-y\", \"@org/server\"]`        |\n",
    "\n",
    "* **command는 실행 프로그램**, args는 **명령 뒤에 붙는 옵션을 순서 그대로 리스트에 나열**한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. MCP Client 생성: 연결할 서버 정보를 제공 (실행)\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"time\": {\n",
    "            \"transport\":\"stdio\",   # 통신 방식\n",
    "            \"command\":\"python\", \n",
    "            \"args\":[\"-m\", \"mcp_server_time\"]   # command + args 실행: python -m mcp_server_time 서버를 실행하고 연결 \n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
