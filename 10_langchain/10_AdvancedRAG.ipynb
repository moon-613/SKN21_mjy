{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742de262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25/12/29(월) 9:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d844427",
   "metadata": {},
   "source": [
    "# Advanced RAG란 무엇인가\n",
    "\n",
    "**RAG**는 LLM(대규모 언어 모델)이 답을 만들 때, **외부 지식(문서/DB/웹 등)을 검색(Retrieval)해서 근거(Context)로 붙인 뒤 생성(Generation)**하는 구조다. 그런데 기본 RAG(Naive RAG)는 실무에서 다음 문제가 있다.\n",
    "\n",
    "- 검색이 \"비슷한 것\"은 찾는데 \"정답 근거\"를 제대로 못 찾는 경우\n",
    "- 근거가 있어도 LLM이 **hallucination(환각)**를 섞거나, 근거와 다른 답을 하는 경우\n",
    "- 검색한 문서가 너무 길고 복잡해서 **정답에 필요한 부분**(**chunk**)을 LLM이 제대로 찾지 못해 답변 품질이 안 좋은 경우\n",
    "\n",
    "**Advanced RAG**: 이런 \"현업형 문제\"를 줄이기 위해 **데이터베이스 구축 단계, 검색 전단계, 검색 후 단계, 생성 단계에서 고도화**하는 설계 패턴.\n",
    "기본 RAG(Naive RAG)가 \"사람이 대충 찾아준 참고자료로 글 쓰는 것\"이라면, Advanced RAG는 \"사서(검색) + 편집자(정제) + 팩트체커(검증) + 작가(생성)가 협업하는 파이프라인\"에 가깝다. 딱 하나의 기법이 아니라 추가 가능한 여러 기법. \n",
    "\n",
    "## 종류\n",
    "\n",
    "### 검색 품질을 올리는 고급 Retrieval\n",
    "\n",
    "- **하이브리드 검색**: 키워드(BM25) + 벡터(임베딩) 조합\n",
    "- **멀티-쿼리/쿼리 재작성(Query rewriting)**: 질문을 더 잘 검색되게 바꿔 검색 성공률을 올림\n",
    "- **메타데이터 필터링**: 메타데이터 필터링을 통해 범위를 좁혀 **정확도**를 올림. 의미기반 검색과 키워드 검색을 조합한 효과.\n",
    "- **리랭킹(Re-ranking)**: 후보 문서를 많이 가져온 뒤, \"정답에 가까운 순서\"로 다시 정렬\n",
    "\n",
    "### Chunking/인덱싱 전략 고도화\n",
    "- 벡터 데이터 베이스 구축시 어떤 구조로 문서를 분할하고 Indexing 할지의 전략\n",
    "  - **구조 기반 분할**: 헤더/섹션/표/코드블록\n",
    "  - **계층형 인덱스**: 문서 요약 → 섹션 → 세부 chunk, Parent-Child 구조\n",
    "  - **윈도우 확장**: 필요 시 앞 뒤 문맥을 함께 붙임\n",
    "  \n",
    "### 검색 결과의 \"정제/조립\" 단계 추가\n",
    "\n",
    "- 중복 제거, 노이즈 제거, 관련 부분만 발췌\n",
    "- 여러 chunk를 **질문 관점으로 재구성**\n",
    "  → LLM에 그대로 던지는 게 아니라 \"답변에 쓰기 좋은 근거 묶음\"으로 편집하여 전달.\n",
    "\n",
    "### 생성 단계의 신뢰성 강화(가드레일)\n",
    "\n",
    "- **근거 기반 답변 강제**: 검색한 문서에 답변의 근거가 없으면 \"답을 모른다.\"고 답변하도록 프롬프트를 구성.\n",
    "- **인용/근거 스니펫 포함**: 어느 문서에서 답이 나왔는지 근거를 보여주도록 해 답변의 신뢰성을 높인다.\n",
    "- **자기검증(Verification)**: 답을 만든 뒤 \"근거와 모순 없는지\" 재확인 하도록 한다.\n",
    "- **불확실성 처리**: 애매하면 추가 질문(Clarification)을 하거나 또는 답변 범위 제한.\n",
    "\n",
    "## Advanced RAG가 필요한 일반적인 경우\n",
    "\n",
    "- 문서가 많고(수천~수백만), 구조가 복잡한 경우(매뉴얼/규정/기술문서)\n",
    "- 질문이 단순 검색이 아니라 \"비교/조건/절차/근거 요구\"가 많은 복잡한 질문인 경우.\n",
    "- 최신성/정확성이 중요한 경우(정책, 금융, 의료, 보안, 운영 장애 대응)\n",
    "- \"대충 그럴듯한 답\"이 아니라 **근거가 있는 답**이 필수인 경우\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75dd69d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################\n",
    "# VectorStore, Retriever 준비\n",
    "###############################################################\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef11987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_qdrant import FastEmbedSparse, QdrantVectorStore, RetrievalMode\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.models import Distance, SparseVectorParams, VectorParams\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1a734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "\n",
    "def load_and_split_olympic_data(file_path=\"data/olympic_wiki.md\"):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as fr:\n",
    "        olympic_text = fr.read()\n",
    "\n",
    "    # Split\n",
    "    splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=[\n",
    "            (\"#\", \"Header 1\"),\n",
    "            (\"##\", \"Header 2\"),\n",
    "            (\"###\", \"Header 3\"),\n",
    "        ],\n",
    "        # strip_headers=False, # 문서에 header 포함 여부(default: True - 제거)\n",
    "    )\n",
    "\n",
    "    return splitter.split_text(olympic_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1b469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Vector DB 연결\n",
    "# retriever 생성\n",
    "#################################################################\n",
    "\n",
    "# collection 삭제후 생성 (데이터 넣지는 않음)\n",
    "def get_vectorstore(collection_name: str = \"olympic_info_wiki\"):\n",
    "\n",
    "    #######################################\n",
    "    # Qdrant Collection 생성 (sparse + dense)\n",
    "    #######################################\n",
    "    dense_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "    sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "    client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "    #삭제후 생성\n",
    "    if client.collection_exists(collection_name):\n",
    "        result = client.delete_collection(collection_name=collection_name)\n",
    "\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={\"dense\": VectorParams(size=3072, distance=Distance.COSINE)},\n",
    "        sparse_vectors_config={ \n",
    "            \"sparse\": SparseVectorParams()\n",
    "        },\n",
    "    )\n",
    "\n",
    "    ######################################\n",
    "    # VectorStore 생성 (Hybrid 모드)\n",
    "    ######################################\n",
    "    vector_store = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "    \n",
    "        embedding=dense_embeddings,\n",
    "        \n",
    "        sparse_embedding=sparse_embeddings,\n",
    "        retrieval_mode=RetrievalMode.HYBRID,\n",
    "    \n",
    "        vector_name=\"dense\",\n",
    "        sparse_vector_name=\"sparse\",\n",
    "    )\n",
    "    \n",
    "    ######################################\n",
    "    # Document들 추가\n",
    "    ######################################\n",
    "    documents = load_and_split_olympic_data()\n",
    "    vector_store.add_documents(documents=documents)\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "def get_retriever(vector_store, k: int = 5):\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_kwargs={\"k\": k}\n",
    "    )\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d7ee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m27 packages\u001b[0m \u001b[2min 336ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/60.15 KiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 14.89 KiB/60.15 KiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.89 KiB/60.15 KiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.89 KiB/60.15 KiB         \u001b[1A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/39.73 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.89 KiB/60.15 KiB         \u001b[2A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 16.00 KiB/39.73 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.89 KiB/60.15 KiB         \u001b[2A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 16.00 KiB/39.73 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.89 KiB/60.15 KiB         \u001b[2A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 16.00 KiB/39.73 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m 30.89 KiB/60.15 KiB         \u001b[2A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 16.00 KiB/39.73 KiB\n",
      "\u001b[2mloguru              \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 30.89 KiB/60.15 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/279.38 KiB          \u001b[3A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 16.00 KiB/39.73 KiB\n",
      "\u001b[2mloguru              \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 30.89 KiB/60.15 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/279.38 KiB          \u001b[3A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 16.00 KiB/39.73 KiB\n",
      "\u001b[2mloguru              \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 30.89 KiB/60.15 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/279.38 KiB          \u001b[3A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 16.00 KiB/39.73 KiB\n",
      "\u001b[2mloguru              \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 30.89 KiB/60.15 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/279.38 KiB          \u001b[3A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 16.00 KiB/39.73 KiB\n",
      "\u001b[2mloguru              \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 30.89 KiB/60.15 KiB\n",
      "\u001b[2mfastembed           \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/105.95 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/279.38 KiB          \u001b[4A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 16.00 KiB/39.73 KiB\n",
      "\u001b[2mloguru              \u001b[0m \u001b[32m------------------------\u001b[2m------\u001b[0m\u001b[0m 46.89 KiB/60.15 KiB\n",
      "\u001b[2mfastembed           \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/105.95 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/279.38 KiB          \u001b[4A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 16.00 KiB/39.73 KiB\n",
      "\u001b[2mloguru              \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 60.15 KiB/60.15 KiB\n",
      "\u001b[2mfastembed           \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/105.95 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/279.38 KiB          \u001b[4A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 32.00 KiB/39.73 KiB\n",
      "\u001b[2mloguru              \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 60.15 KiB/60.15 KiB\n",
      "\u001b[2mfastembed           \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/105.95 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/279.38 KiB          \u001b[4A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 32.00 KiB/39.73 KiB\n",
      "\u001b[2mloguru              \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 60.15 KiB/60.15 KiB\n",
      "\u001b[2mfastembed           \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/105.95 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/279.38 KiB          \u001b[4A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 39.73 KiB/39.73 KiB\n",
      "\u001b[2mloguru              \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 60.15 KiB/60.15 KiB\n",
      "\u001b[2mfastembed           \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/105.95 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/279.38 KiB          \u001b[4A\n",
      "\u001b[2mmmh3                \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 39.73 KiB/39.73 KiB\n",
      "\u001b[2mfastembed           \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/105.95 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/279.38 KiB          \u001b[3A\n",
      "\u001b[2mfastembed           \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/105.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/4)--------------\u001b[0m\u001b[0m     0 B/279.38 KiB          \u001b[2A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m4 packages\u001b[0m \u001b[2min 95ms\u001b[0m\u001b[0m                                                  \u001b[1A\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 17ms\u001b[0m\u001b[0m                                \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastembed\u001b[0m\u001b[2m==0.7.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mloguru\u001b[0m\u001b[2m==0.7.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmmh3\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpy-rust-stemmers\u001b[0m\u001b[2m==0.1.5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cad675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = get_vectorstore()\n",
    "basic_retriever = get_retriever(vectorstore)  # naive rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7c89ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': '올림픽', '_id': 'db7294c4-c7cd-4b9e-832b-165c74eb0d8f', '_collection_name': 'olympic_info_wiki'}, page_content='올림픽(영어: Olympic Games, 프랑스어: Jeux olympiques)은 전 세계 각 대륙 각국에서 모인 수천 명의 선수가 참가해 여름과 겨울에 스포츠 경기를 하는 국제적인 대회이다. 전 세계에서 가장 큰 지구촌 최대의 스포츠 축제인 올림픽은 세계에서 가장 인지도있는 국제 행사이다. 올림픽은 2년마다 하계 올림픽과 동계 올림픽이 번갈아 열리며, 국제 올림픽 위원회(IOC)가 감독하고 있다. 또한 오늘날의 올림픽은 기원전 8세기부터 서기 5세기에 이르기까지 고대 그리스 올림피아에서 열렸던 올림피아 제전에서 비롯되었다. 그리고 19세기 말에 피에르 드 쿠베르탱 남작이 고대 올림피아 제전에서 영감을 얻어, 근대 올림픽을 부활시켰다. 이를 위해 쿠베르탱 남작은 1894년에 IOC를 창설했으며, 2년 뒤인 1896년에 그리스 아테네에서 제 1회 올림픽이 열렸다. 이때부터 IOC는 올림픽 운동의 감독 기구가 되었으며, 조직과 활동은 올림픽 헌장을 따른다. 오늘날 전 세계 대부분의 국가에서 올림픽 메달은 매우 큰 영예이며, 특히 올림픽 금메달리스트는 국가 영웅급의 대우를 받으며 스포츠 스타가 된다. 국가별로 올림픽 메달리스트들에게 지급하는 포상금도 크다. 대부분의 인기있는 종목들이나 일상에서 쉽게 접하고 즐길 수 있는 생활스포츠 종목들이 올림픽이라는 한 대회에서 동시에 열리고, 전 세계 대부분의 국가 출신의 선수들이 참여하는 만큼 전 세계 스포츠 팬들이 가장 많이 시청하는 이벤트이다. 2008 베이징 올림픽의 모든 종목 누적 시청자 수만 47억 명에 달하며, 이는 인류 역사상 가장 많은 수의 인구가 시청한 이벤트였다.  \\n또한 20세기에 올림픽 운동이 발전함에 따라, IOC는 변화하는 세계의 사회 환경에 적응해야 했다. 이러한 변화의 예로는 얼음과 눈을 이용한 경기 종목을 다루는 동계 올림픽, 장애인이 참여하는 패럴림픽, 스페셜 올림픽, 데플림픽, 10대 선수들이 참여하는 유스 올림픽 등을 들 수 있다. 그 뿐만 아니라 IOC는 20세기의 변화하는 경제, 정치, 기술 환경에도 적응해야 했다. 그리하여 올림픽은 피에르 드 쿠베르탱이 기대했던 순수한 아마추어 정신에서 벗어나서, 프로 선수도 참가할 수 있게 되었다. 올림픽은 점차 대중 매체의 중요성이 커짐에 따라 올림픽의 상업화와 기업 후원을 놓고도 논란이 생겨났다. 또한 올림픽을 치르며 발생한 보이콧, 도핑, 심판 매수, 테러와 같은 수많은 일들은 올림픽이 더욱 굳건히 성장할 수 있는 원동력이 되었다.  \\n올림픽은 국제경기연맹(IF), 국가 올림픽 위원회(NOC), 각 올림픽의 위원회(예-벤쿠버동계올림픽조직위원회)로 구성된다. 의사 결정 기구인 IOC는 올림픽 개최 도시를 선정하며, 각 올림픽 대회마다 열리는 올림픽 종목도 IOC에서 결정한다. 올림픽 경기 개최 도시는 경기 축하 의식이 올림픽 헌장에 부합하도록 조직하고 기금을 마련해야 한다. 올림픽 축하 행사로는 여러 의식과 상징을 들 수 있는데 올림픽기나 성화가 그 예이다.  \\n올림픽은 거의 모든 국가가 참여할 정도로 규모가 커졌다. 하계 올림픽은 33개의 종목과 약 400개의 세부종목에서 13,000명이 넘는 선수들이 겨루고 그중 각 종목별 1, 2, 3위는 각각 금/은/동을 수여받는다. 전 세계 언론에서 각각 4년마다 열리는 올림픽 경기를 중계하기 때문에 이름 없는 선수가 개인적, 국가적, 세계적으로 명성을 얻을 수 있는 기회가 된다. 이와 더불어 올림픽 경기는 개최지와 개최국에게도 전 세계에 그 이름을 널리 알리는 좋은 기회가 된다.'),\n",
       " Document(metadata={'Header 1': '올림픽', 'Header 2': '고대 올림픽', '_id': '408bc53e-97d8-4835-af01-848119a045c2', '_collection_name': 'olympic_info_wiki'}, page_content='고대의 올림픽 경기(올림피아 경기)는 고대 그리스의 여러 도시 국가의 대표선수들이 모여 벌인 일련의 시합이었으며, 육상 경기가 주 종목이지만 격투기와 전차 경기도 열렸다. 그리고 패배하면 죽기도 하였다. 고대 올림픽의 유래는 수수께끼로 남아있다. 잘 알려진 신화로는 헤라클레스와 그의 아버지인 제우스가 올림픽의 창시자였다는 것이다. 전설에 따르면 이 경기를 최초로 \\'올림픽\\'이라고 부르고, 4년마다 대회를 개최하는 관례를 만든 사람이 헤라클레스라고 한다. 어떤 전설에서는 헤라클레스가 이른바 헤라클레스의 12업을 달성한 뒤에 제우스를 기리고자 올림픽 경기장을 지었다고 한다. 경기장이 완성되자 헤라클레스는 일직선으로 200 걸음을 걸었으며, 이 거리를 \"스타디온\"이라 불렀는데, 후에 이것이 길이 단위인 \\'스타디온\\'(그리스어: στάδιον → 라틴어: 영어: stadium)이 되었다. 또 다른 설로는 \\'올림픽 휴전\\'(그리스어: ἐκεχειρία 에케케이리아[*])이라는 고대 그리스의 관념이 최초의 올림피아 경기와 관련이 있다고 한다. \\'올림픽 휴전\\'이란 어느 도시 국가라도 올림피아 경기 기간 중에 다른 나라를 침범하면 그에 대한 응징을 받을 수 있다는 뜻으로, \"올림픽 기간에는 전쟁하지 말 것\"으로 요약할 수 있다.  \\n고대 올림피아 경기가 처음 열린 시점은 보통 기원전 776년으로 인정되고 있는데, 이 연대는 그리스 올림피아에서 발견된 비문에 근거를 둔 것이다. 이 비문의 내용은 달리기 경주 승자 목록이며 기원전 776년부터 4년 이후 올림피아 경기 마다의 기록이 남겨져 있다. 고대 올림픽의 종목으로는 육상, 5종 경기(원반던지기, 창던지기, 달리기, 레슬링, 멀리뛰기), 복싱, 레슬링, 승마 경기가 있었다. 전설에 따르면 엘리스의 코로이보스가 최초로 올림피아 경기에서 우승한 사람이라고 한다.  \\n고대 올림피아 경기는 근본적으로 종교적인 중요성을 띄고 있었는데, 스포츠 경기를 할 때는 제우스(올림피아의 제우스 신전에는 페이디아스가 만든 제우스 상이 있음)와 펠롭스를 기리기 위하여 제물 봉헌 의식을 치렀다. 펠롭스는 올림피아의 전설상의 임금이었던 피사티스의 오이노마오스 왕과 전차 경주를 겨룬 영웅으로 유명한 인물이다. 올림피아 경기의 승자는 시와 조각상으로 칭송받았다. 올림피아 경기는 4년마다 열렸으며, 이 기간을 \\'올림피아드\\'(Olympiad)라고 했는데, 그리스인들은 이를 시간 단위로 이용하였다. 올림피아 경기는 고대 그리스에서 정기적으로 열렸던 범그리스 대회의 순환 대회 가운데 하나였다.  \\n올림피아 경기는 기원전 6세기~기원전 5세기에 절정에 이르렀으나, 그 후 로마가 패권을 잡은 뒤 그리스에 영향력을 행사하면서 서서히 쇠퇴하게 된다. 고대 올림픽이 공식적으로 끝난 해는 확실히 알 수 없으나, 대부분 테오도시우스 1세 황제가 모든 이단 숭배 및 예배를 금지했던 393년을 고대 올림픽의 마지막이라고 추정한다. 다른 설에 따르면 테오도시우스의 후계자인 테오도시우스 2세가 모든 그리스 신전을 파괴하라고 명령한 426년이라고도 한다. 이렇게 올림픽이 사라진 이후로 이보다 한참 뒤인 19세기에 이르러서야 비로소 다시 올림픽 경기가 열리게 된다.'),\n",
       " Document(metadata={'Header 1': '올림픽', 'Header 2': '근대 올림픽', 'Header 3': '하계 올림픽', '_id': '03f673ad-2562-40b6-a73f-27738dd5e6fb', '_collection_name': 'olympic_info_wiki'}, page_content='1859년 자파스 올림픽에 참가한 선수의 수는 250명을 넘지 못했다. 에방겔리스 자파스는 \"지난 자파스 올림픽을 포함, 1896년에 개최될 2번째 올림픽을 위해 파나티네코 경기장을 보수해야 한다.\"라는 충고를 하지만, 그리스 정부는 그의 말을 듣지 않았고 결국 1896년 아테네 올림픽 준비를 위해 파나티네코 경기장은 두 번이나 정비해야 했다. 1회 대회 정식종목으로는 9종목이 있었는데 육상, 사이클, 펜싱, 체조, 사격, 수영, 테니스, 역도, 레슬링이 있었으며, 조정도 정식종목이었으나 매우 나쁜 날씨로 인해 조정 경기는 취소되었다. 펜싱 경기는 역사적 건물인 자피온(에반젤리스 자파스의 이름을 딴 것이다)에서 열렸다. 그리스의 관리들과 국민들은 올림픽 경기 개최에 열광적이었다. 많은 선수들이 이에 동감하면서 앞으로도 올림픽 대회를 아테네에서 영구히 개최해야 한다고 요구하기까지 하였다. 그러나 국제올림픽위원회(IOC)는 근대 올림픽은 순환 개최로 열리는 세계적인 행사가 되어야 한다고 생각했다. 결국 2회 올림픽은 프랑스 파리에서 열기로 결정되었다.  \\n#### 변화와 발전  \\n1896년 올림픽 대회의 성공을 이어서 개최된 두 번째 올림픽인 1900년 올림픽에서는 올림픽의 존폐여부를 위협받는 지경에 이르게 되었다. 1900년에 파리와 1904년에 세인트루이스에서 열린 올림픽은 하필이면 엑스포와 시간과 장소가 겹치는 바람에 빛을 바래게 된다. 1904년 대회를 예로 들면 650명의 선수단이 참가했지만 그중 580명은 미국국적을 가진 사람이었다. 1900년과 1904년의 두 올림픽 대회는 역대 올림픽중에 최저점을 기록한다. 올림픽은 1906년 올림픽이 아테네에서 개최되었을 때 다시 일어서게 된다. 또 다른 성공적인 올림픽은 그리스 올림픽 협회가 조직했으며 세 차례나 올림픽을 치른 경기장에서 개최되었다. 이 경기는 비공식 올림픽이긴 했지만 세계적으로 상당한 참가자들을 불러 모았으며 대중들에게 큰 재미를 갖다주었다. 이 때를 시작으로 올림픽의 인기와 번영이 시작되었다.'),\n",
       " Document(metadata={'Header 1': '올림픽', 'Header 2': '근대 올림픽', 'Header 3': '동계 올림픽', '_id': '03df1206-6aa2-4623-8ce1-abac190994c6', '_collection_name': 'olympic_info_wiki'}, page_content='동계 올림픽은 눈과 얼음을 이용하는 스포츠들을 모아 이루어졌으며 하계 올림픽 때 실행하기 불가능한 종목들로 구성되어 있다. 피겨스케이팅, 아이스하키는 각각 1908년과 1920년에 하계올림픽 종목으로 들어가 있었다. IOC는 다른 동계 스포츠로 구성된 새로운 대회를 만들고 싶어 했고, 로잔에서 열린 1921년 올림픽 의회에서 겨울판 올림픽을 열기로 합의했다. 1회 동계올림픽은 1924년, 프랑스의 샤모니에서 11일간 진행되었고, 16개 종목의 경기가 치러졌다. IOC는 동계 올림픽이 4년 주기로 하계 올림픽과 같은 년도에 열리도록 했다. 이 전통은 프랑스의 알베르빌에서 열린 1992년 올림픽 때까지 지속되었으나, 노르웨이의 릴레함메르에서 열린 1994년 올림픽부터 동계 올림픽은 하계 올림픽이 끝난지 2년후에 개최하였다.'),\n",
       " Document(metadata={'Header 1': '올림픽', 'Header 2': '근대 올림픽', 'Header 3': '청소년 올림픽', '_id': '91b49a11-8158-4d22-94dc-dba8a806889e', '_collection_name': 'olympic_info_wiki'}, page_content='2010년에 첫대회가 개최되며 14~18세가 참가하는 대회이다. 청소년 올림픽은 IOC위원장인 자크 로게가 2001년에 고안한 것으로써 2007년 제119차 IOC총회때 승인되었다. 제1회 하계 청소년 올림픽은 2010년 싱가포르에서 개최되었으며 제1회 동계 청소년 올림픽은 2년후인 2012년 오스트리아의 인스브루크에서 열렸다. 이 올림픽은 성인 올림픽보다 짧은 기간 내에 진행되며 하계 올림픽은 12일, 동계 올림픽은 9일간 열린다. IOC는 하계 유스 올림픽에 3,500명의 선수단과 875명의 임직원, 동계 유스 올림픽에는 970명의 선수단과 580명의 임직원이 참여한다고 말했다. 경기종목은 성인 올림픽과 동일하나 세부종목에 있어서는 제외되는 종목이 있다.')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_retriever.invoke(\"근대 올림픽은 언제 시작되었나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd8ce17",
   "metadata": {},
   "source": [
    "# Rerank\n",
    "\n",
    "## 개념\n",
    "\n",
    "- RAG의 정확도는 관련 정보의 컨텍스트 내 존재 유무가 아니라 순서가 중요하다. 즉, 관련 정보가 컨텍스트 내 상위권에 위치하고 있을 때 좋은 답변을 얻을 수 있다는 뜻이다. \n",
    "- **Rerank**는 RAG 시스템에서 **초기 검색 단계에서 추출된 후보 문서들의 순위를 재조정**하는 기법이다. \n",
    "- 벡터 유사도 기반의 빠른 1차 검색 후, 보다 정밀한 모델(예: Cross-encoder, LLM 등)을 활용해 질문과 검색된 문서간의 의미론적 관련성을 평가하여, 실제로 답변 생성에 가장 **적합한 문서들이 상위**에 오도록 순서를 다시 매긴다. 이를 통해 LLM이 더 정확하고 관련성 높은 정보를 바탕으로 답변을 생성할 수 있게 도와준다.\n",
    "\n",
    "## 방법\n",
    "\n",
    "- **Cross-encoder 기반 Rerank**  \n",
    "  - Cross Encoder를 이용해서 순위를 재 지정.\n",
    "  - Cross-encoder\n",
    "    - 질문과 문서를 같이 입력으로 받아 둘간의 유사도 점수를 예측하도록 학습한 모델.\n",
    "    - 학습을 두 문장의 유사도록 예측하도록 학습하였기 때문에 단순 유사도 검사 보다 두 문장간의 의미적 관련성등을 이용해 유사도를 예측하기 때문에 더 정확한 결과.\n",
    "  - 1차적으로 검색한 문서와 질문간의 유사도를 **cross-encoder**로 다시 계산해서 문서의 순위를 재 조정.\n",
    "  \n",
    "  > - **Bi-encoder**\n",
    "  >     - 질문 (query)와 문서(document)를 각각 독립적으로 인코딩한 후, 벡터 간 유사도 계산\n",
    "  >     - Encoder 모델은 개별 문장을 입력받아 embedding vector를 출력한다. 질문과 문서를 각각 encoding한 뒤에 둘 간의 유사도를 계산.\n",
    "  \n",
    "  ![bi_crosss_encoder](figures/bi_cross_encoder.png)\n",
    "\n",
    "  \\[출처:https://aws.amazon.com/ko/blogs/tech/korean-reranker-rag/\\]\n",
    "\n",
    "- **LLM 기반 Rerank**  \n",
    "  GPT-3, GPT-4 등 LLM을 활용해 각 문서가 질문에 얼마나 부합하는지 평가하여 순위를 매긴다. 성능이 뛰어나지만 비용이 높고 응답 속도가 느릴 수 있다.\n",
    "## Rerank RAG 프로세스  \n",
    "1. 1차 검색(예: 임베딩 기반 벡터 검색)으로 상위 k개 문서 추출.  \n",
    "2. Reranker 모델에 질문-문서 쌍을 입력.  \n",
    "3. 각 쌍의 관련성 점수 산출 및 재정렬.  \n",
    "4. 상위 n개 문서를 LLM의 컨텍스트로 전달하여 답변 생성.\n",
    "\n",
    "## 장단점\n",
    "\n",
    "- **장점**  \n",
    "  - Rerank를 적용하면 단순 벡터 유사도 기반 검색보다 훨씬 정교하게 질문과 관련된 정보를 추출할 수 있다. \n",
    "  - 실제로 생성되는 답변의 품질이 크게 향상되며, 도메인 특화 정보나 복잡한 질의에도 높은 정확도를 보인다.\n",
    "\n",
    "- **단점**  \n",
    "  - Cross-encoder나 LLM 기반 Rerank는 연산량이 많아 실시간 응답이 필요한 대규모 서비스에선 속도 저하가 발생 가능.\n",
    "  - 초기 검색 결과(상위 k개)에만 적용하므로, 1차 검색의 품질이 낮으면 Rerank 효과가 제한적일 수 있다.\n",
    "\n",
    "## CrossEncoder Reranker 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06ec44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a06683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b361e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e044a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83aac8f1",
   "metadata": {},
   "source": [
    "# HyDE (Hypothetical Document Embedding)\n",
    "## 개념\n",
    "- 질문(query)에 대한 가상의 답변 문서를 생성하고, 이 생성된 가상의 답변 문서를 임베딩하여 검색에 활용하는 기법이다.\n",
    "- 일반적인 RAG에서 검색은 질문을 임베딩하여 문서 임베딩과 직접 비교한다. \n",
    "- 질문(\"파리는 어떤 도시인가?\")과 답변 문서(\"파리는 프랑스의 수도이며...\")는 표현 방식이 다르다는 문제가 있다. \n",
    "- 즉 의미적으로는 관련있지만 벡터 공간(임베딩 벡터간의 유사서)에서는 거리가 멀 수가 있다.\n",
    "- 그래서 HyDE는 질문과 문서가 아니라 질문으로 가상의 답변 문서를 만들고 **가상의 답변문서와 저장된 문서들간의 유사도**를 비교한다.\n",
    "\n",
    "## HyDE 프로세스\n",
    "\n",
    "1. 가상 문서 생성\n",
    "   -  LLM을 사용해 질문에 대한 가상의 답변 문서 생성\n",
    "   -  이때 성능이 좋은 LLM을 사용하는 것이 좋다.\n",
    "2. 임베딩 변환\n",
    "   - `1`에서 생성한 가상 문서를 벡터로 임베딩\n",
    "3. 유사도 검색\n",
    "   - 가상 문서 임베딩으로 Vector Store에 저장된 문서들 중 유사한 문서를 검색\n",
    "4. 답변 생성\n",
    "   - 검색된 실제 문서를 바탕으로 최종 답변 생성\n",
    "\n",
    "## 장단점\n",
    "- **장점**\n",
    "  - 질문-문서 간 의미적 차이를 해결 해서 정확한 문서 검색 가능\n",
    "  - 질문 표현 방식에 덜 민감\n",
    "- **단점**\n",
    "  - 가상 문서의 품질에 따른 성능 편차가 발생한다.\n",
    "    - 가상 문서 생성 시 환각(hallucination) 위험\n",
    "  - 추가적인 LLM 호출로 인한 비용 증가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62840b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c2dae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a88f3e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b672ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02cd59f8",
   "metadata": {},
   "source": [
    "#  MultiQueryRetriever\n",
    "\n",
    "## 개념\n",
    "- 하나의 사용자 질문으로 **여러 개의 다양한 질문을 생성하여 검색**을 수행하는 방법이다.\n",
    "- 단일 질문의 한계를 극복하고 다각도에서 관련 정보 검색할 수있다.\n",
    "  - 기본 RAG는 사용자의 질문의 질(quality)에 따라 검색 결과가 좌우된다.\n",
    "  - 사용자가 한 질문에만 의존하는 것이 아니라 그 질문을 바탕으로 **다양한 의미의 질문들을 생성해서 단일 질문이 가지는 표현의 한계를 보완**한다.\n",
    "    - 동일한 질문을 다른 각도에서 접근할 수있다.\n",
    "    - 다양한 어휘와 표현으로 질문을 재구성한다.\n",
    "- 예)\n",
    "  - **원본 질문**: \"딥러닝의 장점은 무엇인가?\"\n",
    "  - **생성된 질문들**:\n",
    "    1. \"딥러닝이 전통적인 머신러닝보다 나은 점은?\"\n",
    "    2. \"딥러닝을 사용하면 얻을 수 있는 이익은?\"\n",
    "    3. \"딥러닝의 주요 강점과 특징은?\"\n",
    "    4. \"딥러닝 기술의 핵심 우위는?\"\n",
    "## 실행 프로세스\n",
    "\n",
    "1. 질문 생성   \n",
    "   - LLM을 사용해 원본 질문을 3-5개의 서로 다른 질문으로 변환\n",
    "2. 병렬 검색\n",
    "   - 생성된 각 질문으로 독립적으로 문서 검색 수행\n",
    "3. 결과 통합\n",
    "   - 여러 검색 결과를 하나로 병합\n",
    "4. 중복 제거\n",
    "   - 동일한 문서가 여러 번 검색된 경우 중복 제거\n",
    "5. 최종 답변\n",
    "   - 통합된 문서 세트를 바탕으로 답변 생성\n",
    "\n",
    "## 장단점\n",
    "- **장점**\n",
    "    - 단일 질문으로 놓칠 수 있는 관련 문서 발견 수 있다.\n",
    "    - 사용자 질문 표현 방식의 한계 극복\n",
    "    - 더 포괄적이고 완전한 정보 검색 및 수집을 할 수있다.\n",
    "- **단점**\n",
    "    - 여러 번의 LLM 호출과 검색 수행이 실행 되므로 **계산비용, 토큰비용, 응답시간이 증가한다.**\n",
    "    - 생성된 질문의 품질에 따른 성능 편차가 있을 수 있다.\n",
    "    - 생성된 질문에 따라 원래 질문과 관련성 낮은 문서도 검색될 수 있어 최종 답변을 방해하는 노이즈가 증가할 수있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df5b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb7a01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2015bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185452e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e581ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47826ade",
   "metadata": {},
   "source": [
    "# MapReduce RAG 방식\n",
    "\n",
    "## 개요\n",
    "\n",
    "- RAG(Retrieval-Augmented Generation)에서 검색된 문서들 중 질문과 관련성이 높은 문서만을 선별하여 더 정확한 답변을 생성하는 방법이다.\n",
    "- 검색된 문서들 중에서 질문 답변에 실제로 도움이 되는 문서만을 LLM을 통해 선별한 후 전달하는 방식이다.\n",
    "\n",
    "## MapReduce 방식 프로세스\n",
    "1. Map (문서 검색)\n",
    "   - 벡터스토어에서 질문과 유사한 문서들을 의미적 유사도 검색으로 찾는다.\n",
    "   - 이 단계에서는 단순 벡터 유사도만 고려하므로 질문과 직접적인 관련이 없는 문서도 포함될 수 있다.\n",
    "2. Reduce (문서 선별 및 요약)\n",
    "   - 검색된 각 문서가 질문 답변에 실제로 도움이 되는지 LLM에게 평가 요청한다.\n",
    "   - 관련성이 높은 문서들만 선별하여 요약하거나 결합한다.\n",
    "   - 필요시 여러 문서의 정보를 통합하여 더 응답에 적합한 컨텍스트를 생성한다.\n",
    "3.  Generate (최종 답변 생성)\n",
    "    - 질문과 선별된 컨텍스트를 함께 LLM에 전달하여 최종 답변을 생성한다.\n",
    "\n",
    "## 장단점\n",
    "\n",
    "- **장점**\n",
    "  - **높은 정확도**: 질문과 직접 관련된 정보만 사용하여 더 정확한 답변을 생성한다.\n",
    "  - **노이즈 제거**: 유사하지만 관련 없는 정보로 인한 혼동을 방지한다.\n",
    "  - **컨텍스트 최적화**: 제한된 토큰 범위 내에서 가장 유용한 정보만 전달한다.\n",
    "  - **확장성**: 많은 문서가 검색되어도 중요한 정보만 선별하여 처리할 수 있다.\n",
    "- 단점\n",
    "  - **추가 비용**: 문서 선별을 위한 LLM 호출로 인한 비용이 증가한다.\n",
    "  - **처리 시간**: 문서 평가 단계가 추가되어 응답 속도가 저하된다.\n",
    "  - **복잡성**: 구현과 관리가 더 복잡하다.\n",
    "  - **의존성**: 문서 선별 성능이 LLM의 판단 능력에 크게 의존한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a07c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c49de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db372ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e3d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8a900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c78c96dd",
   "metadata": {},
   "source": [
    "# Self Query Retriever\n",
    "\n",
    "- **Self-Query Retriever**는 사용자의 자연어 질문을 LLM을 통해 '의미 기반 검색 쿼리(semantic query)'와 '메타데이터 기반 필터 조건(metadata filter)'으로 자동 분해/구조화하여, 벡터 검색과 조건 기반 필터링을 동시에 수행하도록 설계된 Advanced RAG의 고급 Retriever 기법이다. 이를 통해 메타데이터의 속성을 정확히 반영한 정밀 검색이 가능하다.\n",
    "- 즉 사용자 질의로 부터 메타데이터의 필터 조회시 사용할 값을 추출하여 metadata 조건 기반 필터링을 할 수 있도록 한다.\n",
    "\n",
    "## Self Query Retriever의 구성 요소\n",
    "\n",
    "- **LLM (Large Language Model)**\n",
    "    - 자연어로 표현된 사용자 질문을 받아, 이를 메타데이터 조건과 필터링 조건이 포함된 정형 쿼리(Structured Query)로 변환하는 역할을 한다.\n",
    "- **StructuredQuery**\n",
    "    - 사용자의 질문을 기반으로 생성되는 구조화된 쿼리로 다음 두가지가 생성된다.\n",
    "      - 벡터 유사도 검색을 위한 **의미 기반 검색 쿼리**(semantic query)\n",
    "      - 문서 메타데이터를 이용한 **필터링 조건**(metadata filter)\n",
    "  \n",
    "- **Query Translator**\n",
    "    - 생성된 StructuredQuery를 특정 벡터 데이터베이스(Qdrant, Chroma 등)의 쿼리 언어로 번역하여, 실제 검색이 가능하도록 한다.\n",
    "- **Vector Database**\n",
    "    - 변환된 쿼리를 바탕으로 벡터 유사도 검색과 메타데이터 조건 필터링을 함께 수행하여 관련 문서를 반환한다.\n",
    "\n",
    "## Self Query Retriever 작동 원리\n",
    "\n",
    "![selfquery retriever](figures/selfquery_retriever.jpg)\n",
    "\n",
    "1. 사용자가 자연어 질의(Query)를 입력한다.\n",
    "2. LLM이 입력된 자연어 질문을 해석하여 **Query Constructor**가 **StructuredQuery**로 변환한다.\n",
    "3. **Query Translator**가 StructuredQuery를 **벡터 데이터베이스에서 이해할 수 있는 쿼리**로 변환한다.\n",
    "4. 벡터 데이터베이스가 변환된 쿼리에 따라 문서를 검색한다.\n",
    "5. 최종적으로, 검색 결과가 사용자에게 제공된다.\n",
    "\n",
    "## 사용 예시\n",
    "1. Query\n",
    "    - \"2023년에 발표된 OpenAI의 GPT 모델 관련 논문을 찾아줘.\"\n",
    "2. Query Constructor가 위 질문을 다음과 같은 형태의 StructuredQuery로 변환한다.\n",
    "\n",
    "    ```json\n",
    "    {\n",
    "        \"query\": \"GPT 모델 논문\",\n",
    "        \"filter\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"key\": \"year\",\n",
    "                    \"match\": {\n",
    "                        \"value\": 2023\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"key\": \"author\",\n",
    "                    \"match\": {\n",
    "                        \"value\": \"OpenAI\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    ```\n",
    "     - query: 벡터검색에 사용될 자연어 의미기반 쿼리(semantic query)\n",
    "     - filter: 메타데이터 기반 필터 조건\n",
    "3. 위의 StruncturedQuery는 Retriever와 연결된 Vector database의 검색 형식에 맞춰 query translator에 의해 변환 되고 이것을 이용해 검색을 진행한다. (형식은 DB 마다 다르다.)\n",
    "\n",
    "\n",
    "## Self Query Retriever의 장점\n",
    "\n",
    "- **정밀성**: 메타데이터 조건을 정확하게 지정하여 원하는 문서를 정밀하게 검색할 수 있다.\n",
    "- **효율성**: 메타데이터 필터링을 통해 관련 없는 문서를 미리 제거하여 검색 대상 문서의 후보 집합을 사전에 축소함으로써, 벡터 유사도 계산 대상이 줄어들고 전체 검색 연산량을 감소시킬 수 있다.\n",
    "- **사용자 편의성**: 사용자가 복잡한 쿼리 조건을 직접 작성하지 않고, 자연어로 간편하게 질문할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03dba7f",
   "metadata": {},
   "source": [
    "## 예제\n",
    "- 필요 패키지 설치\n",
    "  - pip install langchain langchain-community langchain-openai langchain-qdrant lark\n",
    "\n",
    "> ### Lark 패키지\n",
    "> \n",
    "> - Lark는 텍스트를 구조적으로 분석하기 위한 파싱 라이브러리로, 미리 정의한 문법에 따라 문장을 해석하여 정해진 형태(parse tree 또는 abstract syntax tree) 형태의 구조화된 결과를 생성한다.\n",
    "> - 이 라이브러리는 컴파일러, 인터프리터, DSL(도메인 특화 언어), 쿼리 언어, 수식 해석기처럼 구조화된 입력을 처리해야 하는 다양한 프로그램에서 활용된다.\n",
    "> - LangChain의 **SelfQueryRetriever**에서는 LLM이 생성한 쿼리 조건 문자열(output)을 석하여 메타데이터 필터 조건으로 변환하기 위해 Lark가 사용된다. Lark는 텍스트 형식의 조건을 분석하여 벡터 검색 시 사용되는 StructuredQuery의 filter(metadata filter) 구조로 변환해주는 역할을 담당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e2c35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da64881",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"A bunch of scientists bring back dinosaurs and mayhem breaks loose\",\n",
    "        metadata={\"year\": 1993, \"rating\": 7.7, \"genre\": \"science fiction\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Leo DiCaprio gets lost in a dream within a dream within a dream within a ...\",\n",
    "        metadata={\"year\": 2010, \"director\": \"Christopher Nolan\", \"rating\": 8.2},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A psychologist / detective gets lost in a series of dreams within dreams within dreams and Inception reused the idea\",\n",
    "        metadata={\"year\": 2006, \"director\": \"Satoshi Kon\", \"rating\": 8.6},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"A bunch of normal-sized women are supremely wholesome and some men pine after them\",\n",
    "        metadata={\"year\": 2019, \"director\": \"Greta Gerwig\", \"rating\": 8.3},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Toys come alive and have a blast doing so\",\n",
    "        metadata={\"year\": 1995, \"genre\": \"animated\"},\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Three men walk into the Zone, three men walk out of the Zone\",\n",
    "        metadata={\n",
    "            \"year\": 1979,\n",
    "            \"director\": \"Andrei Tarkovsky\",\n",
    "            \"genre\": \"thriller\",\n",
    "            \"rating\": 9.9,\n",
    "        },\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Store 생성\n",
    "\n",
    "COLLECTION_NAME = \"example\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"example\",\n",
    "    embedding=embedding_model\n",
    ")\n",
    "vectorstore.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbaa4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
