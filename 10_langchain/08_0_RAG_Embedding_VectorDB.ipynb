{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907e923a-af5e-48c3-9664-58bd640efb20",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "![rag_embedding](figures/rag_embedding.png)\n",
    "\n",
    "- 분할된 텍스트를 벡터 표현(임베딩 벡터)으로 변환한다.\n",
    "- LangChain은 OpenAI, HuggingFace 등 다양한 임베딩 모델을 지원하며, 동일한 인터페이스로 사용할 수 있다.\n",
    "- [임베딩모델의 메서드](https://reference.langchain.com/python/langchain/embeddings/#langchain.embeddings.init_embeddings)\n",
    "\n",
    "    - **`embed_documents(texts: List[str])`**\n",
    "        - 여러 문서를 받아 벡터화(임베딩)한다.\n",
    "        - Context를 벡터화 할 때 사용한다.\n",
    "    - **`embed_query(text: str)`**\n",
    "        - 하나의 문자열(문서)을 받아 벡터화한다.\n",
    "        - Query를 벡터화 할 때 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff941301-56f5-4219-89e8-6b54d5afd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "        \"나는 고양이와 개 중 반려동물로 개를 키우고 싶습니다.\",\n",
    "        \"이 강아지 품종은 진도개 입니다. 국제 표준으로 중대형견으로 분류되며 다리가 길어 체고가 높은 편에 속합니다.\",\n",
    "        \"日本の市内バスの運賃は主に距離によって決まり、地域やバス会社によって異なる場合があります\",                 # 일본의 시내버스 요금은 주로 거리에 따라 결정되며, 지역 및 버스 회사에 따라 다를 수 있습니다.\n",
    "        \"Bus fares in the United States vary from city to city, but are generally around $2.90 for a regular bus.\", # 미국의 버스 요금은 도시마다 다르지만, 일반적으로 정기 버스의 경우 2.90달러 정도입니다.\n",
    "        \"광역버스 요금은 일반 3000원, 청소는 1800원, 어린이 1500원 입니다.\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465811fa-32dd-44f3-96f9-c6193cb414ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702aae4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82d02707-99d9-4d48-826f-ae446a405fc6",
   "metadata": {},
   "source": [
    "# 벡터 데이터베이스(Vector Database)\n",
    "\n",
    "![rag_vector_store](figures/rag_vector_store.png)\n",
    "\n",
    "- **벡터 데이터베이스란**\n",
    "-  벡터 데이터베이스는 데이터를 고차원 벡터(임베딩)로 변환하여 저장하고, 벡터 간의 유사도를 기반으로 검색과 관리를 수행하는 특수한 형태의 데이터베이스이다.\n",
    "\n",
    "- **주요 특징**\n",
    "  - 텍스트, 이미지, 오디오 등의 비정형 데이터를 수치 벡터로 변환하여 저장\n",
    "   - 코사인 유사도, 유클리드 거리 등을 이용한 벡터 간 유사도 계산을 통한 검색\n",
    "   - 근사 최근접 이웃(Approximate Nearest Neighbor, ANN) 알고리즘을 통한 빠른 검색을 지원.\n",
    "\n",
    "## 벡터 데이터베이스와 딥러닝\n",
    "- 벡터 데이터베이스는 딥러닝 기술의 발전과 깊은 관련이 있다.\n",
    "- 딥러닝 모델은 학습 과정에서 데이터의 특징을 추출하는 방법을 함께 학습한다. 충분한 데이터를 학습한 딥러닝 모델은 **데이터의 특성을 설명하는 특성 벡터(feature vector)를 효과적으로 생성**할 수 있다.\n",
    "- 이때 추출된 특성 벡터는 고차원 데이터(RAW Data)를 저차원 공간에서 표현한 **임베딩 벡터**다.\n",
    "    - > **임베딩**은 고차원 데이터를 저차원 공간으로 변환하여 표현하는 방법으로, 정보 손실을 최소화하면서 데이터 간의 의미 있는 관계를 벡터 공간에서 유지한다.\n",
    "- 딥러닝 모델로 추출한 데이터의 특징(feature vector)을 임베딩 공간에 배치하면, 비슷한 데이터는 가까이, 그렇지 않은 데이터는 멀리 배치된다.\n",
    "- 이러한 특성을 활용하면 임베딩 벡터 간의 거리를 계산해 유사한 데이터를 효과적으로 검색할 수 있다. 벡터 데이터베이스는 이러한 임베딩 벡터의 특성을 기반으로 개발되었다.\n",
    "- 딥러닝 기술의 발전과 폭넓은 활용으로 임베딩 데이터의 사용이 증가하면서, 이를 저장하고 관리하는 기능에 특화된 데이터베이스에 대한 수요도 증가해 다양한 벡터 데이터베이스가 등장했다.\n",
    "\n",
    "## LLM과 벡터 데이터베이스\n",
    "- ChatGPT(LLM)의 등장 이후 벡터 데이터베이스는 폭발적인 주목을 받았다.\n",
    "- 임베딩 벡터의 유사도를 기반으로 문서를 검색하는 RAG(Relevant Augmented Generation) 기술은 LLM의 환각(할루시네이션) 현상을 줄이고, LLM을 추가 학습하지 않고도 최신 정보를 효율적으로 활용할 수 있는 핵심 기법으로 자리 잡았다.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a65063-9482-4fdb-9ada-941eb08fb3b2",
   "metadata": {},
   "source": [
    "## 벡터 데이터베이스 종류\n",
    "![img](figures/vector_database.png)\n",
    "\n",
    "<<https://blog.det.life/why-you-shouldnt-invest-in-vector-databases-c0cd3f59d23c>>\n",
    "\n",
    "### 주요 벡터 데이터베이스 종류\n",
    "- **Qdrant**\n",
    "    - Rust로 개발된 고성능 벡터 검색 엔진으로, 실시간 근사 최근접 이웃 검색을 제공한다.  \n",
    "    - 추천 시스템에 특화되어 있으며, 벡터 임베딩 저장과 유사도 쿼리를 효율적으로 수행한다.\n",
    "- **Pinecone**\n",
    "    - 클라우드 기반의 완전 관리형 벡터 데이터베이스 서비스로, 간단한 API를 통해 벡터 데이터를 관리할 수 있다.  \n",
    "    - 자동 확장성과 고가용성을 제공하며, 실시간 데이터 수집과 유사성 검색에 최적화되어 있다.\n",
    "    - 가장 쉽게 시작할 수 있는 관리형 서비스를 제공한다.\n",
    "- **Chroma**\n",
    "    - 벡터 임베딩을 효율적으로 저장하고 검색할 수 있는 오픈소스 데이터베이스로, AI 및 머신러닝 애플리케이션에 최적화되어 있다.\n",
    "    - 대규모 임베딩 저장에 최적화되어 있다.\n",
    "- **FAISS**\n",
    "    - Facebook AI에서 개발한 고성능 벡터 검색 라이브러리로, 고차원 벡터의 효율적인 유사성 검색을 위해 최적화되어 있다.\n",
    "    - GPU를 활용해 계산 성능을 높이며, 벡터 양자화 기술을 활용하여 메모리 사용을 최적화한다.\n",
    "    - 근사 최근접 이웃 검색(ANNS)에 최적화되어 있다.\n",
    "- **Milvus**\n",
    "    - 오픈소스 벡터 데이터베이스로, 대규모 벡터 데이터를 효율적으로 저장하고 검색할 수 있다.  \n",
    "    - 분산 아키텍처를 채택하여 확장성이 뛰어나며, IVF_PQ, DiskANN 등 다양한 인덱싱 알고리즘을 지원한다.\n",
    "    - 대규모 데이터셋 처리에 가장 적합한 솔루션이다.\n",
    "- **Weaviate**\n",
    "    - 오픈소스 벡터 데이터베이스로, 텍스트, 이미지, 오디오 등 다양한 비정형 데이터를 벡터로 저장하고 검색할 수 있다.  \n",
    "    - GraphQL API를 통해 접근 가능하며, 내장된 머신러닝 모듈을 통해 가장 강력한 의미론적 검색 기능을 제공한다.\n",
    "- **Elasticsearch**\n",
    "    - HNSW 알고리즘을 사용하여 벡터 검색을 구현하는 검색 엔진이다.\n",
    "    - 전통적인 검색 기능과 벡터 검색을 효과적으로 결합할 수 있어, 하이브리드 검색에 가장 적합하다.\n",
    "- **PGVector**\n",
    "    - PostgreSQL의 확장 모듈로, 벡터 데이터를 저장하고 유사성 검색을 수행할 수 있게 해준다.  \n",
    "    - SQL과 통합된 벡터 연산이 가능하며, L2 거리, 코사인 거리, 내적 등 다양한 거리 측정 방식을 지원한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf3f6fe-c5e2-4c4f-9ef8-2cf5850f1bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1336f523-0b76-419c-8e46-fa96bdbcbdd6",
   "metadata": {},
   "source": [
    "# Langchain - Vector Store 연동 \n",
    "- Langchain은 다양한 벡터 데이터베이스와 연동할 수 있다.\n",
    "- 벡터 데이터베이스 마다 API가 다르기 때문에, Langchain을 사용하면 동일한 interface로 사용할 수 있다.\n",
    "\n",
    "## **VectorStore**\n",
    "- Langchain이 지원하는 모든 벡터 데이터베이스는 **VectorStore** 인터페이스를 구현한다.\n",
    "- 그래서 Langchain에서는 벡터 데이터베이스를 **Vector Store** 라고 한다.\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/\n",
    "\n",
    "### Vector Store 연결\n",
    "- Vector DB와 연결하는 메소드\n",
    "- `VectorStore.from_documents()`\n",
    "  - Document들을 insert 하면서 연결.\n",
    "  - Database가 있으면 연결, 없으면 생성하면서 연결한다.\n",
    "  - Parameter\n",
    "    - documents: insert할 문서들을 list[Document]로 전달.\n",
    "    - embedding model\n",
    "    - vector db에 연결하기 위한 설정들을 넣어준다.\n",
    "-`VectorStore()`\n",
    "  - vector db와 연결만 한다.\n",
    "  - Database가 있으면 연결, 없으면 생성하면서 연결한다.\n",
    "  - Parameter\n",
    "    - embedding model\n",
    "    - vector db에 연결하기 위한 설정들을 넣어준다.\n",
    "## InMemoryVectorStore\n",
    "- langchain에서 제공하는 메모리 기반 벡터 데이터베이스이다.\n",
    "- Data들을 Dictionary를 사용해 메모리에 저장하며, 검색 할 때 코사인 유사도(cosine similarity)를 계산하여 조회한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcddfb-0fd3-4cb8-a4f0-b72d1988d6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1092d6e3-2c41-426d-ac58-5f4ba1201ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc4641-857c-47c1-80ff-5f4c2651a4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0da7c8f-c1be-4ddf-a935-90b22eac1f11",
   "metadata": {},
   "source": [
    "# 실습\n",
    "1. text loading\n",
    "2. text split\n",
    "3. embedding + vector store(InMemoryVectorStore)에 저장\n",
    "4. query(질의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349be3ce-539e-4d18-bc2b-67e8100ebcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152a3ac6-6f56-41ea-9c60-6a982226eb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d01f0-2fd7-4795-85a1-4ce9ea26a00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2c15ed2-e9d6-4361-9d9e-0dfaf650de41",
   "metadata": {},
   "source": [
    "## MMR(최대 한계 관련성-Maximal Marginal Relevance) 알고리즘 적용\n",
    "최대 한계 관련성(Maximal Marginal Relevance, MMR) 알고리즘은 정보 검색 및 요약에서 검색 결과의 **관련성**과 **다양성**을 동시에 고려하여 최적의 결과를 제공하는 방법이다. \n",
    "이 알고리즘은 사용자 쿼리와의 관련성을 최대화하면서도 중복 정보를 최소화하여 다양한 정보를 제공하는 것을 목표로 한다.\n",
    "\n",
    "1. **관련성과 다양성의 균형 조절**: MMR은 사용자 쿼리와 문서 간의 유사성 점수와 이미 선택된 문서들과의 다양성 점수를 조합하여 각 문서의 최종 점수를 계산한다. 이를 통해 관련성이 높으면서도 중복되지 않는 문서를 선택한다.\n",
    "\n",
    "2. **수학적 정의**\n",
    "   $$\n",
    "   \\text{MMR} = \\lambda \\cdot \\text{Sim}(d, Q) - (1 - \\lambda) \\cdot \\max_{d' \\in D'} \\text{Sim}(d, d')\n",
    "   $$\n",
    "\n",
    "   - $\\text{Sim}(d, Q)$: 문서 $d$와 쿼리 $\\text{Q}$ 사이의 유사성. (문서 유사성 계산)\n",
    "   - $\\max_{d' \\in D'} \\text{Sim}(d, d')$: 문서 $d$와 이미 선택된 문서 집합 $D'$ 중 가장 유사한 문서와의 유사성. (문서 다양성 계산)\n",
    "   - $\\lambda$: 유사성과 다양성의 중요도를 조절하는 매개변수(parameter)\n",
    "3. **적용 분야**: MMR은 정보 검색, 추천 시스템, 문서 요약 등에서 활용된다. 특히 LLM 검색에서 성능 향상이 입증되었다.\n",
    "\n",
    "### `vectorStore.max_marginal_relevance_search()` 메소드\n",
    "  - MMR 알고리즘을 적용한 검색을 수행한다.\n",
    "  - **파라미터**\n",
    "    - **query**: 사용자로부터 입력받은 검색 쿼리\n",
    "    - **k**: 최종적으로 선택할 문서의 수\n",
    "    - **fetch\\_k**: MMR 알고리즘 적용 시 고려할 상위 문서의 수\n",
    "    - **lambda_mult**: 쿼리와의 유사성과 선택된 문서 간의 다양성 사이의 균형을 조절하는 매개변수. $\\lambda = 1$이면 유사성만 고려하고, $\\lambda = 0$이면 다양성만을 최대화한다.\n",
    "    - **filter**: 검색 결과를 필터링할 조건을 지정한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a398d-f0f6-416f-aad8-4c97ced68992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908b3c9c-8f56-48fd-a952-9f79f0b75f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab46f5a-14b4-4b0d-a6ea-4dd855a452c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
