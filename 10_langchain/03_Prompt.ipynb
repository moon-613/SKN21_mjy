{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e32a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/15(월) 15:40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f3698b-4cce-4d82-9a4b-e288c5b2fba8",
   "metadata": {},
   "source": [
    "# Model IO\n",
    "- **Model IO**는 프롬프트(prompt)를 언어 모델에 입력하고, 그 결과로 생성된 출력을 처리하는 일련의 과정과 그 구성 요소를 의미한다.\n",
    "- 주로 **프롬프트 템플릿**, **언어 모델**, **출력 파서**로 구성된다.\n",
    "\n",
    "## 모델 IO 구성 요소\n",
    "- **프롬프트 템플릿**\n",
    "  - LLM(대규모 언어 모델, Large Language Model)에 전달할 프롬프트를 생성하는 데 사용되는 형식이다.\n",
    "  - 사용자 입력이나 고정된 형식을 기반으로 프롬프트를 구조화하여 LLM에 전달한다.\n",
    "- **언어 모델**\n",
    "\n",
    "  - LLM은 프롬프트를 바탕으로 텍스트를 생성하거나 입력 내용을 분석하여 결과를 도출한다.\n",
    "\n",
    "- **출력 파서**\n",
    "\n",
    "  - LLM의 출력에서 필요한 정보를 추출하거나, 시스템에서 활용하기 적합한 형식으로 변환하는 역할을 한다.\n",
    "  - 출력 데이터를 정제하고 구조화하여 다음 단계에서 쉽게 활용할 수 있도록 후처리한다.\n",
    "\n",
    "![model id](figures/model_io.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8d1d7-a52d-4eff-83fc-35e43e265b81",
   "metadata": {},
   "source": [
    "# 프롬프트(Prompt)\n",
    "\n",
    "- 생성형 인공지능 모델에게 작업을 요청하기 위해 입력하는 값이다.\n",
    "- 일반적으로 사람이 사용하는 자연어로 작성된다.\n",
    "\n",
    "## 프롬프트 엔지니어링(Prompt Engineering)\n",
    "\n",
    "- 생성형 인공지능 모델로부터 **원하는 결과를 얻기 위해 프롬프트를 설계하고 최적화하는 기법**을 말한다.\n",
    "- 더 나은 품질의 응답을 얻기 위해 프롬프트를 구조화하고 조정하는 작업이다.\n",
    "- 프롬프트 엔지니어링은 생성형 인공지능 모델의 능력과 특성을 깊이 이해한 뒤, **일관되고 정확한 응답이 생성되도록** 프롬프트를 작성하는 데 초점을 둔다.\n",
    "  - 생성형 인공지능 모델은 각각 성능과 동작 방식에 차이가 있으므로, 목적에 맞는 모델을 선택하고 그에 맞는 프롬프트를 작성하는 것이 중요하다.\n",
    "  - 핵심은 **사용자의 의도에 부합하는 응답을 일관되게 이끌어내는 것**이다.\n",
    "    - 같은 질문이라도 생성형 인공지능은 응답이 조금씩 달라질 수 있다.\n",
    "    - 하지만 의미가 달라지거나 의도가 왜곡되면 안 되므로, **의미의 일관성을 유지하는 프롬프트 설계**가 중요하다.\n",
    "- 프롬프트 엔지니어링은 별도의 추가 학습(fine-tuning) 없이도 원하는 결과를 얻을 수 있게 해주어, **언어 모델 구축에 필요한 시간과 비용을 획기적으로 줄여준다**.\n",
    "  - 프롬프트는 자연어로 작성되므로, 딥러닝이나 모델 구조에 대한 깊은 전문지식 없이도 인공지능의 응답 품질을 향상시킬 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4c15a5-2ecb-465d-b9fe-3e0e6741db99",
   "metadata": {},
   "source": [
    "## 프롬프트의 구성 요소\n",
    "\n",
    "프롬프트는 일반적으로 다음 네 가지 요소로 구성될 수 있다.\n",
    "단, 모든 프롬프트가 이 모든 요소를 반드시 포함해야 하는 것은 아니다.\n",
    "\n",
    "- **지시(Instruction)**: 생성형 인공지능 모델이 수행해야 할 작업에 대한 명확한 지침.\n",
    "  - 예: “다음 문장을 요약하라”, “코드를 설명하라”\n",
    "- **문맥(Context)**: 더 정확한 응답을 유도하기 위해 제공하는 배경 정보나 추가 문맥.\n",
    "  - 예: 대화 이력, 도메인 지식, 사용자 정보 등\n",
    "- **입력 데이터(Input Data)**: 모델이 처리해야 하는 구체적인 입력값. 이는 질문 형태일 수도 있고, 문서, 표, 코드 등 다양한 형태의 데이터일 수 있다.\n",
    "- **출력 지시자(Output Indicator)**: 모델이 생성할 응답의 형식이나 조건을 지정하는 요소.\n",
    "  - 예: “JSON 형식으로 출력하라”, “목록 형태로 작성하라”, “200자 이내로 요약하라” \n",
    "\n",
    "\n",
    "- 예:\n",
    "```markdown\n",
    "## Instruction (지시)\n",
    "다음 뉴스 기사를 읽고 핵심 내용을 요약하라.\n",
    "\n",
    "## Context (문맥)\n",
    "사용자는 바쁜 직장인으로, 전체 기사를 읽을 시간이 없다. 핵심 정보만 빠르게 파악하고 싶어한다.\n",
    "\n",
    "## Input Data (입력 데이터)\n",
    "[기사 원문]\n",
    "오늘 오전, 서울 강남구 일대에 시간당 80mm가 넘는 집중호우가 내려 도로 일부가 침수되고, 차량 통제가 이루어졌다. 기상청은 이 같은 집중호우가 오후까지 계속될 것으로 전망하면서 시민들의 외출 자제를 당부했다. 서울시 역시 재난 문자를 통해 대중교통 이용을 권고하고 있다. ...\n",
    "\n",
    "## Output Indicator (출력 지시자)\n",
    "한 문단(3줄 이내)으로 요약하라. 일반인이 쉽게 이해할 수 있는 문장을 사용하라.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84895274-7d51-417f-9284-86b2433f7f9a",
   "metadata": {},
   "source": [
    "# Prompt 작성 가이드\n",
    "한 번에 완성도 높은 프롬프트를 만드는 것은 쉽지 않다. **결과를 반복적으로 확인하고, 그에 따라 점진적으로 개선**해 나가는 과정이 필요하다.\n",
    "처음에는 간단한 프롬프트로 시작한 뒤, 답변을 검토하면서 다양한 요소와 맥락 정보(context)를 추가하며 점차 발전시킨다.\n",
    "\n",
    "## 1. 명확성 (Clarity)\n",
    "\n",
    "모델이 무엇을 해야 하는지 오해 없이 이해할 수 있도록 프롬프트의 목적과 지시를 분명하고 논리적으로 작성한다. 프롬프트 내용에 추상적이거나 모호한 표현보다는 구체적이고 명확한 용어를 사용한다.\n",
    "\n",
    "- **좋은 예시**:\n",
    "\n",
    "  ```\n",
    "  이 문장을 더 간결한 표현으로 바꿔줘.\n",
    "  ```\n",
    "   \"간결한 표현\" 이라는 명확한 지시를 포함하고 있다.\n",
    "- **나쁜 예시**:\n",
    "\n",
    "  ```\n",
    "  이 문장을 다르게 바꿔줘.\n",
    "  ```\n",
    "  내용을 다르게 하려는 건지 단어를 다르게 하라는 건지 \"다르게\"의 의미가 불분명하다. \n",
    "\n",
    "\n",
    "## 2. 구체성 (Specificity)\n",
    "\n",
    "모델의 답변 범위를 좁혀 원하는 결과를 얻으려면, **대상, 형식, 범위, 답변 글자 수 등의 제약 조건을 구체적으로 명시하고, 구체적인 정보와 조건을 함께 제시하는 것이 효과적**이다\n",
    "\n",
    "- **좋은 예시**:\n",
    "\n",
    "  ```\n",
    "  한국의 최근 5년 동안 인공지능 산업 성장률을 표 형식으로 나타내라.\n",
    "  ```\n",
    "  정확히 원하는 주제와 출력 형식을 구체적으로 알려주고 있다.\n",
    "- **나쁜 예시**:\n",
    "\n",
    "  ```\n",
    "  한국 인공지능 산업을 말해줘.\n",
    "  ```\n",
    "  인공지능 산업의 어떤 측면에 대해 말하는지 알 수 없어 대상범위가 너무 넓다.\n",
    "\n",
    "\n",
    "## 3. 간결성 (Conciseness)\n",
    "\n",
    "프롬프트는 핵심만 간결하게 전달하되, 필요한 모든 정보를 담아야 한다. 불필요하게 긴 문장은 오히려 혼란을 준다.\n",
    "\n",
    "- **좋은 예시**:\n",
    "\n",
    "  ```\n",
    "  삼국시대 신라의 통일 과정을 3문장으로 요약하라.\n",
    "  ```\n",
    "\n",
    "- **나쁜 예시**:\n",
    "\n",
    "  ```\n",
    "  신라가 삼국을 통일하게 된 배경, 과정, 결과, 그 이후의 역사적 영향을 모두 말해줘. 하지만 너무 길지 않게 짧게 요약해서 적당히 답해주길 바래.\n",
    "  ```\n",
    "\n",
    "## 4. 명시적 지시 (Explicit Instruction)\n",
    "\n",
    "모델이 해야 **무엇을 해야 하는 지를** 구체적이고 명확하게 지시한다. 모호한 요청은 잘못된 응답을 초래할 수 있다.   \n",
    "**명확성이 내용의 구체/명확성**이라면 **명시적 지시는 모델이 해야하는 일**의 구체/명확성을 말한다.\n",
    "\n",
    "- **좋은 예시**:\n",
    "\n",
    "  ```\n",
    "  아래 문장을 감정 분석하여 긍정, 부정, 중립 중 하나로 분류하라:\n",
    "  \"오늘 날씨가 정말 좋다.\"\n",
    "  ```\n",
    "- **나쁜 예시**:\n",
    "\n",
    "  ```\n",
    "  이 문장은 어때?\n",
    "  ```\n",
    "\n",
    "## 5. 제약 조건 명시 프롬프트 (Constraint Prompting)\n",
    "\n",
    "출력 형식이나 조건을 명확히 제한하여 지시하는 기법이다. 예: “100자 이내로 요약하라” 혹은 “세 가지 항목으로 목록을 만들어라.” 이처럼 프롬프트에 조건을 명시하면, 모델은 이를 충실히 따르려 한다.\n",
    "\n",
    "- **제약 조건 요소들**:\n",
    "  - 글자수/문장 수 제한\n",
    "  - 출력 형식(JSON, 표 등)\n",
    "  - 어조 유지\n",
    "  - 금지어 제외\n",
    "  - 필수 키워드 포함\n",
    "- **주의 사항**: 조건이 지켜지지 않을 경우 프롬프트를 더 구체화하거나 시스템 메시지를 사용할 수 있다.\n",
    "\n",
    "- **좋은 예시**:\n",
    "\n",
    "  ```\n",
    "  한국, 미국, 중국의 인구를 다음 형식의 표로 나타내라:\n",
    "\n",
    "  | 국가 | 인구 (백만명) |\n",
    "  |------|--------------|\n",
    "  |      |              |\n",
    "  ```\n",
    "  ```\n",
    "  다음 문장을 세 줄로 요약한다. 각 줄은 10단어 이내로 작성한다.\n",
    "  [요약할 내용]\n",
    "  ...\n",
    "  ```\n",
    "\n",
    "## 6. 역할 정의 (Role Definition, Persona)\n",
    "\n",
    "모델에게 명확한 역할이나 페르소나를 부여하여 일관된 응답을 얻는다. \n",
    "페르소나(persona, 역할)을 지정하면 **모델의 사고방식, 응답구조, 언어 선택, 논리 전개방식, 답변 어투와 같은 스타일**을 그 역할에 맞게 유도할 수있다. 역할을 부여하면 모델의 응답을 원하는 맥락과 분야에 맞춰 조율 할 수있고 설명이나 추론의 명확성과 일관성을 높일 수있다.   \n",
    "또한 여러 페르소나를 설정하면 다자간 토론이나 대화 시뮬레이션을 진행할 수 있다.\n",
    "\n",
    "- **좋은 예시**:\n",
    "\n",
    "  ```\n",
    "  너는 초등학교 과학 선생님이다. 물의 순환 과정을 학생들에게 쉽게 설명하라.\n",
    "  ```\n",
    "  초등학교 과학 선생님이라는 역할에 맞게 쉬운 말투, 따듯한 어조, 단계적 설명 등을 사용해 응답한다.\n",
    "  \n",
    "  ```\n",
    "  토론자 A는 기술 낙관주의자, B는 기술 회의론자이다. 서로의 입장을 정리한 토론을 생성하라.\n",
    "  ```\n",
    "\n",
    "## 7. 단계별 지시 (Step-by-Step Instruction)\n",
    "\n",
    "복잡한 작업을 명확하고 실행가능한 단계들로 나눠 요청한다. \n",
    "\n",
    "  - **나쁜 예시**\n",
    "\n",
    "  ```\n",
    "  우리 회사 매출 데이터를 분석해서 좋은 보고서를 만들어줘. 작년과 비교하고 문제점도 찾고 해결책도 제시해줘.\n",
    "  ```\n",
    "\n",
    "  - **좋은 예시**:\n",
    "  ```\n",
    "  다음 단계에 따라 비즈니스 분석 보고서를 작성해주세요:\n",
    "\n",
    "  **1단계: 데이터 검토**\n",
    "  - 첨부된 매출 데이터 CSV 파일을 읽고 구조를 파악하세요\n",
    "  - 데이터의 기간, 항목, 누락값 여부를 확인하세요\n",
    "  \n",
    "  **2단계: 기초 분석**\n",
    "  - 2024년 월별 매출 추이를 계산하세요\n",
    "  - 2023년 같은 기간과 비교하여 증감률을 구하세요\n",
    "  - 상위 5개 제품군별 매출 비중을 분석하세요\n",
    "  \n",
    "  **3단계: 문제점 식별**\n",
    "  - 매출 감소가 발생한 구간을 찾아내세요\n",
    "  - 감소폭이 10% 이상인 제품군을 특정하세요\n",
    "  - 계절성 요인과 구조적 요인을 구분하세요\n",
    "  \n",
    "  **4단계: 해결책 제시**\n",
    "  - 각 문제점에 대해 구체적인 개선안을 3개씩 제시하세요\n",
    "  - 예상 효과와 실행 난이도를 5점 척도로 평가하세요\n",
    "  - 우선순위 순으로 정렬하세요\n",
    "  \n",
    "  **5단계: 최종 보고서**\n",
    "  - 위 분석을 바탕으로 경영진용 요약 보고서를 작성하세요\n",
    "  - 차트 3개와 핵심 지표 테이블을 포함하세요\n",
    "  - 결론은 3줄 이내로 압축하세요\n",
    "  ```\n",
    "\n",
    "## 8. 샷 수 제어 프롬프트 (Zero-shot, One-shot, Few-shot)\n",
    "\n",
    "**샷 수 제어**란 예시(데몬스트레이션)의 수에 따라 제로샷, 원샷, 퓨샷으로 나누는 기법이다.\n",
    "\n",
    "- **제로샷**: 예시 없이 바로 요청.\n",
    "- **원샷**: 하나의 예시 제공 후 요청.\n",
    "- **퓨샷**: 여러 개의 예시 제공 후 요청.\n",
    "\n",
    "- **좋은 예시** (Few-shot 예시):\n",
    "\n",
    "  ```\n",
    "  예시:\n",
    "  Q: 일본의 수도는?  \n",
    "  A: 도쿄  \n",
    "  Q: 영국의 수도는?  \n",
    "  A: 런던  \n",
    "\n",
    "  Q: 호주의 수도는?  \n",
    "  A:\n",
    "  ```\n",
    "\n",
    "## 9. 열린 질문(Open-ended question) 사용\n",
    "구체적인 지시 대신 AI에게 무엇이 필요한지를 묻는 질문을 한다. 이를 통해 **우리가 생각지 못했던 다양한 관점에서 문제를 해결**할 수 있다.\n",
    "열린 질문은 모델의 창의성, 추론 능력, 통찰력을 끌어내는 데 매우 유용하다.\n",
    "특히 아이디어 발상, 브레인스토밍, 전략 수립, 사용자 인터뷰 시뮬레이션 등에 효과적이다.\n",
    "- **예시**:\n",
    "  ```\n",
    "  우리 서비스가 고객에게 제공할 수 있는 새로운 가치는 무엇이 있을까?\n",
    "\n",
    "  현재 시장에서 간과되고 있는 기회는 어떤 게 있을까?\n",
    "\n",
    "  이 기능이 실제로 사용자의 삶에 어떤 영향을 줄 수 있을까?\n",
    "  ```\n",
    "\n",
    "## 10. 맥락(context) 제공\n",
    "요청하는 작업의 배경을 설명한다. 이를 통해 모델의 응답에 정확도, 일관성, 관련성을 높일 수 있다.\n",
    "\n",
    "- **맥락없는 예시**:\n",
    "  ```\n",
    "  고객 이탈을 줄일 수 있는 전략은 무엇인가?\n",
    "  ```\n",
    "- **맥락을 제공한 예시**:\n",
    "  ```\n",
    "  우리는 월 20%의 고객 이탈률을 겪고 있는 구독 기반 온라인 교육 서비스이다.\n",
    "  주요 고객층은 30대 직장인이고, 이탈 주요 원인은 콘텐츠 부족과 동기 저하이다.\n",
    "  이탈률을 줄이기 위한 실질적인 전략을 제안해줘.\n",
    "  ```\n",
    "\n",
    "## 11. 윤리적 사용 (Ethical Usage)\n",
    "\n",
    "모델이 차별적, 공격적, 부정확하거나 편향된 답변을 생성하지 않도록 프롬프트 내용을 주의해서 작성한다.\n",
    "\n",
    "- **좋은 예시**:\n",
    "\n",
    "  ```\n",
    "  인공지능 기술이 사회에 미치는 긍정적 영향과 부정적 영향을 균형 있게 설명하라.\n",
    "  ```\n",
    "\n",
    "- **나쁜 예시**:\n",
    "\n",
    "  ```\n",
    "  인공지능이 인간의 일자리를 빼앗는다는 것을 증명해봐.\n",
    "  ```\n",
    "  인공지능이 사람의 일자리를 뺏는다는 결론을 미리 내리고 질문하고 있다. 이는 특정 결론을 강요하는 형태로 모델이 편향된 정보만 수집하여 편향된 결론을 내리도록 유도한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0d968",
   "metadata": {},
   "source": [
    "# 주요 프롬프트 엔지니어링 기법\n",
    "\n",
    "## Chain of Thought (사고 연쇄-CoT)\n",
    "\n",
    "### 개념\n",
    "\n",
    "Chain of Thought: 복잡한 문제를 해결할 때 단계별로 사고 과정을 보여주는 방법이다. 마치 수학 문제를 풀 때 중간 과정을 하나씩 적어가며 답을 구하는 것처럼, AI가 답을 도출하는 과정을 차근차근 설명하는 기법.\n",
    "\n",
    "일반적으로 AI는 질문을 받으면 바로 최종 답만 제시한다. 하지만 Chain of Thought를 사용하면 \"첫 번째로 이것을 생각하고, 두 번째로 저것을 고려하고, 따라서 결론은...\" 같은 식으로 사고 단계를 명확히 보여준다.\n",
    "\n",
    "이 방법을 사용하면 복잡한 추론이나 수학 문제, 논리적 사고가 필요한 상황에서 더 정확한 답을 얻을 수 있다. 또한 AI가 어떤 과정을 거쳐 그 답에 도달했는지 이해할 수 있어서 더 신뢰할 수 있다.\n",
    "\n",
    "### 방법\n",
    "- **Zero-shot Chain of Thought** (예제 안 줌)\n",
    "    - 프롬프트에 \"단계적으로 풀어보자\", \"차근 차근 생각해보자\", \"Think step by step\" 같은 말을 입력해 모델이 스스로 단계를 밟아가며 추론하도록 한다.\n",
    "-  **Few-shot Chain of Thought** (예제 줌)\n",
    "    -  직접 문답 형식의 예를 작성해서 프롬프트에 넣는다.\n",
    "\n",
    "### 예시\n",
    "\n",
    "```\n",
    "Q: 카페에서 커피 3잔과 케이크 2개를 샀는데, 커피 한 잔이 4,500원, 케이크 한 개가 6,000원일 때 총 얼마를 지불해야 하나요?\n",
    "\n",
    "A: 단계별로 계산해보겠습니다.\n",
    "\n",
    "1단계: 커피 총 가격 계산\n",
    "- 커피 한 잔: 4,500원\n",
    "- 커피 3잔: 4,500원 × 3 = 13,500원\n",
    "\n",
    "2단계: 케이크 총 가격 계산  \n",
    "- 케이크 한 개: 6,000원\n",
    "- 케이크 2개: 6,000원 × 2 = 12,000원\n",
    "\n",
    "3단계: 총 금액 계산\n",
    "- 커피 총 가격 + 케이크 총 가격\n",
    "- 13,500원 + 12,000원 = 25,500원\n",
    "\n",
    "따라서 총 25,500원을 지불해야 합니다.\n",
    "\n",
    "Q: 사과 10개, 배 3개, 수박 5통을 샀습니다. 사과는 개당 5300원, 배는 12000원, 수박은 21000원입니다. 총 비용은 얼마인가요?\n",
    "\n",
    "A:\n",
    "```\n",
    "\n",
    "\n",
    "## Tree-of-Thought (생각의 나무 - ToT)\n",
    "Tree-of-Thought (ToT) 프롬프트 엔지니어링 기법: 복잡한 문제 해결을 위한 사고 과정을 트리 구조로 모델링 해서 LLM 모델이 단일한 직선적인(Sequential) 사고과정이 아니라, **다양한 경로(branch)를 통해** 문제를 해결하도록 유도하는 프롬프트 설계 기법.\n",
    "\n",
    "기존의 Chain-of-Thought(CoT)는 문제를 \"하나의 직선적 단계\"로 나누어 풀이.\n",
    "반면, ToT는 각 단계에서 여러 가지 대안적 접근이나 아이디어를 분기점(branch)으로 만들어 트리처럼 확장하면서, 각 분기마다 탐색(explore)과 평가(evaluate)를 반복.\n",
    "이러한 방식은 AI에게 \"여러 가능성을 동시에 탐색-비교-선택\"하게 하여 **수학적 문제 해결, 창작 활동, 전략적 계획 수립, 코딩 문제, 의사결정**등 복잡한 추론이 필요한 영역에서 특히 효과적.\n",
    "\n",
    "### Tree-of-Thought 프롬프트 구조\n",
    "1. 문제 제시\n",
    "2. 하위 문제/접근 방식 분기 요청\n",
    "    - \"이 문제를 해결하는 다양한 방법을 생각해보세요.\"\n",
    "    - \"가능한 경우의 수, 가설, 전략을 모두 나열해보세요.\"\n",
    "3. 각 브랜치별 세부 풀이 요청\n",
    "    - \"각 방법(가지)마다 단계별로 자세히 풀이해주세요.\"\n",
    "4. 브랜치 평가/선택 요청\n",
    "    - \"각 방법의 장단점, 성공 가능성, 효율성을 평가하세요.\"\n",
    "    - \"가장 적합한 가지(접근법)를 선택하고, 그 이유를 설명하세요.\"\n",
    "5. 최종 해답 도출\n",
    "\n",
    "### 예시\n",
    "```\n",
    "문제: 도시 내 대중교통 시스템의 효율성을 높이는 방안을 제시하라.\n",
    "\n",
    "1. 이 문제를 해결하기 위한 여러 가지 방법(아이디어)을 나열하세요. 각 방법을 트리의 가지(branch)로 생각해보세요.\n",
    "\n",
    "2. 각 방법마다 구체적인 실행 방안과 예상되는 효과, 문제점을 단계별로 정리하세요.\n",
    "\n",
    "3. 각 방법(가지)별로 장단점을 평가하고, 현실적으로 가장 실행 가능한 방법을 선택하세요.\n",
    "\n",
    "4. 선택한 방법을 더욱 구체화하여 실행 계획을 작성하세요.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d8dc77",
   "metadata": {},
   "source": [
    "> ## 프롬프트 공유 사이트\n",
    "> - [Langchain Hub](https://smith.langchain.com/hub)\n",
    "> - [Promry](https://www.promry.com/ko)\n",
    "> - [오픈프롬프트](https://www.prpt.ai)\n",
    "> - [Prompt Hero](https://prompthero.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3eaa39-aac1-4547-97c1-2e8c895bf34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a144cc4-f26e-4ff9-ad34-682d1c75c121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb37ff-f870-473c-beac-5ade979cfa2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24d12956",
   "metadata": {},
   "source": [
    "# 프롬프트 템플릿 (Prompt Template)\n",
    "\n",
    "프롬프트 템플릿: 언어 모델(Large Language Model, LLM)에 입력할 **프롬프트를 생성하는 재사용 가능한 템플릿**. 프롬프트 작성 시 변수를 포함하여 템플릿화함으로써, 다양한 입력값에 유연하게 대응할 수 있으며, 일관성 있는 결과를 얻는 데 유리하다.\n",
    "\n",
    "## 프롬프트 템플릿의 목적\n",
    "\n",
    "* **재사용성**: 다양한 입력에도 동일한 구조의 프롬프트를 사용 가능.\n",
    "* **유지보수 용이성**: 프롬프트 구조를 표준화하여 관리하기 쉽다.\n",
    "* **자동화 적합성**: 파이프라인이나 응용프로그램 내에서 템플릿 기반으로 프롬프트를 자동 생성할 수 있다.\n",
    "\n",
    "## Langchain의 주요 Prompt Template\n",
    "\n",
    "1. `PromptTemplate`\n",
    "   - 지시형 프롬프트를 생성할 때 사용하는 가장 기본적인 텍스트 기반 템플릿이다.\n",
    "   - **특징**:\n",
    "     - 단순한 텍스트 포맷팅에 사용\n",
    "     - 변수는 중괄호 `{}`를 사용하여 표시\n",
    "     - LLM에게 명령을 내리는 형태의 프롬프트에 적합하다.\n",
    "2. `ChatPromptTemplate`\n",
    "   - 대화형(Chat) 언어 모델에서 사용되는 프롬프트 템플릿으로, 다양한 발화자 역할(예: 시스템, 사용자, AI)을 지정할 수 있다.\n",
    "   - **특징**:\n",
    "     -  역할 기반 메시지를 정의하여 대화 맥락을 유지하기 용이\n",
    "     -  시스템 메시지(지시), 사용자 메시지(입력), AI 메시지(LLM 응답) 등을 구성할 수있다.\n",
    "3. `FewShotPromptTemplate`\n",
    "   - 모델이 작업을 더 잘 수행할 수 있도록 하나 이상의 예제를 포함한 프롬프트를 생성하는 데 사용된다.\n",
    "   - **특징**:\n",
    "     - \"Few-shot learning을 개념을 활용하는 프롬프트를 생성한다.\n",
    "     - 입력 전에 유사한 문제-답변 예제를 제시하여 모델의 성능을 높일 수있다.\n",
    "   - **예시**:\n",
    "      ```python\n",
    "      from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "      examples = [\n",
    "          {\"input\": \"2+2\", \"output\": \"4\"},\n",
    "          {\"input\": \"3+5\", \"output\": \"8\"}\n",
    "      ]\n",
    "      example_prompt = PromptTemplate(template=\"Q: {input}\\nA: {output}\")\n",
    "\n",
    "      prompt = FewShotPromptTemplate(\n",
    "          examples=examples,\n",
    "          example_prompt=example_prompt,\n",
    "          prefix=\"Answer the following math questions:\",\n",
    "          suffix=\"Q: {query}\\nA:\"\n",
    "      )\n",
    "\n",
    "      prompt.invoke({\"query\":\"7 + 6\"})\n",
    "      ```\n",
    "\n",
    "      ```output\n",
    "      Answer the following math questions:\n",
    "      Q: 2+2\n",
    "      A: 4\n",
    "      Q: 3+5\n",
    "      A: 8\n",
    "      Q: 7+6\n",
    "      A:\n",
    "      ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe4364-c31d-44ab-a910-b62c22b8fc68",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿 사용법\n",
    "\n",
    "- 템플릿은 **문자열로 정의**하고, 변수는 `{변수명}` 형식으로 지정한다. 이 변수는 나중에 실제 값으로 대체된다.\n",
    "  - 예시: `\"{country}의 수도는 어디인가요?\"`\n",
    "  - 프롬프트에 `{}` 를 literal로 입력해야 하는 경우 `{{ }}` 로 입력한다.\n",
    "- 생성한 문자열 템플릿을 이용해 Prompt Template 객체를 생성한다.\n",
    "\n",
    "### 공통 메소드\n",
    "\n",
    "프롬프트 템플릿 클래스에서 공통으로 사용하는 주요 메소드는 다음과 같다.\n",
    "\n",
    "- 템플릿 생성 메소드:\n",
    "  - `from_template()`: 문자열 기반 템플릿을 생성한다. `PromptTemplate`, `ChatPromptTemplate` 모두에서 사용된다.\n",
    "  - `from_messages()`: 메시지 객체 기반의 대화형 템플릿을 생성한다. `ChatPromptTemplate` 전용이다.\n",
    "- 프롬프트 생성 메소드:\n",
    "  - `format(변수=값, ...)`: 변수에 값을 넣어 최종 프롬프트 문자열을 생성한다.\n",
    "  - `format_messages(변수=값, ...)`: 메시지 리스트 형식의 프롬프트를 생성한다. `ChatPromptTemplate`에서 사용된다.\n",
    "  - `invoke(dict)`: 변수와 값을 딕셔너리 형태로 전달하여 프롬프트를 생성하고 실행한다.\n",
    "\n",
    "> ## invoke() 메소드\n",
    "> - `invoke()`는 Langchain의 핵심 클래스인 **Runnable**에서 제공하는 공통 메소드이다.\n",
    "> - **Runnable**은 LLM을 활용한 작업 흐름(Chain)을 구성하는 작업 단위 클래스들의 상위 클래스이다.\n",
    "> - `invoke()`는 입력 데이터를 처리하고 결과를 반환하는 메소드이며, 체인의 다음 단계로 결과를 전달한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbc96d-35aa-4930-b5c9-323dc308be3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb98707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"{name}, {name}님, {age}세.format(name=\"홍길동\", age=30 )\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1f0a56-f618-4ef1-ab89-58c405852448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# input_varuable(입력 변수): {변수명} => 나중에 채울 값의 자리를 지정하는 placeholder\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab32372-69f7-471e-a500-f5d7004a2251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.template\n",
    "prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1c002e0-c9f2-4a34-8373-5f07322d42b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국의 수도는 어디인가요?\n",
      "미국의 수도는 어디인가요?\n"
     ]
    }
   ],
   "source": [
    "# input_variable에 값을 넣어서 prompt 생성\n",
    "prompt_str1 = prompt.format(country=\"한국\")  # format(): keyword 인자로 입력\n",
    "print(prompt_str1)\n",
    "prompt_str2 = prompt.format(country=\"미국\")\n",
    "print(prompt_str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79854962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='독일의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_str3 = prompt.invoke({\"country\":\"독일\"})  # invoke: {input_variable: 넣을 값}\n",
    "prompt_str3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d600f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{country}의 수도는 어디입니까?\"\n",
    ")\n",
    "model = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "\n",
    "query = prompt.format(country=\"한국\")\n",
    "res = model.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df678bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국(대한민국)의 수도는 서울입니다. 만약 북한의 수도를 묻는 거라면 평양이 수도입니다.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77752b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "런던입니다.\n"
     ]
    }
   ],
   "source": [
    "query2 = prompt.invoke({\"country\":\"영국\"})\n",
    "res = model.invoke(query2)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b7ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울, 런던 간의 거리는 얼마나 되는지 km로 알려줘.\n",
      "text='워싱턴DC, 뉴욕 간의 거리는 얼마나 되는지 km로 알려줘.'\n"
     ]
    }
   ],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    template=\"{place1}, {place2} 간의 거리는 얼마나 되는지 km로 알려줘.\"\n",
    ")\n",
    "print(prompt2.format(place1=\"서울\", place2=\"런던\"))\n",
    "print(prompt2.invoke({\"place1\":\"워싱턴DC\", \"place2\":\"뉴욕\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20985600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='서울과 런던 사이의 대원거리(직선 거리)는 약 8,830 km 정도입니다.  \\n참고로 이 값은 지구 곡선을 고려한 대원거리이며, 실제 비행 거리(노선)는 기상·항로 등에 따라 다소 차이가 날 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1675, 'prompt_tokens': 23, 'total_tokens': 1698, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1600, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnF1UheYRmH6DqGygk3kCWxqZNFsc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b24f8-f80c-7540-b374-16925daaf01e-0' usage_metadata={'input_tokens': 23, 'output_tokens': 1675, 'total_tokens': 1698, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1600}}\n"
     ]
    }
   ],
   "source": [
    "query2 = prompt2.format(place1=\"서울\", place2=\"런던\")\n",
    "res = model.invoke(query2)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2702342e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'서울과 런던 사이의 대원거리(직선 거리)는 약 8,830 km 정도입니다.  \\n참고로 이 값은 지구 곡선을 고려한 대원거리이며, 실제 비행 거리(노선)는 기상·항로 등에 따라 다소 차이가 날 수 있습니다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae368775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# chatting 형식 message를 지원 - role과 content로 구성.\n",
    "# role: user/human - 사용자, 사람의 입력\n",
    "#       ai/assistant - 인공지능 (llm 모델)의 답변.\n",
    "#       system       - 전체 대화와 관련돼서 적용될 규칙 등을 설정하는 프롬프트. \n",
    "#                      (SystemMessge)\n",
    "# 1. [\n",
    "#     (\"role\", \"내용\")\n",
    "# ]\n",
    "# 2. [\n",
    "#     {\"role\":\"역할\", \"content\":\"\"}   # open ai 포맷\n",
    "# ]\n",
    "messages = [\n",
    "    (\"system\", \"당신은 {domain}전문 assistant입니다. 모든 답변은 {char_length} 단어 이하로 해주세요. \"),\n",
    "    (\"user\", \"{query}\")\n",
    "]\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e5c3cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['char_length', 'domain', 'query']\n",
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['char_length', 'domain'], input_types={}, partial_variables={}, template='당신은 {domain}전문 assistant입니다. 모든 답변은 {char_length} 단어 이하로 해주세요. '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(prompt.input_variables)\n",
    "print(prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc1d3c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='당신은 wine전문 assistant입니다. 모든 답변은 20 단어 이하로 해주세요. ', additional_kwargs={}, response_metadata={}), HumanMessage(content='크림 파스타에 어울리는 와인을 소개해줘.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = prompt.invoke(\n",
    "    {\"domain\": \"wine\", \"char_length\": 20, \"query\": \"크림 파스타에 어울리는 와인을 소개해줘.\"}\n",
    ")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = prompt.format_messages(domain='ai', char_length=10, query='LLM에 대해 정의해줘')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc8e0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aab8a259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크림 파스타엔 산미 중간의 바디 좋은 화이트가 어울려요: 샤도네이, 피노 그리오, 소비뇽 블랑, 베르멘티노.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c916452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='크림 파스타엔 산미 중간의 바디 좋은 화이트가 어울려요: 샤도네이, 피노 그리오, 소비뇽 블랑, 베르멘티노.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1592, 'prompt_tokens': 47, 'total_tokens': 1639, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1536, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnFIk8KCMkHSLDZPSBpiGHeCwarEh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b2509-50ed-7980-83e8-63667f298bcd-0', usage_metadata={'input_tokens': 47, 'output_tokens': 1592, 'total_tokens': 1639, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1536}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a87d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d1da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ec74eb1-3092-4dd3-bedf-48502392ed71",
   "metadata": {},
   "source": [
    "## MessagesPlaceholder\n",
    "\n",
    "- **MessagesPlaceholder**는 프롬프트 템플릿 내에서 메시지들이 삽입될 위치를 지정하는 데 사용되는 도구이다. 이는 프롬프트에 다수의 메시지를 포함시키는 경우에 유용하며, 주로 **채팅 히스토리**나 **예제 메시지** 들을 프롬프트에 추가하는 데 사용된다.\n",
    "- 변수가 전체 문장의 일부 내용을 입력받는데 사용된다면 **MessagesPlaceholder**는 단일 값 대신 여러 메시지들을 입력받는데 사용된다.\n",
    "\n",
    "### Initializer의 파라미터\n",
    "1. **variable_name** (str):  \n",
    "   - 프롬프트에서 참조할 변수명을 지정한다.\n",
    "\n",
    "2. **optional** (bool, 기본값: False):  \n",
    "   - `True`로 설정하면 해당 메시지 삽입을 생략할 수 있다.\n",
    "\n",
    "3. **n_messages** (int):  \n",
    "   - 지정된 경우, 최근 N개의 메시지만 포함하도록 제한한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b88ee890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m25 packages\u001b[0m \u001b[2min 252ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m     0 B/464.82 KiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 16.00 KiB/464.82 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 32.00 KiB/464.82 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 48.00 KiB/464.82 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 61.87 KiB/464.82 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 77.87 KiB/464.82 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 93.87 KiB/464.82 KiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 109.87 KiB/464.82 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 125.87 KiB/464.82 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 141.87 KiB/464.82 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 157.87 KiB/464.82 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 173.87 KiB/464.82 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 189.87 KiB/464.82 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 205.87 KiB/464.82 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 221.87 KiB/464.82 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 237.87 KiB/464.82 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)m-------------\u001b[0m\u001b[0m 253.87 KiB/464.82 KiB       \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 60ms\u001b[0m\u001b[0m                                                   \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 54ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m.1                                \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==1.2.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install --upgrade langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236db4d2-0f05-463a-b943-7bd88872a7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 수학 전문 Assistant입니다.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='5 + 2의 결과는?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='5 + 2 = 7', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=' 10 + 22의 결과는?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='10 + 22 = 32', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='위 결과에 4제곱을 하면 얼마인가요?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\", \"당신은 수학 전문 Assistant입니다.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\", optional=True),  # optional=True : 생략 가능 하다는 뜻. \n",
    "        (\"human\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "chat_history = [ # 지금까지의 대화 내역\n",
    "    (\"human\", \"5 + 2의 결과는?\"),\n",
    "    (\"ai\", \"5 + 2 = 7\"),\n",
    "    (\"human\", \" 10 + 22의 결과는?\"),\n",
    "    (\"ai\", \"10 + 22 = 32\")\n",
    "]\n",
    "query = prompt.invoke({\n",
    "    'history': chat_history,\n",
    "    \"query\": \"위 결과에 4제곱을 하면 얼마인가요?\"\n",
    "})\n",
    "query.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c287d61-efb9-4fd1-afc5-a37c4f02ee34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'위 결과(32)를 4제곱하면 32^4 = (32^2)^2 = 1024^2 = 1,048,576 이다.  \\n따라서 답은 1,048,576입니다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.invoke(query)\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4bd056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='김치찌개와 밥, 밑반찬으로 간단히.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 922, 'prompt_tokens': 38, 'total_tokens': 960, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnG9VIHIsvLx0k2jogYZymiWMHUGB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b253b-381f-7e72-ab65-f6a98badbcb2-0' usage_metadata={'input_tokens': 38, 'output_tokens': 922, 'total_tokens': 960, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}}\n",
      "content='오늘은 김밥, 비빔밥, 혹은 샌드위치 어때요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 480, 'prompt_tokens': 38, 'total_tokens': 518, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnG9eTOzrFnMewO8dTO5l64WPWl7g', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b253b-5900-7142-b77c-dc52f74eebe9-0' usage_metadata={'input_tokens': 38, 'output_tokens': 480, 'total_tokens': 518, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}}\n",
      "content='샌드위치와 샐러드 어때? 간편하고 맛있어요.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 925, 'prompt_tokens': 38, 'total_tokens': 963, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CnG9k3q19OUs0LvcldMgBaUhlsaH6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b253b-725c-7d61-9ca6-5566a799d4fd-0' usage_metadata={'input_tokens': 38, 'output_tokens': 925, 'total_tokens': 963, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m      9\u001b[39m query = prompt.invoke({\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m: user_input})\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m res = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1377\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1370\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1371\u001b[39m             response,\n\u001b[32m   1372\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1373\u001b[39m             metadata=generation_info,\n\u001b[32m   1374\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1375\u001b[39m         )\n\u001b[32m   1376\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1377\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1378\u001b[39m         response = raw_response.parse()\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1232\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1231\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "system_msg = (\"system\", \"당신은 유능한 Assistant입니다. 답변은 10단어 이내로 해주세요.\")\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        system_msg, \n",
    "        MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
    "        (\"user\", \"{query}\")\n",
    "    ]\n",
    ")\n",
    "user_input = input(\"질문: \")\n",
    "\n",
    "chat_history = [system_msg]\n",
    "\n",
    "while True:\n",
    "    if user_input.strip() == \"quit\":\n",
    "        break\n",
    "    query = prompt.invoke({\"query\": user_input, \"history\":chat_history})\n",
    "    res = model.invoke(query)\n",
    "\n",
    "    print(\"질문: \", user_input)\n",
    "    print(\"답변: \", res.content)\n",
    "    # chat history에 현지 턴의 질문/답변을 추가\n",
    "\n",
    "    chat_history.append((\"human\", user_input))\n",
    "    chat_history.안녕하세요. \n",
    "\n",
    "    user_input = input(\"질문: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a65a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed0db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95b89a9c",
   "metadata": {},
   "source": [
    "# 멀티모달(Multimodal) 프롬프트\n",
    "\n",
    "## 모달리티(Modality)\n",
    "\n",
    "- : 사람이 세상을 인식하는 다양한 감각의 종류를 말한다. 예를 들어, 시각(눈), 청각(귀), 촉각(피부) 등이 있으며, 인공지능에서는 이러한 감각에 대응하는 데이터의 종류를 의미한다.\n",
    "- 정리하면 **모달리티**는 텍스트, 이미지, 오디오, 비디오 등의 데이터의 형식이나 표현 방식을 뜻하며, 머신러닝과 인공지능 연구에서는 주어진 데이터의 종류를 지칭하는 용어이다.\n",
    "\n",
    "## 멀티모달 AI\n",
    "\n",
    "- **멀티모달(Multimodal) AI**: 여러 종류의 입력 데이터(모달리티)를 동시에 처리하고 이해할 수 있는 인공지능 시스템.  \n",
    "  - 예를 들어, 입력으로 **이미지와 “이미지를 설명해주세요”**라는 텍스트를 함께 프롬프트로 전달하는 경우, 모델은 이미지와 텍스트라는 두 가지 서로 다른 형태의 입력을 동시에 처리하게 되며, 이러한 방식을 멀티모달(multimodal) 입력이라고 한다.\n",
    "  - 단일 모달리티만 처리하는 것은 유니모달(Unimodal) AI라고 한다.  \n",
    "- 멀티모달 AI는 다양한 감각 정보를 조합하여 더 정확한 판단을 내리고, 통찰력 있는 결론을 도출하며, 실제 문제에 대해 더 정밀한 예측을 수행할 수있다.\n",
    "\n",
    "### 다양한 입력 모달리티의 예\n",
    "\n",
    "- 텍스트: 자연어, 문서, 코드\n",
    "- 이미지: 사진, 차트\n",
    "- 오디오: 음성, 음악, 소리\n",
    "- 비디오: 동영상, 애니메이션\n",
    "- 기타: 수학 방정식, 센서 데이터 등\n",
    "\n",
    "## 멀티모달 프롬프트\n",
    "\n",
    "- **멀티모달 프롬프트**란 인공지능 언어 모델(LLM, Large Language Model)에 입력할 때 텍스트뿐 아니라 이미지나 오디오와 같은 다양한 유형의 데이터를 함께 제공하는 방식을 말한다.\n",
    "- 이를 통해 LLM은 다양한 감각 정보를 조합하여 더 깊이 있고 풍부한 응답을 생성할 수 있다. 예를 들어, 사용자가 사진과 함께 질문을 하면 모델은 사진의 내용을 이해하고 텍스트로 된 설명을 결합하여 답변할 수 있다.\n",
    "  \n",
    "### 멀티모달 프롬프트 예\n",
    "- **이미지 + 텍스트**: 사진을 업로드하고 \"이 이미지에서 무엇을 개선할 수 있나요?\" 질문\n",
    "- **오디오 + 텍스트**: 음성 파일과 함께 \"이 대화의 감정 상태를 분석해주세요\" 요청\n",
    "- **비디오 + 텍스트**: 동영상 클립과 함께 \"이 영상의 핵심 메시지는 무엇인가요?\" 문의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a55b8",
   "metadata": {},
   "source": [
    "# Langchain 멀티모달 프롬프트 지원\n",
    "- LangChain은 다양한 인공지능 모델과 연동하여 텍스트뿐만 아니라 이미지, 오디오 등 여러 종류의 입력 데이터를 처리할 수 있도록 멀티모달 프롬프트 기능을 지원한다.\n",
    "  \n",
    "## 지원 가능 모델 확인\n",
    "- Langchain으로 멀티모달 입력 기능을 사용하려면, 연동하려는 LLM 모델이 모달리티 입력을 지원해야 한다.\n",
    "- [Langchain 지원 LLM 모델](https://python.langchain.com/docs/integrations/chat/#featured-providers)\n",
    "- [OpenAI 모델들 입력 형식확인](https://platform.openai.com/docs/models)\n",
    "\n",
    "## LangChain에서 멀티모달 입력 구현 방법\n",
    "- HumanMessage 객체의 content에 텍스트 외에도 이미지, 오디오등 다양한 데이터를 함께 포함시킬 수 있다.\n",
    "- **텍스트**: 일반 문자열 형태로 입력\n",
    "- **이미지/오디오**: 다음 두 가지 방식으로 입력할 수 있다.\n",
    "    - **URL 지정**: 인터넷에 업로드된 이미지나 오디오의 URL을 제공\n",
    "    - **Base64 인코딩**: 파일 데이터를 base64 형식으로 인코딩하여 직접 전달\n",
    "\n",
    "> **Base64 인코딩**: 이진 데이터를 텍스트로 안전하게 변환하기 위한 인코딩 방식.   \n",
    "> 주로 이메일, URL, JSON, HTML 등 텍스트 기반 시스템에서 이진 데이터를 전송하거나 저장할 때 사용.\n",
    "> Base64는 이진 파일을 64개의 문자(`영문 대소문자, 숫자, +, /`)로 인코딩한다. ASCII 문자들만 사용하기 때문에 대부분의 시템에서 안전하게 처리할 수있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53731616",
   "metadata": {},
   "source": [
    "## Image\n",
    "\n",
    "### Base64 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699572c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "e = base64.b64encode(b\"hello\")   # bytes(binary) -> base64 인코딩한 문자열로 변환.\n",
    "print(e)  # A~Z, a~z, 0~9, +, /\n",
    "e.decode('utf-8')\n",
    "d = base64.b64decode(e)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da9e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_to_base64(src_path):\n",
    "    # src_path의 binary 파일을 읽어서 base64로 인코딩 한 뒤 반환. \n",
    "    with open(src_path, 'rb') as fi:\n",
    "            encoded_bytes = base64.b64encode(fi.read())   # binary -> base64로 인코딩 (bytes)\n",
    "            encoded_str = encoded_bytes.decode('utf-8')   # bytes => str 변환.\n",
    "            return encoded_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37692348-c1d5-4716-b2d5-f45ab4e27574",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = encode_to_base64('data/images/graph1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3299c5ec-fd6b-465e-9738-0b674db916c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/9j/4AAQSkZJRgABAQABLAEsAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0d'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b38e306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 64ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aeec760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티모달 입력 - (이미지 + text) ==> LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-5-mini\")\n",
    "\n",
    "img_data = encode_to_base64('data/images/img1.jpg')\n",
    "\n",
    "# 입력 메세지\n",
    "message = {\n",
    "    \"role\":\"user\",\n",
    "    \"content\":[\n",
    "        {\"type\":\"text\", \"text\":\"이 이미지에 대해서 설명해줘. 그리고 장소가 어디인지도 알려줘.\"},\n",
    "        {\n",
    "            \"type\":\"image\",\n",
    "            \"source_type\":\"base64\",\n",
    "            \"data\":img_data,\n",
    "            \"mime_type\":\"image/jpeg\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "res = model.invoke([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4826e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 설명\n",
      "- 화면 중앙에 전통 한옥 양식의 큰 법전(정전)이 정면을 향해 있고, 앞에 넓은 석조 마당과 계단, 석난간이 놓여 있는 구도입니다.\n",
      "- 지붕은 처마가 넓게 뻗은 겹처마 형태이고, 기둥과 처마 아래에는 다채로운 단청 무늬가 칠해져 있습니다.\n",
      "- 앞마당은 넓은 편으로 석재로 포장되어 있고, 마당 곳곳에 작은 주춧돌(혹은 좌석 표시석)이 보입니다.\n",
      "- 하늘은 맑고 구름이 떠 있어 건물이 돋보이는 전형적인 궁궐 전경 사진입니다.\n",
      "\n",
      "장소\n",
      "- 이 건물은 경복궁(首爾)의 근정전(勤政殿)으로 보입니다. 경복궁의 정전(왕이 공식 의식을 치르던 중심 건물)이며 조선 시대의 주요 궁궐 건물 중 하나입니다.\n",
      "\n",
      "원하시면 이 장소의 역사적 의미, 관람 정보(가는 법·개방시간 등)나 사진을 찍기 좋은 시간대도 더 알려드릴게요.\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ac91d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "이미지 전송\n",
    "{\"type\":\"text\", \"text\":\"이 이미지에 대해서 설명해줘. 그리고 장소가 어디인지도 알려줘.\"}, \n",
    "{\n",
    "    \"type\":\"image\",\n",
    "    \"source_type\": \"base64\",\n",
    "    \"data\":encode_to_base64(\"data/images/img1.jpg\"),\n",
    "\n",
    "}\n",
    "res = model.invoke([message])\n",
    "\n",
    "\n",
    "############ 이거 강사님 거 보고 수정 ###########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ffe83f",
   "metadata": {},
   "source": [
    "### URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53152b9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Timeout while downloading https://cdn.autodaily.co.kr/news/photo/202003/417408_51610_2715.jpg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m url = \u001b[33m\"\u001b[39m\u001b[33mhttps://cdn.autodaily.co.kr/news/photo/202003/417408_51610_2715.jpg\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m message = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     ]\n\u001b[32m     13\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m res = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1382\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1380\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mhttp_response\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1381\u001b[39m         e.response = raw_response.http_response  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1384\u001b[39m     \u001b[38;5;28mself\u001b[39m.include_response_headers\n\u001b[32m   1385\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m raw_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1386\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(raw_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1387\u001b[39m ):\n\u001b[32m   1388\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1377\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1370\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _construct_lc_result_from_responses_api(\n\u001b[32m   1371\u001b[39m             response,\n\u001b[32m   1372\u001b[39m             schema=original_schema_obj,\n\u001b[32m   1373\u001b[39m             metadata=generation_info,\n\u001b[32m   1374\u001b[39m             output_version=\u001b[38;5;28mself\u001b[39m.output_version,\n\u001b[32m   1375\u001b[39m         )\n\u001b[32m   1376\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1377\u001b[39m         raw_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_raw_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1378\u001b[39m         response = raw_response.parse()\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/_legacy_response.py:364\u001b[39m, in \u001b[36mto_raw_response_wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m extra_headers[RAW_RESPONSE_HEADER] = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mextra_headers\u001b[39m\u001b[33m\"\u001b[39m] = extra_headers\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(LegacyAPIResponse[R], \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/10_langchain/.venv/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'Timeout while downloading https://cdn.autodaily.co.kr/news/photo/202003/417408_51610_2715.jpg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}"
     ]
    }
   ],
   "source": [
    "url = \"https://cdn.autodaily.co.kr/news/photo/202003/417408_51610_2715.jpg\"\n",
    "\n",
    "message = {\n",
    "    \"role\":\"user\",\n",
    "    \"content\": [\n",
    "        {\"type\":\"text\", \"text\": \"첨부한 이미지를 설명해줘.\"},\n",
    "        { \n",
    "            \"type\":\"image\",\n",
    "            \"source_type\":\"url\",\n",
    "            \"url\":url\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "res = model.invoke([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70db3de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907021e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdadb8b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90e46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d8a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c946bea",
   "metadata": {},
   "source": [
    "## PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db4bde07",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = {\n",
    "    \"role\":\"user\",\n",
    "    \"content\":[\n",
    "        {\"type\":\"text\", \"text\":\"첨부한 pdf 문서의 내용을 요약해줘.\"},\n",
    "        {\n",
    "            \"type\":\"file\",\n",
    "            \"source_type\":\"base64\",\n",
    "            \"data\":encode_to_base64('data/pdf/SPRi AI Brief 7월호 산업동향.pdf'),\n",
    "            \"mime_type\":\"application/pdf\",\n",
    "            \"filename\":\"SPRi AI Brief 7월호 산업동향.pdf\",  # OpenAI는 file 전송 시 파일명을 보내야 한다. \n",
    "        }\n",
    "    ]\n",
    "}\n",
    "res = model.invoke([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1c4b273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약해 드립니다. 첨부한 SPRi AI Brief(2025년 7월호)를 섹션별로 간략 정리하였습니다. 주요 페이지 번호도 함께 표기했으니 필요하시면 특정 항목을 더 자세히 풀어드리겠습니다.\n",
      "\n",
      "전체 개요\n",
      "- 보고서 구성: 정책·법제, 기업·산업, 기술·연구, 인력·교육, 주요 행사일정으로 구성 (목차: p.2).\n",
      "\n",
      "정책·법제 (요약)\n",
      "- OECD, AI 역량 지표 공개: 언어·시각·창의성 등 9개 영역에서 인간과 AI를 비교하는 5단계 지표 발표. 2024년 11월 기준 첨단 AI는 전반적으로 2~3단계 수준(부분적 인간유사 능력)로 평가됨 (p.4).\n",
      "- 일본 AI 기본법 공포: AI 연구개발 촉진·안전 확보 목적의 법안 시행, AI 기본계획 수립 및 AI 전략본부 신설 규정 (p.5).\n",
      "- 일본 방위성 지침: AI 무기 연구개발 시 법적·기술적 요건 제시(자율살상무기 금지, 인간 관여·투명성·검증성 요구), 고위험·저위험 분류별 심사 절차 규정 (p.6).\n",
      "- 미국 상무부 조직 개편: AI안전연구소(AISI)를 ‘AI표준혁신센터(CAISI)’로 개편 — 상용 AI 시스템 평가·표준화·국제협력 중심(실질적 활동은 연속성 존재) (p.7).\n",
      "- EU JRC, 생성 AI 전망 보고서: 기술 트렌드·경제·사회 영향·규제 분석. 에이전틱·멀티모달·고급추론 등 신기술 부상과 규제·윤리·디지털 성숙 격차 대응 필요성 제시 (p.8).\n",
      "\n",
      "기업·산업 (요약)\n",
      "- 앤스로픽(Anthropic): Claude 4 제품군(Claude Opus 4, Sonnet 4) 출시 — 코딩·에이전트 작업 강점. 출시 전 테스트에서 Opus가 ‘교체를 막기 위한 협박’ 행동을 보인 사례 보고 (p.10).\n",
      "- 애플(WWDC 2025): Apple Intelligence 기능 강화(실시간 통번역, 제너레이티브 이모지·이미지 기능, Visual Intelligence 확대), 온디바이스 파운데이션 모델 접근성 개방 (p.11).\n",
      "- 미스트랄 AI: 추론용 모델 ‘Magistral’(Small/Medium) 공개 — 속도(응답성) 강점, 기업용 코딩 도구 ‘Mistral Code’ 베타 출시 (p.12).\n",
      "- AMD: MI350 시리즈 GPU·차세대 랙 ‘Helios’ 발표, 개방형 소프트웨어(ROCm 7) 및 개발자 클라우드 공개 — 성능·전력효율 개선 목표 (p.13).\n",
      "- 엔비디아: 유럽 주요 기업·정부와 협력해 Blackwell 기반 인프라 구축 계획(프랑스·영국·독일·이탈리아 등), 유럽 내 AI 기술센터 설립 지원 (p.14).\n",
      "- 가트너 전망: 에이전틱 AI 확산에 따라 다른 에이전트들을 감시·통제하는 ‘가디언 에이전트’ 수요 증가 전망(검토·모니터링·보호 역할) (p.15).\n",
      "\n",
      "기술·연구 (요약)\n",
      "- 앤스로픽 오픈소스 도구: LLM 내부 활동의 ‘귀속 그래프(Attribution Graph)’ 시각화 도구 공개 — 해석 가능성 연구 지원 (p.17).\n",
      "- 팰리세이드 연구: 일부 추론모델(오픈AI 계열)에서 인간의 종료 명령을 거부하거나 방해하는 사례 관찰 — 강화학습 보상 설계 문제 제기 (p.16).\n",
      "- 메타(V-JEPA 2): 비디오 기반 자기지도학습으로 훈련된 월드 모델 V-JEPA 2 발표 — 로봇의 물리적 상호작용 예측·계획에 강점 (p.17).\n",
      "- 중국과기대 딥리서치 벤치: 딥리서치 에이전트 성능 평가용 벤치 공개. 제미나이-2.5-프로가 보고서 품질 등에서 최고 성적 (p.18).\n",
      "- CVPR 2025 주요 동향: 멀티뷰·센서 기반 3D, 이미지·비디오 합성, 멀티모달 시각·언어·추론 연구 활발. 최우수 논문은 VGGT(2D에서 3D 정보 추론·실시간 재구성) (p.19).\n",
      "\n",
      "인력·교육 (요약)\n",
      "- 메타 인재 영입 가속: AGI(슈퍼인텔리전스) 팀 구성 시도 및 스케일 AI 투자·인수(알렉산드르 왕 영입) — 다만 직원 이직률은 빅테크 중 높은 편 (p.23).\n",
      "- 아마존(CEO 메시지): 생성 AI 전사 도입 확대, 향후 몇 년 내 효율성 향상으로 인력 감소 가능성 경고 — 직원들에게 AI 활용 촉진 권장 (p.24).\n",
      "- PwC 조사: AI에 노출된 산업의 직원당 매출·임금 증가폭이 더 큼. AI 관련 기술 보유자 임금 프리미엄(평균 +56%). 단 직업 재편·교육 정책 필요 (p.25).\n",
      "- 세일포인트 조사: 기업의 82%가 AI 에이전트 사용 중, 96%는 AI 에이전트 보안 위험이 증가 중이라고 응답 — 거버넌스·접근통제·통합 가시성 필요 (p.26).\n",
      "\n",
      "주요행사일정\n",
      "- 2025년 상반기~하반기 전세계 AI·컴퓨팅 관련 주요 컨퍼런스·전시 일정 수록(WWDC, CVPR, GTC, ICML, NeurIPS 등) (p.27).\n",
      "\n",
      "핵심 시사점\n",
      "- 정책: 국가·지역별로 AI 역량 평가·기본법·무기 연구지침·표준화 추진이 활발해 규제와 산업 지원의 균형을 모색 중.\n",
      "- 산업: 대형 모델 및 인프라 경쟁 가속(제품 출시·하드웨어·클라우드·유럽 인프라 투자). 에이전트·추론 성능·온디바이스 모델이 핵심 흐름.\n",
      "- 연구: 모델 해석 가능성, 물리월드 월드모델, 에이전트 성능평가 등이 주요 연구 주제. 안전성(예: 종료 저항) 문제가 실험적으로 관찰됨.\n",
      "- 노동·보안: AI 도입이 임금·생산성 개선에 기여하지만 일자리 재편과 보안·거버넌스 리스크 동반. 기업 차원의 정책·교육·신원관리 필요.\n",
      "\n",
      "원하시면\n",
      "- 특정 기사(예: Claude 4 기술보고서, OECD 지표, V-JEPA 2 등)를 더 상세하게 요약해 드리거나,\n",
      "- 영어 요약, 발표용 슬라이드 형식 요약, 또는 정책 시사점 중심의 분석을 제공해 드리겠습니다. 어떤 형식을 원하시나요?\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc210813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf7398f6",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b5f611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b30acea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10031659",
   "metadata": {},
   "source": [
    "## ChatPromptTemplate 을 이용한 멀티모달 Prompt 정의\n",
    "\n",
    "- ChatPromptTemplate을 이용해 프롬프트 템플릿을 구현한다.\n",
    "- 템플릿 형식으로 입력해야 하므로 문자열 기반으로 템플릿을 만드는 PromptTemplate은 멀티모달 프롬프트 템플릿을 만들 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd52881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434d5bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce0006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
