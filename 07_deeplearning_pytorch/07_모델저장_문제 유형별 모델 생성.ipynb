{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11/19(수) 11:20\n",
    "# 강사님 거 보고 오류 수정하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습된 모델 저장\n",
    "\n",
    "- 학습이 완료된 모델을 파일로 저장하여, 이후 추가 학습이나 예측 서비스에 사용할 수 있도록 한다.\n",
    "- 파이토치(PyTorch)는 **모델의 파라미터만 저장**하는 방법과 **모델의 구조와 파라미터를 모두 저장**하는 두 가지 방식을 제공한다.\n",
    "- 저장 함수\n",
    "  - `torch.save(저장할 객체, 저장 경로)`\n",
    "- 보통 저장 파일의 확장자는 `.pt`나 `.pth`를 사용한다.\n",
    "\n",
    "## 모델 전체 저장 및 불러오기\n",
    "\n",
    "- 저장하기\n",
    "  - `torch.save(model, 저장 경로)`\n",
    "- 불러오기\n",
    "  - `load_model = torch.load(저장 경로, weights_only=False)`\n",
    "- 모델 저장 시 **피클(pickle)**을 사용해 직렬화되므로, 모델을 불러오는 실행 환경에도 저장할 때 사용한 클래스 정의가 필요하다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델의 파라미터만 저장\n",
    "\n",
    "-   모델을 구성하는 파라미터만 저장한다.\n",
    "-   모델의 구조는 저장하지 않기 때문에 불러올 때 **모델을 먼저 생성하고 생성한 모델에 불러온 파라미터를 덮어씌운다.**\n",
    "-   모델의 파라미터는 **state_dict** 형식으로 저장한다.\n",
    "\n",
    "### state_dict\n",
    "\n",
    "-   모델의 파라미터 Tensor들을 레이어 단위별로 나누어 저장한 Ordered Dictionary (OrderedDict)\n",
    "-   `모델객체.state_dict()` 메소드를 이용해 조회한다.\n",
    "-   모델의 state_dict을 조회 후 저장한다.\n",
    "    -   `torch.save(model.state_dict(), \"저장경로\")`\n",
    "-   생성된 모델에 읽어온 state_dict를 덮어씌운다.\n",
    "    -   `new_model.load_state_dict(torch.load(\"state_dict저장경로\"))`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint 저장 및 불러오기\n",
    "\n",
    "- 학습이 끝나지 않은 모델을 저장하고, 나중에 이어서 학습시키려면 모델의 구조와 파라미터뿐만 아니라 optimizer, loss 함수 등 학습에 필요한 객체들도 함께 저장해야 한다.\n",
    "- 딕셔너리(Dictionary)에 저장하려는 값들을 key-value 쌍으로 구성하여 `torch.save()`를 이용해 저장한다.\n",
    "\n",
    "```python\n",
    "# 저장\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': train_loss\n",
    "}, \"저장경로\")\n",
    "\n",
    "# 불러오기\n",
    "model = MyModel()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 불러온 checkpoint를 이용해 이전 학습 상태 복원\n",
    "checkpoint = torch.load(\"저장경로\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 모델 정의\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "\n",
    "    def __init__(self):  # forward에서 추론에 필요한 걸 init에서 만듬. \n",
    "        super().__init__()\n",
    "        self.lr1 = nn.Linear(3, 4) # 3 X 4 + 4 \n",
    "        self.lr2 = nn.Linear(4, 2)\n",
    "        self.relu = nn.ReLU() \n",
    "        # activation함수 -> 파라미터가 없는 단순 계산함수. relu(X) = max(X, 0). relu는 acitvate할 게 없다. 학습을 통해 찾아야 하는 게 없다. \n",
    "    def forward(self, X):  # forward에서는 추론 연산. \n",
    "        X = self.lr1(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.lr2(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (lr1): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (lr2): Linear(in_features=4, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성성\n",
    "model = MyModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=4, bias=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################\n",
    "#  모델에 Layer들을 조회. 모델.instance변수명\n",
    "################################################\n",
    "lr_layer = model.lr1\n",
    "lr_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#  Layer의 파라미터(weight/bias) 조회\n",
    "################################################\n",
    "lr1_weight = lr_layer.weight\n",
    "lr1_bias = lr_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4835, -0.3790, -0.2484],\n",
       "        [-0.0126, -0.1223,  0.3131],\n",
       "        [ 0.1389, -0.5053, -0.3756],\n",
       "        [-0.1995,  0.0508, -0.0470]], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr1_weight.size())\n",
    "lr1_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.4714,  0.4909, -0.2778, -0.5458], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"saved_models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#  모델을 저장\n",
    "################################################\n",
    "torch.save(model, \"saved_models/my_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "#  저장된 모델 Load\n",
    "################################################\n",
    "load_model = torch.load(\"saved_models/my_model.pt\", weights_only=False) # weights_only=False : 모델 자체를 저장했다는 뜻. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (lr1): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (lr2): Linear(in_features=4, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4835, -0.3790, -0.2484],\n",
       "        [-0.0126, -0.1223,  0.3131],\n",
       "        [ 0.1389, -0.5053, -0.3756],\n",
       "        [-0.1995,  0.0508, -0.0470]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.lr1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4835, -0.3790, -0.2484],\n",
       "        [-0.0126, -0.1223,  0.3131],\n",
       "        [ 0.1389, -0.5053, -0.3756],\n",
       "        [-0.1995,  0.0508, -0.0470]], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lr1.weight',\n",
       "              tensor([[-0.4835, -0.3790, -0.2484],\n",
       "                      [-0.0126, -0.1223,  0.3131],\n",
       "                      [ 0.1389, -0.5053, -0.3756],\n",
       "                      [-0.1995,  0.0508, -0.0470]])),\n",
       "             ('lr1.bias', tensor([-0.4714,  0.4909, -0.2778, -0.5458])),\n",
       "             ('lr2.weight',\n",
       "              tensor([[-0.3197,  0.0348,  0.4957, -0.3007],\n",
       "                      [ 0.2623, -0.2973,  0.3423, -0.3514]])),\n",
       "             ('lr2.bias', tensor([ 0.0089, -0.2925]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################\n",
    "# 모델의 파라미터들(weight들, bias들)만 저장/불러오기\n",
    "######################################################\n",
    "state_dict = model.state_dict()\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['lr1.weight', 'lr1.bias', 'lr2.weight', 'lr2.bias'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# state_dict 저장\n",
    "################### \n",
    "\n",
    "torch.save(state_dict, \"saved_models/my_model_parameter.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lr1.weight',\n",
       "              tensor([[-0.4835, -0.3790, -0.2484],\n",
       "                      [-0.0126, -0.1223,  0.3131],\n",
       "                      [ 0.1389, -0.5053, -0.3756],\n",
       "                      [-0.1995,  0.0508, -0.0470]])),\n",
       "             ('lr1.bias', tensor([-0.4714,  0.4909, -0.2778, -0.5458])),\n",
       "             ('lr2.weight',\n",
       "              tensor([[-0.3197,  0.0348,  0.4957, -0.3007],\n",
       "                      [ 0.2623, -0.2973,  0.3423, -0.3514]])),\n",
       "             ('lr2.bias', tensor([ 0.0089, -0.2925]))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################\n",
    "# state_dict load\n",
    "#####################\n",
    "sd = torch.load(\"saved_models/my_model_parameter.pt\")  # weight_only = True (default)\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lr1.weight',\n",
       "              tensor([[ 0.4322, -0.0257, -0.3738],\n",
       "                      [-0.2157, -0.3241, -0.0399],\n",
       "                      [ 0.1244, -0.1493,  0.4862],\n",
       "                      [ 0.0639, -0.1935, -0.1440]])),\n",
       "             ('lr1.bias', tensor([-0.0523,  0.3053,  0.4592, -0.5645])),\n",
       "             ('lr2.weight',\n",
       "              tensor([[-0.3878, -0.0015,  0.2073, -0.1239],\n",
       "                      [-0.2156, -0.3969, -0.4217, -0.1592]])),\n",
       "             ('lr2.bias', tensor([0.0232, 0.0459]))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load한 state_dict를 모델 파라미터에 적용(덮어 씌운다.)\n",
    "new_model = MyModel()\n",
    "new_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('lr1.weight',\n",
       "              tensor([[-0.4835, -0.3790, -0.2484],\n",
       "                      [-0.0126, -0.1223,  0.3131],\n",
       "                      [ 0.1389, -0.5053, -0.3756],\n",
       "                      [-0.1995,  0.0508, -0.0470]])),\n",
       "             ('lr1.bias', tensor([-0.4714,  0.4909, -0.2778, -0.5458])),\n",
       "             ('lr2.weight',\n",
       "              tensor([[-0.3197,  0.0348,  0.4957, -0.3007],\n",
       "                      [ 0.2623, -0.2973,  0.3423, -0.3514]])),\n",
       "             ('lr2.bias', tensor([ 0.0089, -0.2925]))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchinfo 패키지 설치: 파이토치 모델 구조를 조사해주는 패키지.\n",
    "# !uv pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MyModel                                  --\n",
       "├─Linear: 1-1                            16\n",
       "├─Linear: 1-2                            10\n",
       "├─ReLU: 1-3                              --\n",
       "=================================================================\n",
       "Total params: 26\n",
       "Trainable params: 26\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyModel                                  [100, 2]                  --\n",
       "├─Linear: 1-1                            [100, 4]                  16\n",
       "├─ReLU: 1-2                              [100, 4]                  --\n",
       "├─Linear: 1-3                            [100, 2]                  10\n",
       "==========================================================================================\n",
       "Total params: 26\n",
       "Trainable params: 26\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.01\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input data 의 shape을 지정하면 각 Layer의 output shape을 출력한다.\n",
    "summary(model, (100, 3))  # input_data = 입력 Tensor 객체, input_data=torch.randn(100, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 문제 유형별 MLP 네트워크\n",
    "- 해결하려는 문제 유형에 따라 출력 Layer의 구조가 바뀐다.\n",
    "- 딥러닝 구조에서 **Feature를 추출하는 Layer 들을 Backbone** 이라고 하고 **추론하는 Layer들을 Head** 라고 한다. \n",
    "\n",
    "\n",
    "> - MLP(Multi Layer Perceptron), DNN(Deep Neural Network), ANN(Artificial Neural Network)\n",
    ">     -   Fully Connected Layer(nn.Linear)로 구성된 딥러닝 모델\n",
    ">     -   input feature들 모두에 대응하는 weight들(가중치)을 사용한다.\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Boston Housing Dataset - **Regression(회귀) 문제**\n",
    "\n",
    "보스턴 주택가격 dataset은 다음과 같은 속성을 바탕으로 해당 타운 주택 가격의 중앙값을 예측하는 문제.\n",
    "\n",
    "-   CRIM: 범죄율\n",
    "-   ZN: 25,000 평방피트당 주거지역 비율\n",
    "-   INDUS: 비소매 상업지구 비율\n",
    "-   CHAS: 찰스강에 인접해 있는지 여부(인접:1, 아니면:0)\n",
    "-   NOX: 일산화질소 농도(단위: 0.1ppm)\n",
    "-   RM: 주택당 방의 수\n",
    "-   AGE: 1940년 이전에 건설된 주택의 비율\n",
    "-   DIS: 5개의 보스턴 직업고용센터와의 거리(가중 평균)\n",
    "-   RAD: 고속도로 접근성\n",
    "-   TAX: 재산세율\n",
    "-   PTRATIO: 학생/교사 비율\n",
    "-   B: 흑인 비율\n",
    "-   LSTAT: 하위 계층 비율\n",
    "    <br><br>\n",
    "-   **Target**\n",
    "    -   MEDV: 타운의 주택가격 중앙값(단위: 1,000달러)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/boston_housing.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns='MEDV').values\n",
    "y = df['MEDV'].values.reshape(-1, 1)  # pytorch에서는 2차원이어야 하는데 1차원이라 늘려줌. \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 회귀문제라 stratify 불가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 102)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/Test Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "trainset = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "testset = TensorDataset(\n",
    "    torch.tensor(X_test, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "len(trainset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 생성\n",
    "\n",
    "batch_size = 200\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# 모델 정의\n",
    "########################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class BostonModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr1 = nn.Linear(13, 32)  # input layer  # 첫 번째 연산\n",
    "        self.lr2 = nn.Linear(32, 16)\n",
    "        self.lr3 = nn.Linear(16, 1)  # 추론 결과 출력 : 회귀 - 예측할 값의 개수 (집값: 1, 아파트, 단독주택, 연립: 3), y.shape: (N, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Linear -> ReLU -> Linear -> LeRU -> Linear -> 출력\n",
    "        out = self.lr1(X)\n",
    "        out = self.relu(out)  # 비선형\n",
    "        out = self.lr2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.lr3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "lr = 0.001\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "# 모델 생성\n",
    "boston_model = BostonModel().to(device)\n",
    "\n",
    "# loss 함수\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.RMSprop(boston_model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BostonModel                              [100, 1]                  --\n",
       "├─Linear: 1-1                            [100, 32]                 448\n",
       "├─ReLU: 1-2                              [100, 32]                 --\n",
       "├─Linear: 1-3                            [100, 16]                 528\n",
       "├─ReLU: 1-4                              [100, 16]                 --\n",
       "├─Linear: 1-5                            [100, 1]                  17\n",
       "==========================================================================================\n",
       "Total params: 993\n",
       "Trainable params: 993\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.10\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.04\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.05\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(boston_model, (100, 13), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000] train loss:  2076.15973, validation loss: 526.40479\n",
      "[101/1000] train loss:  54.08716, validation loss: 24.92609\n",
      "[201/1000] train loss:  50.89907, validation loss: 18.57525\n",
      "[301/1000] train loss:  33.01104, validation loss: 15.46663\n",
      "[401/1000] train loss:  48.75301, validation loss: 14.55555\n",
      "[501/1000] train loss:  26.33569, validation loss: 13.33767\n",
      "[601/1000] train loss:  25.28071, validation loss: 12.87698\n",
      "[701/1000] train loss:  25.05484, validation loss: 12.20464\n",
      "[801/1000] train loss:  17.25213, validation loss: 11.65772\n",
      "[901/1000] train loss:  31.19368, validation loss: 12.10776\n",
      "[1000/1000] train loss:  20.04422, validation loss: 10.95914\n"
     ]
    }
   ],
   "source": [
    "# Train -> Train / Validation 두 단계\n",
    "for epoch in range(epochs):\n",
    "    #######################\n",
    "    # 학습 (train)\n",
    "    #######################\n",
    "    boston_model.train()\n",
    "    train_loss = 0.0  # 현 epoch의 loss를 저장할 변수.\n",
    "    for X_train, y_train in train_loader:  # 1 batch 학습\n",
    "\n",
    "        # 1. X, y를 device로 이동. (model과 같은 device로 이동)\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "\n",
    "        # 2. 추론\n",
    "        pred_train = boston_model(X_train)\n",
    "\n",
    "        # 3. loss 계산\n",
    "        loss = loss_fn(pred_train, y_train)\n",
    "\n",
    "        ########### 여기까지가 순전파 \n",
    "\n",
    "        # 4. 역전파로 gradient 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 6. gradient 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 7. 현재 batch에 대한 loss 계산\n",
    "        train_loss += loss.item()\n",
    "         \n",
    "        ######### 1 epoch 끝남\n",
    "\n",
    "    train_loss_list.append(train_loss / len(train_loader))\n",
    "\n",
    "    #######################\n",
    "    # 검증 (validation) - 1 epoch 학습한 것에 대한 검증\n",
    "    #######################\n",
    "    boston_model.eval()  # 추론만 할 때.\n",
    "\n",
    "    valid_loss = 0.0  # 현재 epoch에 대한 검증 loss값을 저장할 변수\n",
    "    with torch.no_grad():\n",
    "        for X_valid, y_valid in test_loader:\n",
    "            # 1. X, y를 model의 device로 이동\n",
    "            X_valid, y_valid = X_valid.to(device), y_valid.to(device)\n",
    "\n",
    "            # 2. 추론\n",
    "            pred_valid = boston_model(X_valid)\n",
    "\n",
    "            # 3. 평가 - MSE\n",
    "            valid_loss += loss_fn(pred_valid, y_valid).item()\n",
    "        valid_loss /= len(test_loader)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "         \n",
    "    # 로그 출력 - train/valid loss를 출력\n",
    "    if epoch % 100 == 0 or epoch == epochs-1: \n",
    "        print(f\"[{epoch+1}/{epochs}] train loss: {train_loss: .5f}, validation loss: {valid_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_boston_model_path = \"saved_models/boston_model.pth\"\n",
    "torch.save(boston_model, save_boston_model_path) # 모델 전체 저장\n",
    "torch.save(boston_model.state_dict(), \"saved_models/bost_model_parameter.pth\") # 모델 파라미터만 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = torch.load(save_boston_model_path, weights_only=False)\n",
    "load_model.eval()\n",
    "with torch.no_grad():\n",
    "    load_model(X_valid)[:10]\n",
    "# load_state_dict = torch.load(\"saved_models/bost_model_parameter.pth\", weights_only=True)\n",
    "# load_model(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[26.7733],\n",
      "        [33.8045],\n",
      "        [16.5158],\n",
      "        [25.3020],\n",
      "        [16.5690],\n",
      "        [20.4914],\n",
      "        [16.3373],\n",
      "        [13.6960],\n",
      "        [25.6682],\n",
      "        [17.7169]])\n"
     ]
    }
   ],
   "source": [
    "load_state_dict = torch.load(\"saved_models/bost_model_parameter.pth\", weights_only=True)\n",
    "new_model = BostonModel()\n",
    "new_model.load_state_dict(load_state_dict)\n",
    "new_model.eval()\n",
    "with torch.no_grad():\n",
    "    result = new_model(X_valid)[:10]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 13]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 분류 (Classification)\n",
    "\n",
    "### Fashion MNIST Dataset - **다중분류(Multi-Class Classification) 문제**\n",
    "\n",
    "10개의 범주(category)와 70,000개의 흑백 이미지로 구성된 [패션 MNIST](https://github.com/zalandoresearch/fashion-mnist) 데이터셋.\n",
    "이미지는 해상도(28x28 픽셀)가 낮고 다음처럼 개별 의류 품목을 나타낸다:\n",
    "\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
    "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>그림</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">패션-MNIST 샘플</a> (Zalando, MIT License).<br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- **Feature**이미지는 28x28 크기이며 Gray scale이다.\n",
    "- **Target**은 총 10개의 class로 구성되어 있으며 각 class의 class 이름은 다음과 같다.\n",
    "\n",
    "| 레이블 | 클래스       |\n",
    "|--------|--------------|\n",
    "| 0      | T-shirt/top |\n",
    "| 1      | Trousers    |\n",
    "| 2      | Pullover    |\n",
    "| 3      | Dress       |\n",
    "| 4      | Coat        |\n",
    "| 5      | Sandal      |\n",
    "| 6      | Shirt       |\n",
    "| 7      | Sneaker     |\n",
    "| 8      | Bag         |\n",
    "| 9      | Ankle boot  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 학습 도중 모델 저장\n",
    ">\n",
    "> - 학습 도중 가장 좋은 성능을 보이는 모델이 나올 수 있다.\n",
    "> - 학습 도중 모델을 저장하는 방법\n",
    ">   1. 각 에폭이 끝날 때 마다 모델을 저장한다.\n",
    ">   2. 한 에폭 학습 후 성능 개선이 있으면 모델을 저장하여 가장 성능 좋은 모델만 저장되도록 한다.\n",
    ">      - 최고 성능 점수(best score)와 현재 에폭의 성능을 비교하여, 성능이 개선되었을 경우 모델을 저장(덮어쓰기)한다.\n",
    ">\n",
    "> #### 조기 종료(Early Stopping)\n",
    ">\n",
    "> - 학습 도중 성능 개선이 나타나지 않으면, 중간에 학습을 종료하도록 구현한다.\n",
    "> - 에폭 수를 충분히 길게 설정한 뒤, 특정 횟수 동안 성능 개선이 없으면 학습을 조기 종료하도록 구현한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"mps\" if torch.backend.mps.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000, 10000, 195, 40)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "batch_size = 256\n",
    "dataset_path = \"datasets/fashion_mnist\"\n",
    "f_trainset = FashionMNIST(dataset_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "f_testset = FashionMNIST(dataset_path, train=False, download=True, transform=transforms.ToTensor())\n",
    "f_trainset, f_validset = random_split(f_trainset, [50000, 10000])\n",
    "\n",
    "f_train_loader = DataLoader(f_trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "f_valid_loader = DataLoader(f_validset, batch_size=batch_size)\n",
    "f_test_loader = DataLoader(f_testset, batch_size=batch_size)\n",
    "\n",
    "len(f_trainset), len(f_testset), len(f_validset), len(f_train_loader), len(f_test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_testset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_testset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([1, 28, 28])\n",
      "tensor(0.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(f_trainset[0][0].dtype)\n",
    "print(f_trainset[0][0].size())\n",
    "print(f_trainset[0][0].min(), f_trainset[0][0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# 모델 정의 \n",
    "#######################\n",
    "class FashionMNISTModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr1 = nn.Linear(28*28, 2048)\n",
    "        self.lr2 = nn.Linear(2048, 1024)\n",
    "        self.lr3 = nn.Linear(1024, 512)\n",
    "        self.lr4 = nn.Linear(512, 256)\n",
    "        self.lr5 = nn.Linear(256, 128)\n",
    "        self.lr6 = nn.Linear(128, 64)\n",
    "        self.lr7 = nn.Linear(64, 32)\n",
    "        self.lr7 = nn.Linear(64, 10)\n",
    "        # 출력 Layer out_features 개수: 다중분류문제의 경우 정답 클래스 개수.\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X shape: (batch, 1, 28, 28) -> (batch, 784) torch.flatten(start_dim=1) 함수\n",
    "        out = nn.Flatten()(X) # 0축은 그대로 두고 그 이후 축을 flatten 한다.\n",
    "        out = self.lr1(out)   # self.relu(self.lr1(out))\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.lr2(out)   \n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.lr3(out)  \n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.lr4(out)   \n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.lr5(out)   \n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.lr6(out)   \n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.lr7(out)  \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FashionMNISTModel                        [100, 10]                 --\n",
       "├─Linear: 1-1                            [100, 2048]               1,607,680\n",
       "├─ReLU: 1-2                              [100, 2048]               --\n",
       "├─Linear: 1-3                            [100, 1024]               2,098,176\n",
       "├─ReLU: 1-4                              [100, 1024]               --\n",
       "├─Linear: 1-5                            [100, 512]                524,800\n",
       "├─ReLU: 1-6                              [100, 512]                --\n",
       "├─Linear: 1-7                            [100, 256]                131,328\n",
       "├─ReLU: 1-8                              [100, 256]                --\n",
       "├─Linear: 1-9                            [100, 128]                32,896\n",
       "├─ReLU: 1-10                             [100, 128]                --\n",
       "├─Linear: 1-11                           [100, 64]                 8,256\n",
       "├─ReLU: 1-12                             [100, 64]                 --\n",
       "├─Linear: 1-13                           [100, 10]                 650\n",
       "==========================================================================================\n",
       "Total params: 4,403,786\n",
       "Trainable params: 4,403,786\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 440.38\n",
       "==========================================================================================\n",
       "Input size (MB): 0.31\n",
       "Forward/backward pass size (MB): 3.23\n",
       "Params size (MB): 17.62\n",
       "Estimated Total Size (MB): 21.16\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(FashionMNISTModel(), (100, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "\n",
    "f_model = FashionMNISTModel().to(device)\n",
    "optimizer = torch.optim.Adam(f_model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "# 다중분류일 때의 loss는 : CrossEntropyLoss()\n",
    "# CrossEntropyLoss() 입력: 정답 -class index로 구성 [[3], [8], [0] ..], 모델 추정 결과: Softmax를 적용하기 전 값 - logit\n",
    "# \"위의 설명만 기억해주시면 되겠습니다~\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] train loss: 1.17361, valid loss: 0.73307, valid acc: 0.71660\n",
      ">>>>>>> 모델 저장: 1 epoch - 이전 score: 0.733066163957119, 개선된 score: 0.733066163957119\n",
      "[2/100] train loss: 0.66108, valid loss: 0.59472, valid acc: 0.77830\n",
      ">>>>>>> 모델 저장: 2 epoch - 이전 score: 0.5947174057364464, 개선된 score: 0.5947174057364464\n",
      "[3/100] train loss: 0.56888, valid loss: 0.53777, valid acc: 0.80080\n",
      ">>>>>>> 모델 저장: 3 epoch - 이전 score: 0.5377684898674489, 개선된 score: 0.5377684898674489\n",
      "[4/100] train loss: 0.51318, valid loss: 0.49151, valid acc: 0.83230\n",
      ">>>>>>> 모델 저장: 4 epoch - 이전 score: 0.4915106318891048, 개선된 score: 0.4915106318891048\n",
      "[5/100] train loss: 0.47208, valid loss: 0.44879, valid acc: 0.85080\n",
      ">>>>>>> 모델 저장: 5 epoch - 이전 score: 0.44878836423158647, 개선된 score: 0.44878836423158647\n",
      "[6/100] train loss: 0.43740, valid loss: 0.45238, valid acc: 0.84180\n",
      "[7/100] train loss: 0.41867, valid loss: 0.41694, valid acc: 0.85490\n",
      ">>>>>>> 모델 저장: 7 epoch - 이전 score: 0.4169355809688568, 개선된 score: 0.4169355809688568\n",
      "[8/100] train loss: 0.39217, valid loss: 0.40131, valid acc: 0.86150\n",
      ">>>>>>> 모델 저장: 8 epoch - 이전 score: 0.4013134650886059, 개선된 score: 0.4013134650886059\n",
      "[9/100] train loss: 0.37617, valid loss: 0.37724, valid acc: 0.86760\n",
      ">>>>>>> 모델 저장: 9 epoch - 이전 score: 0.37724108099937437, 개선된 score: 0.37724108099937437\n",
      "[10/100] train loss: 0.35921, valid loss: 0.38993, valid acc: 0.86330\n",
      "[11/100] train loss: 0.34521, valid loss: 0.37991, valid acc: 0.86660\n",
      "[12/100] train loss: 0.33269, valid loss: 0.35756, valid acc: 0.87620\n",
      ">>>>>>> 모델 저장: 12 epoch - 이전 score: 0.3575574718415737, 개선된 score: 0.3575574718415737\n",
      "[13/100] train loss: 0.32080, valid loss: 0.34276, valid acc: 0.88050\n",
      ">>>>>>> 모델 저장: 13 epoch - 이전 score: 0.3427559740841389, 개선된 score: 0.3427559740841389\n",
      "[14/100] train loss: 0.31213, valid loss: 0.33524, valid acc: 0.88200\n",
      ">>>>>>> 모델 저장: 14 epoch - 이전 score: 0.3352439790964127, 개선된 score: 0.3352439790964127\n",
      "[15/100] train loss: 0.30002, valid loss: 0.32848, valid acc: 0.88600\n",
      ">>>>>>> 모델 저장: 15 epoch - 이전 score: 0.3284791324287653, 개선된 score: 0.3284791324287653\n",
      "[16/100] train loss: 0.28886, valid loss: 0.33616, valid acc: 0.88370\n",
      "[17/100] train loss: 0.28529, valid loss: 0.32536, valid acc: 0.88570\n",
      ">>>>>>> 모델 저장: 17 epoch - 이전 score: 0.32535519227385523, 개선된 score: 0.32535519227385523\n",
      "[18/100] train loss: 0.27299, valid loss: 0.31531, valid acc: 0.89200\n",
      ">>>>>>> 모델 저장: 18 epoch - 이전 score: 0.31531426347792146, 개선된 score: 0.31531426347792146\n",
      "[19/100] train loss: 0.26939, valid loss: 0.32365, valid acc: 0.88940\n",
      "[20/100] train loss: 0.25918, valid loss: 0.31676, valid acc: 0.88990\n",
      "[21/100] train loss: 0.25277, valid loss: 0.32518, valid acc: 0.88760\n",
      "[22/100] train loss: 0.24622, valid loss: 0.31259, valid acc: 0.89490\n",
      ">>>>>>> 모델 저장: 22 epoch - 이전 score: 0.312592763081193, 개선된 score: 0.312592763081193\n",
      "[23/100] train loss: 0.23808, valid loss: 0.31582, valid acc: 0.89240\n",
      "[24/100] train loss: 0.23202, valid loss: 0.32074, valid acc: 0.89160\n",
      "[25/100] train loss: 0.22541, valid loss: 0.33078, valid acc: 0.89070\n",
      "[26/100] train loss: 0.21640, valid loss: 0.30328, valid acc: 0.90040\n",
      ">>>>>>> 모델 저장: 26 epoch - 이전 score: 0.3032810978591442, 개선된 score: 0.3032810978591442\n",
      "[27/100] train loss: 0.21249, valid loss: 0.30824, valid acc: 0.89600\n",
      "[28/100] train loss: 0.20288, valid loss: 0.31856, valid acc: 0.89600\n",
      "[29/100] train loss: 0.20243, valid loss: 0.33294, valid acc: 0.89130\n",
      "[30/100] train loss: 0.19207, valid loss: 0.32237, valid acc: 0.89670\n",
      "[31/100] train loss: 0.18958, valid loss: 0.31728, valid acc: 0.89880\n",
      "[32/100] train loss: 0.18235, valid loss: 0.33522, valid acc: 0.89340\n",
      "[33/100] train loss: 0.17247, valid loss: 0.32917, valid acc: 0.89740\n",
      "[34/100] train loss: 0.17112, valid loss: 0.34585, valid acc: 0.88930\n",
      "[35/100] train loss: 0.16317, valid loss: 0.36096, valid acc: 0.89220\n",
      "[36/100] train loss: 0.16057, valid loss: 0.33119, valid acc: 0.89800\n",
      ">>>>>>>>> 조기 종료: 0.3032810978591442보다 개선되지 않았다.\n",
      "학습에 걸린 시간: 842.8466880321503 초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "valid_acc_list = []\n",
    "\n",
    "############################################\n",
    "# 1. 성능이 개선될 때마다 모델을 저장.\n",
    "#    최종적으로 가장 성능이 좋은 epoch의 모델이 저장 되도록 한다.\n",
    "# 2. 일정 epoch 동안 성능 개선이 안되면 학습을 중단.\n",
    "# 이것과 관련된 변수들 정의\n",
    "############################################\n",
    "\n",
    "# 저장\n",
    "best_score = torch.inf   # 가장 좋은 validation_loss 값을 저장. valid_loss < best_score 성능이 개선 됐다. -> 이 때 저장. \n",
    "\n",
    "# 조기 종료\n",
    "save_model_path = \"saved_models/fashion_mnist_model.pth\"\n",
    "\n",
    "patience = 10  # 성능이 개선되는지 10 epoch 동안 기다려본다. valid_loss >= best_score 성능 개선이 안 됨. \n",
    "stop_count = 0 # 학습하는 도중 몇 번 동안 성능 개선이 안 되었는지 저장할 변수. stop_count == patience 이면 종료.\n",
    "\n",
    "epochs = 100\n",
    "s = time.time()\n",
    "for epoch in range(epochs):\n",
    "    # 학습\n",
    "    f_model.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    for X_train, y_train in f_train_loader:\n",
    "        # 1. X, y를 device로 이동\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "\n",
    "        # 2. 모델 추론\n",
    "        pred_train = f_model(X_train)\n",
    "\n",
    "        # 3. loss 계산\n",
    "        loss = loss_fn(pred_train, y_train)\n",
    "\n",
    "        # 4. gradient 계산 (역전파)\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 6. 파라미터 초기화 \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 7. 현재 epoch에서의 train loss 누적       \n",
    "        train_loss += loss.item()\n",
    "\n",
    "\n",
    "    # train_loss 평균 계산 \n",
    "    train_loss /= len(f_train_loader)\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "    # 검증\n",
    "    f_model.eval()\n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "    \n",
    "    with torch.no_grad(): # gradient 계산 할 필요 없어 난 지금 평가하려는 거야 라는 뜻. \n",
    "        for X_valid, y_valid in f_valid_loader:\n",
    "            # 1. device로 이동\n",
    "            X_valid, y_valid, X_valid.to(device), y_valid.to(device)\n",
    "\n",
    "            # 2. 모델 추정\n",
    "            pred_valid = f_model(X_valid)  # 10개 class에 대한 logit 값.\n",
    "            pred_label = pred_valid.argmax(dim=-1)  # 가장 확률 높은 class\n",
    "\n",
    "            # 3. 평가 - loss와 정확도\n",
    "            valid_loss += loss_fn(pred_valid, y_valid).item()  # 현 step에서의 loss \n",
    "            valid_acc += torch.sum(pred_label == y_valid).item()  # 현 step에서 맞은 것 개수.\n",
    "\n",
    "        valid_loss /= len(f_valid_loader)\n",
    "        valid_acc /= len(f_validset)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "\n",
    "        # 로그 출력 - train_loss, valid_loss, valid_acc\n",
    "        print(f\"[{epoch+1}/{epochs}] train loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, valid acc: {valid_acc:.5f}\")\n",
    "\n",
    "        ####################\n",
    "        # 모델 저장, 조기 종료\n",
    "        ####################\n",
    "        if valid_loss < best_score: # 이번 epoch 학습에서 성능 (valid_loss)이 개선되었다.\n",
    "            # 모델 저장\n",
    "            torch.save(f_model, save_model_path)\n",
    "            best_score = valid_loss\n",
    "            print(f\">>>>>>> 모델 저장: {epoch+1} epoch - 이전 score: {best_score}, 개선된 score: {valid_loss}\")\n",
    "            best_score = valid_loss\n",
    "            # 조기 종료 (stop_count를 초기화)\n",
    "            stop_count = 0\n",
    "\n",
    "        else: # 성능개선이 안 됨. \n",
    "            stop_count += 1\n",
    "            if stop_count == patience:\n",
    "                print(f\">>>>>>>>> 조기 종료: {best_score}보다 개선되지 않았다.\")\n",
    "                break  # break는 if와는 연관없음. for문에만 연관 있음.\n",
    "\n",
    "e = time.time()\n",
    "print('학습에 걸린 시간:', (e-s), \"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "result_dict = {\n",
    "    \"train_loss\": train_loss_list,\n",
    "    \"valid_acc\": valid_acc_list,\n",
    "    \"valid_loss\": valid_loss_list\n",
    "}\n",
    "\n",
    "with open (\"f_mnist_train_result.pkl\", 'wb') as fo:\n",
    "    pickle.dump(result_dict, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"f_mnist_train_result.pkl\", 'rb') as fi:\n",
    "    load_result = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_acc</th>\n",
       "      <th>valid_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.173615</td>\n",
       "      <td>0.7166</td>\n",
       "      <td>0.733066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.661077</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>0.594717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568876</td>\n",
       "      <td>0.8008</td>\n",
       "      <td>0.537768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.513176</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>0.491511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.472077</td>\n",
       "      <td>0.8508</td>\n",
       "      <td>0.448788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.437405</td>\n",
       "      <td>0.8418</td>\n",
       "      <td>0.452377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.418668</td>\n",
       "      <td>0.8549</td>\n",
       "      <td>0.416936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.392165</td>\n",
       "      <td>0.8615</td>\n",
       "      <td>0.401313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.376172</td>\n",
       "      <td>0.8676</td>\n",
       "      <td>0.377241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.359214</td>\n",
       "      <td>0.8633</td>\n",
       "      <td>0.389930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.345209</td>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.379906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.332693</td>\n",
       "      <td>0.8762</td>\n",
       "      <td>0.357557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.320802</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>0.342756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.312133</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>0.335244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.300025</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>0.328479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.288858</td>\n",
       "      <td>0.8837</td>\n",
       "      <td>0.336163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.285287</td>\n",
       "      <td>0.8857</td>\n",
       "      <td>0.325355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.272988</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.315314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.269393</td>\n",
       "      <td>0.8894</td>\n",
       "      <td>0.323650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.259185</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.316756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.252767</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>0.325175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.246218</td>\n",
       "      <td>0.8949</td>\n",
       "      <td>0.312593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.238080</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>0.315817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.232020</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>0.320735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.225408</td>\n",
       "      <td>0.8907</td>\n",
       "      <td>0.330777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.216397</td>\n",
       "      <td>0.9004</td>\n",
       "      <td>0.303281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.212487</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.308237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.202880</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.318557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.202433</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.332942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.192074</td>\n",
       "      <td>0.8967</td>\n",
       "      <td>0.322374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.189577</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>0.317276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.182354</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.335218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.172467</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>0.329166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.171122</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>0.345854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.163166</td>\n",
       "      <td>0.8922</td>\n",
       "      <td>0.360963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.160570</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.331189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  valid_acc  valid_loss\n",
       "0     1.173615     0.7166    0.733066\n",
       "1     0.661077     0.7783    0.594717\n",
       "2     0.568876     0.8008    0.537768\n",
       "3     0.513176     0.8323    0.491511\n",
       "4     0.472077     0.8508    0.448788\n",
       "5     0.437405     0.8418    0.452377\n",
       "6     0.418668     0.8549    0.416936\n",
       "7     0.392165     0.8615    0.401313\n",
       "8     0.376172     0.8676    0.377241\n",
       "9     0.359214     0.8633    0.389930\n",
       "10    0.345209     0.8666    0.379906\n",
       "11    0.332693     0.8762    0.357557\n",
       "12    0.320802     0.8805    0.342756\n",
       "13    0.312133     0.8820    0.335244\n",
       "14    0.300025     0.8860    0.328479\n",
       "15    0.288858     0.8837    0.336163\n",
       "16    0.285287     0.8857    0.325355\n",
       "17    0.272988     0.8920    0.315314\n",
       "18    0.269393     0.8894    0.323650\n",
       "19    0.259185     0.8899    0.316756\n",
       "20    0.252767     0.8876    0.325175\n",
       "21    0.246218     0.8949    0.312593\n",
       "22    0.238080     0.8924    0.315817\n",
       "23    0.232020     0.8916    0.320735\n",
       "24    0.225408     0.8907    0.330777\n",
       "25    0.216397     0.9004    0.303281\n",
       "26    0.212487     0.8960    0.308237\n",
       "27    0.202880     0.8960    0.318557\n",
       "28    0.202433     0.8913    0.332942\n",
       "29    0.192074     0.8967    0.322374\n",
       "30    0.189577     0.8988    0.317276\n",
       "31    0.182354     0.8934    0.335218\n",
       "32    0.172467     0.8974    0.329166\n",
       "33    0.171122     0.8893    0.345854\n",
       "34    0.163166     0.8922    0.360963\n",
       "35    0.160570     0.8980    0.331189"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "result_df = pd.DataFrame(load_result)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df[[\"train_loss\", \"valid_loss\"]].plot(xlabel=\"epoch\", ylabel=\"loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_df['valid_acc'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_loss    0.160570\n",
       "valid_loss    0.303281\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[[\"train_loss\", \"valid_loss\"]].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9004"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['valid_acc'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModel(\n",
       "  (lr1): Linear(in_features=784, out_features=2048, bias=True)\n",
       "  (lr2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (lr3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (lr4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (lr5): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (lr6): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (lr7): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장된 모델 load\n",
    "save_model_path = \"saved_models/fashion_mnist_model.pth\"\n",
    "load_model = torch.load(save_model_path, weights_only=False)\n",
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3232497613877058\n",
      "accuracy: 0.8867\n"
     ]
    }
   ],
   "source": [
    "### Testset으로 최종 평가 \n",
    "load_model.eval()\n",
    "loss = 0.0\n",
    "acc = 0.0\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "with torch.no_grad():\n",
    "    for X, y in f_test_loader:  \n",
    "        X, y = X.to(device), y.to(device)  # 1. device로 옮기기\n",
    "        pred = load_model(X)   # 2. 모델 추론\n",
    "        pred_label = pred.argmax(dim=-1)\n",
    "        # 평가\n",
    "        loss += loss_fn(pred, y).item()\n",
    "        acc += torch.sum(y == pred_label).item()\n",
    "    loss /= len(f_test_loader)\n",
    "    acc /= len(f_testset)\n",
    "\n",
    "print(\"loss:\", loss)\n",
    "print(\"accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = nn.Softmax(dim=-1)(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.4874,  -2.5664,  -5.8606,   4.8184,  -4.5077, -11.2088,  -1.1314,\n",
       "         -11.9139,  -4.7864,  -7.0264],\n",
       "        [  1.3979,   1.4915,   1.5243,  -1.2632,  -1.6423,  -7.6514,  -0.6190,\n",
       "          -7.5930,  -4.1656,  -5.1825]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.9215e-03, 6.1549e-04, 2.2832e-05, 9.9169e-01, 8.8331e-05, 1.0860e-07,\n",
       "         2.5847e-03, 5.3656e-08, 6.6847e-05, 7.1165e-06],\n",
       "        [2.8660e-01, 3.1474e-01, 3.2522e-01, 2.0026e-02, 1.3707e-02, 3.3669e-05,\n",
       "         3.8137e-02, 3.5693e-05, 1.0993e-03, 3.9762e-04]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 위스콘신 유방암 데이터셋 - **이진분류(Binary Classification) 문제**\n",
    "\n",
    "-   **이진 분류 문제 처리 모델의 두 가지 방법**\n",
    "    1. positive(1)일 확률을 출력하도록 구현\n",
    "        - output layer: units=1, activation='sigmoid'\n",
    "        - loss: binary_crossentropy\n",
    "    2. negative(0)일 확률과 positive(1)일 확률을 출력하도록 구현 => 다중분류 처리 방식으로 해결\n",
    "        - output layer: units=2, activation='softmax', y(정답)은 one hot encoding 처리\n",
    "        - loss: categorical_crossentropy\n",
    "-   위스콘신 대학교에서 제공한 종양의 악성/양성여부 분류를 위한 데이터셋\n",
    "-   Feature\n",
    "    -   종양에 대한 다양한 측정값들\n",
    "-   Target의 class\n",
    "    -   0 - malignant(악성종양)\n",
    "    -   1 - benign(양성종양)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "## 모델의 weight, bias -> float32. X, y는 weight, bias와 계산을 하게 되기 때문에 타입을 맞춰준다.\n",
    "trainset = TensorDataset(\n",
    "    torch.tensor(X_train_scaled, dtype=torch.float32),  \n",
    "    torch.tensor(y_train, dtype=torch.float32)\n",
    ")\n",
    "testset = TensorDataset(\n",
    "    torch.tensor(X_test_scaled, dtype=torch.float32), \n",
    "    torch.tensor(y_test, dtype=torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class name <-> class index\n",
    "classes = np.array([\"악성종양\", \"양성종양\"])\n",
    "class_to_idx = {\"악성종양\":0, \"양성종양\":1}\n",
    "\n",
    "trainset.classes = classes\n",
    "trainset.class_to_idx = class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_loader = DataLoader(trainset, batch_size=200, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 모델 정의\n",
    "class BCModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr1 = nn.Linear(30, 16)\n",
    "        self.lr2 = nn.Linear(16, 8)\n",
    "        self.lr3 = nn.Linear(8, 1)  # out_features: 1 - positive 일 확률\n",
    "        self.relu = nn.ReLU()  # hidden layer의 활성 함수\n",
    "        self.sigmoid = nn.Sigmoid()  # Linear 출력값을 0~1 확률로 만들어주는 Sigmoid(Logistic)함수.\n",
    "\n",
    "    def farward(self, X):\n",
    "        out = self.relu(self.lr1(X))\n",
    "        out = self.relu(self.lr2(out))\n",
    "\n",
    "        out = self.lr3(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "BCModel                                  --\n",
       "├─Linear: 1-1                            496\n",
       "├─Linear: 1-2                            136\n",
       "├─Linear: 1-3                            9\n",
       "├─ReLU: 1-4                              --\n",
       "├─Sigmoid: 1-5                           --\n",
       "=================================================================\n",
       "Total params: 641\n",
       "Trainable params: 641\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "m = BCModel()\n",
    "summary(m)\n",
    "# p = m(torch.randn(10, 30))\n",
    "# p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### 학습\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "valid_acc_list = []\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "model = BCModel().to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 조기 종료, best 모델 저장\n",
    "best_score = torch.inf  # valid loss 기준\n",
    "save_model_path = \"saved_models/bc_model.pth\"\n",
    "patience = 10\n",
    "stop_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [BCModel] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m X_train, y_train = X_train.to(device), y_train.to(device)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 2. 추론\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m pred_train = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 3. loss\u001b[39;00m\n\u001b[32m     11\u001b[39m loss = loss_fn(pred_train, y_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/07_deeplearning_pytorch/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/07_deeplearning_pytorch/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/07_deeplearning_pytorch/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:374\u001b[39m, in \u001b[36m_forward_unimplemented\u001b[39m\u001b[34m(self, *input)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, *\u001b[38;5;28minput\u001b[39m: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    364\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Define the computation performed at every call.\u001b[39;00m\n\u001b[32m    365\u001b[39m \n\u001b[32m    366\u001b[39m \u001b[33;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m \u001b[33;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] is missing the required \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mforward\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m function\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNotImplementedError\u001b[39m: Module [BCModel] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # 학습\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_train, y_train in train_loader:\n",
    "        # 1. device로 이동\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        # 2. 추론\n",
    "        pred_train = model(X_train)\n",
    "        # 3. loss\n",
    "        loss = loss_fn(pred_train, y_train)\n",
    "        # 4. gradient 계산\n",
    "        loss.backward()\n",
    "        # 5. 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "        # 6. 파라미터 초기화 \n",
    "        optimizer.zero_grad()\n",
    "        # loss 누적\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # train loss 평균\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "    # 검증\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for X_valid, y_valid in test_loader:\n",
    "            # 1. device 이동\n",
    "            X_valid, y_valid = X_valid.to(device), y_valid.to(device)\n",
    "            # 2. 추론 \n",
    "            pred_valid = model(X_valid)  # (batch, 1)  1축: positive일 확률\n",
    "            pred_label = (pred_valid > 0.5).type(torch.int32)  # label\n",
    "            # 3. 평가 \n",
    "            valid_loss += loss_fn(pred_valid, y_valid).item()\n",
    "            valid_acc += torch.sum(pred_label == y_valid).item()\n",
    "\n",
    "        valid_loss /= len(test_loader)\n",
    "        valid_acc /= len(testset)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "\n",
    "        print(f\"{epoch+1}/{epochs}] train loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, valid acc: {valid_acc:.5f}\")\n",
    "\n",
    "        # 성능 개선 시 모델 저장 + 조기 종료\n",
    "        if valid_loss < best_score: # 개선됨\n",
    "            # 모델 저장 + stop_count 초기화\n",
    "            print(f\">>>>>>>>. {epoch+1} Epoch에서 모델을 저장합니다. {best_score}에서 {valid_loss}로 개선됨\")\n",
    "            torch.save(model, save_model_path)\n",
    "            best_score = valid_loss\n",
    "            stop_account = 0\n",
    "        else: # 개선 안 됨\n",
    "            stop_count += 1\n",
    "            if patience == stop_count:\n",
    "                print(f\"{epoch+1}에서 조기종료 합니다. {best_score}에서 개선이 안 됨\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######### 저장된 모델 로드\n",
    "\n",
    "load_bc_model = torch.load(save_model_path, weights_only=False)\n",
    "load_bc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 추론 함수 #######\n",
    "def predict_bc(model, X, device=\"cpu\"):\n",
    "    # model로 X를 추론한 결과를 반환\n",
    "    # label, 확률\n",
    "    result = []\n",
    "    with torch.no_grad():\n",
    "        pred_proba = model(X)\n",
    "        pred_class = (pred_proba > 0.5).type(torch.int32)\n",
    "        for class_index, proba in zip(pred_class, pred_proba):\n",
    "            # print(class_index, proba.item() if class_index.item() == 1 else 1-proba)\n",
    "            result.append((class_index.item(), proba.item() if class_index.item() == 1 else 1-proba.item()))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = torch.tensor(X_test_scaled[:5], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict_bc(load_model, new_data)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BCModel().to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [BCModel] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodule\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fit\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msave_models/bc_model2.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbinary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m     \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/07_deeplearning_pytorch/module/train.py:149\u001b[39m, in \u001b[36mfit\u001b[39m\u001b[34m(train_loader, val_loader, model, loss_fn, optimizer, epochs, save_best_model, save_model_path, early_stopping, patience, device, mode, lr_scheduler)\u001b[39m\n\u001b[32m    147\u001b[39m s = time.time()\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     train_loss, train_accuracy = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     \u001b[38;5;66;03m############ 1 epoch 학습 종료 -> LR 를 변경 ###########\u001b[39;00m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lr_scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/07_deeplearning_pytorch/module/train.py:88\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataloader, model, loss_fn, optimizer, device, mode)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[32m     87\u001b[39m     X, y = X.to(device), y.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     loss = loss_fn(pred, y)\n\u001b[32m     92\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/07_deeplearning_pytorch/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/07_deeplearning_pytorch/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/07_deeplearning_pytorch/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:374\u001b[39m, in \u001b[36m_forward_unimplemented\u001b[39m\u001b[34m(self, *input)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, *\u001b[38;5;28minput\u001b[39m: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    364\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Define the computation performed at every call.\u001b[39;00m\n\u001b[32m    365\u001b[39m \n\u001b[32m    366\u001b[39m \u001b[33;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    372\u001b[39m \u001b[33;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] is missing the required \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33mforward\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[33m function\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNotImplementedError\u001b[39m: Module [BCModel] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "from module.train import fit\n",
    "\n",
    "result = fit(train_loader, test_loader,\n",
    "    model, loss_fn, optimizer, \n",
    "    epochs=1000, save_best_model=True, save_model_path=\"save_models/bc_model2.pth\",\n",
    "    device=device, mode=\"binary\"     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 유형별 구현 정리\n",
    "\n",
    "## 공통\n",
    "\n",
    "-   Input layer(첫번째 Layer)의 in_features\n",
    "    -   입력데이터의 feature(속성) 개수에 맞춰준다.\n",
    "-   Hidden layer 수\n",
    "    -   경험적(art)으로 정한다.\n",
    "    -   Hidden layer에 Linear를 사용하는 경우 보통 feature 수를 줄여 나간다. (핵심 특성들을 추출해나가는 과정의 개념.)\n",
    "\n",
    "## 회귀 모델\n",
    "\n",
    "-   output layer의 출력 unit개수(out_features)\n",
    "    -   정답의 개수\n",
    "    -   ex\n",
    "        -   집값: 1\n",
    "        -   아파트가격, 단독가격, 빌라가격: 3 => y의 개수에 맞춘다.\n",
    "-   출력 Layer에 적용하는 activation 함수\n",
    "    -   일반적으로 **None**\n",
    "    -   값의 범위가 설정되 있고 그 범위의 값을 출력하는 함수가 있을 경우\n",
    "        -   ex) 0 ~ 1: logistic(Sigmoid), -1 ~ 1: hyperbolic tangent(Tanh)\n",
    "-   loss함수\n",
    "    -   MSELoss\n",
    "-   평가지표\n",
    "    -   MSE, RMSE, R square($R^2$)\n",
    "\n",
    "## 다중분류 모델\n",
    "\n",
    "-   output layer의 unit 개수\n",
    "    -   정답 class(고유값)의 개수\n",
    "-   출력 Layer에 적용하는 activation 함수\n",
    "    -   Softmax: 클래스별 확률을 출력\n",
    "-   loss함수\n",
    "    -   **categrocial crossentropy**\n",
    "    -   파이토치 함수\n",
    "        -   **CrossEntropyLoss** = NLLLoss(정답) + LogSoftmax(모델 예측값)\n",
    "        -   **NLLLoss**\n",
    "            -   정답을 OneHot Encoding 처리 후 Loss를 계산한다.\n",
    "            -   입력으로 LogSoftmax 처리한 모델 예측값과 onehot encoding 안 된 정답을 받는다.\n",
    "        -   **LogSoftmax**\n",
    "            -   입력값에 Softmax 계산후 그 Log를 계산한다.\n",
    "                -   NLLLoss의 모델 예측값 입력값으로 처리할 때 사용한다.\n",
    "\n",
    "```python\n",
    "pred = model(input)\n",
    "loss1 = nn.NLLLoss(nn.LogSoftmax(dim=-1)(pred), y)\n",
    "# or\n",
    "loss2 = nn.CrossEntropyLoss()(pred, y)\n",
    "```\n",
    "\n",
    "## 이진분류 모델\n",
    "\n",
    "-   output layer의 unit 개수\n",
    "    -   1개 (positive일 확률)\n",
    "-   출력 Layer에 적용하는 activation 함수\n",
    "    -   Sigmoid(Logistic)\n",
    "-   loss 함수\n",
    "    -   **Binary crossentropy**\n",
    "    -   파이토치 함수: **BCELoss**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
