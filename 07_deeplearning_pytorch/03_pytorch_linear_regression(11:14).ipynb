{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11/14(금) 14:30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LinearRegression from Scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구현할 것\n",
    "- 공부시간과 성적간의 관계를 모델링한다.\n",
    "    - **머신러닝 모델(모형)이란** 수집한 데이터를 기반으로 입력값(Feature)와 출력값(Target)간의 관계를 하나의 공식으로 정의한 함수이다. 그 공식을 찾는 과정을 **모델링**이라고 한다.\n",
    "    - 이 예제에서는 공부한 시험시간으로 점수를 예측하는 모델을 정의한다.\n",
    "    - 입력값과 출력값 간의 관계를 정의할 수있는 다양한 함수(공식)이 있다. 여기에서는 딥러닝과 관계가 있는 **Linear Regression** 을 사용해본다.\n",
    "\n",
    "# 데이터 확인\n",
    "- 입력데이터: 공부시간\n",
    "- 출력데이터: 성적\n",
    "\n",
    "|공부시간|점수|\n",
    "|-|-|\n",
    "|1|20|\n",
    "|2|40|\n",
    "|3|60|\n",
    "\n",
    "우리가 수집한 공부시간과 점수 데이터를 바탕으로 둘 간의 관계를 식으로 정의 할 수 있으면 **내가 몇시간 공부하면 점수를 얼마 받을 수 있는지 예측할 수 있게 된다.**   \n",
    "수집한 데이터를 기반으로 앞으로 예측할 수있는 모형을 만드는 것이 머신러닝 모델링이다.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습(훈련) 데이터셋 만들기\n",
    "- 모델을 학습시키기 위한 데이터셋을 구성한다.\n",
    "- 입력데이터와 출력데이터을 각각 다른 행렬로 구성한다.\n",
    "- 하나의 데이터 포인트의 입력/출력 값은 같은 index에 정의한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형회귀 (Linear Regression)\n",
    "- Feature들의 가중합을 이용해 Target을 추정한다.\n",
    "- Feature에 곱해지는 가중치(weight)들은 각 Feature가 Target 얼마나 영향을 주는지 영향도가 된다.\n",
    "    - 음수일 경우는 target값을 줄이고 양수일 경우는 target값을 늘린다.\n",
    "    - 가중치가 0에 가까울 수록 target에 영향을 주지 않는 feature이고 0에서 멀수록 target에 많은 영향을 준다.\n",
    "- 모델 학습과정에서 가장 적절한 Feature의 가중치를 찾아야 한다.\n",
    "      \n",
    "\n",
    "\\begin{align}\n",
    "&\\large \\hat{y} = W\\cdot X + b\\\\\n",
    "&\\small \\hat{y}: \\text{모델추정값}\\\\\n",
    "&\\small W: \\text{가중치}\\\\\n",
    "&\\small X: \\text{Feature(입력값)}\\\\\n",
    "&\\small b: \\text{bias(편향)}\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataset 구성\n",
    "- Train data는 feature(input)와 target(output) 각각 2개의 행렬로 구성한다.\n",
    "- Feature의 행은 관측치(개별 데이터)를 열을 Feature(특성, 변수)를 표현한다. 이 문제에서는 `공부시간` 1개의 변수를 가진다.\n",
    "- Target은 모델이 예측할 대상으로 행은 개별 관측치, 열은 각 항목에 대한 정답으로 구성.   \n",
    "  이 문제에서 예측할 항목은 `시험점수` 한개이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "X_train = torch.tensor([[1], [2], [3]], dtype=torch.float32) # 공부시간\n",
    "y_train = torch.tensor([[20], [40], [60]], dtype=torch.float32) # 시험점수\n",
    "X_train.size(), y_train.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파라미터 (weight, bias) 정의\n",
    "- 학습대상/최적화 대상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1]) torch.Size([1])\n",
      "tensor([[1.5398]], requires_grad=True)\n",
      "tensor([0.1440], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "weight = torch.randn(1, 1, requires_grad=True)  # feature에 곱할 값. (가중치)\n",
    "                            # (1: 입력 feature의 개수, 1: 출력값(예측값)의 개수)\n",
    "bias = torch.randn(1, requires_grad=True)\n",
    "print(weight.size(), bias.size())\n",
    "print(weight)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6838],\n",
       "        [3.2237],\n",
       "        [4.7635]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추론\n",
    "pred = X_train @ weight + bias\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.],\n",
       "        [40.],\n",
       "        [60.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1579.6830], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오차 계산\n",
    "loss = torch.mean((y_train - pred)**2, dim=0)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient 계산 -> loss에 대한 weight, bias의 순간 변화율 (gradient)를 계산.\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-171.7188]]), tensor([-73.5526]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.grad, bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18.7117]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.1\n",
    "weight.data = weight.data - weight.grad * lr\n",
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.4993])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.data = bias.data - bias.grad * lr\n",
    "bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "weight = torch.randn(1, 1, requires_grad=True)\n",
    "bias = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# 추론 모델\n",
    "def linear_model(X):\n",
    "    return X @ weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss (오차) 계산 함수\n",
    "def mse_loss_fn (pred, y):\n",
    "    return torch.mean((pred-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습\n",
    "1. 모델을 이용해 추정한다.\n",
    "   - pred = model(input)\n",
    "1. loss를 계산한다.\n",
    "   - loss = loss_fn(pred, target)\n",
    "1. 계산된 loss를 파라미터에 대해 미분하여 계산한 gradient 값을 각 파라미터에 저장한다.\n",
    "   - loss.backward()\n",
    "1. optimizer를 이용해 파라미터를 update한다.\n",
    "   - optimizer.step()  \n",
    "1. 파라미터의 gradient(미분값)을 0으로 초기화한다.\n",
    "   - optimizer.zero_grad()\n",
    "- 위의 단계를 반복한다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000  # train set을 몇 번 학습하는지. \n",
    "lr = 0.01\n",
    "for epoch in range(epochs):\n",
    "    # 1. 추론 (예측)\n",
    "    pred = linear_model (X_train)\n",
    "    # 2. 오차 계산\n",
    "    loss = mse_loss_fn(pred, y_train)\n",
    "    # 3. 파라미터들 (weight, bias)에 대한 gradient 계산\n",
    "    loss.backward()\n",
    "    # 4. 파라미터 업데이트\n",
    "    weight.data = weight.data - lr * weight.grad\n",
    "    bias.data = bias.data - lr * bias.grad\n",
    "    # 5. gradient 초기화\n",
    "    weight.grad = None\n",
    "    bias.grad = None\n",
    "\n",
    "    # 마지막 epoch, 100 epoch마다 loss를 출력 (성능 개선 상황을 모니터링)\n",
    "    if epoch % 100 == 0 and epoch == (epoch-1):\n",
    "        print(f\"[{epoch}/{epochs}] - loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[19.9715]]), tensor([0.0648]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.data, bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 99.9223],\n",
      "        [139.8653]])\n"
     ]
    }
   ],
   "source": [
    "# 추론\n",
    "with torch.no_grad():\n",
    "    new_X = torch.tensor([[5],[7]], dtype=torch.float32)\n",
    "    pred = linear_model (new_X)\n",
    "    print(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다중 입력, 다중 출력\n",
    "- 다중입력: Feature가 여러개인 경우\n",
    "- 다중출력: Output 결과가 여러개인 경우\n",
    "\n",
    "다음 가상 데이터를 이용해 사과와 오렌지 수확량을 예측하는 선형회귀 모델을 정의.  \n",
    "[참조](https://www.kaggle.com/code/aakashns/pytorch-basics-linear-regression-from-scratch)\n",
    "\n",
    "\n",
    "|온도(F)|강수량(mm)|습도(%)|사과생산량(ton)|오렌지생산량|\n",
    "|-|-|-|-:|-:|\n",
    "|73|67|43|56|70|\n",
    "|91|88|64|81|101|\n",
    "|87|134|58|119|133|\n",
    "|102|43|37|22|37|\n",
    "|69|96|70|103|119|\n",
    "\n",
    "```\n",
    "사과수확량  = w11 * 온도 + w12 * 강수량 + w13 * 습도 + b1\n",
    "오렌지수확량 = w21 * 온도 + w22 * 강수량 + w23 *습도 + b2\n",
    "```\n",
    "\n",
    "- `온도`, `강수량`, `습도` 값이 **사과**와, **오렌지 수확량**에 어느정도 영향을 주는지 가중치를 찾는다.\n",
    "    - 모델은 사과의 수확량, 오렌지의 수확량 **두개의 예측결과를 출력**해야 한다.\n",
    "    - 사과에 대해 예측하기 위한 weight 3개와 오렌지에 대해 예측하기 위한 weight 3개 이렇게 두 묶음, 총 6개의 weight를 정의하고 학습을 통해 가장 적당한 값을 찾는다.\n",
    "        - `개별 과일를 예측하기 위한 weight들 @ feature들` 의 계산 결과를  **Node, Unit, Neuron** 이라고 한다.\n",
    "        - 두 과일에 대한 Unit들을 묶어서 **Layer** 라고 한다.\n",
    "- 목적은 우리가 수집한 train 데이터셋을 이용해 **정확한 예측을 위한 weight와 bias 들**을 찾는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataset\n",
    "- Train data는 feature(input)와 target(output) 각각 2개의 행렬로 구성한다.\n",
    "- Feature의 행은 관측치(개별 데이터)를 열을 Feature(특성, 변수)를 표현한다. 이 문제에서는 `온도, 강수량, 습도` 세개의 변수를 가진다.\n",
    "- Target은 모델이 예측할 대상으로 행은 개별 관측치, 열은 각 항목에 대한 정답으로 구성한다. 이 문제에서 예측할 항목은 `사과수확량, 오렌지 수확량` 2개의 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  input: 생산환경 (temp, rainfall, humidity) : (5, 3)\n",
    "environs = [\n",
    "    [73, 67, 43], \n",
    "    [91, 88, 64], \n",
    "    [87, 134, 58], \n",
    "    [102, 43, 37], \n",
    "    [69, 96, 70]\n",
    "]\n",
    "\n",
    "# Targets: 생산량 - (apples, oranges) - (5, 2)\n",
    "apple_orange_output = [\n",
    "    [56, 70], \n",
    "    [81, 101], \n",
    "    [119, 133], \n",
    "    [22, 37], \n",
    "    [103, 119]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3]), torch.Size([5, 2]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Dataset을 torch.Tensor로 생성\n",
    "X = torch.tensor(environs, dtype=torch.float32)\n",
    "y = torch.tensor(apple_orange_output, dtype=torch.float32)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight와 bias\n",
    "- weight: 각 feature들이 생산량에 영향을 주었는지의 가중치로 feature에 곱해줄 값.\n",
    "    - 사과, 오렌지의 생산량을 구해야 하므로 가중치가 두개가 된다.\n",
    "    - weight의 shape: `(3, 2)`\n",
    "- bias는 모든 feature들이 0일때 생산량이 얼마일지를 나타내는 값으로 feature와 weight간의 가중합 결과에 더해줄 값이다.\n",
    "    - 사과, 오렌지의 생산량을 구하므로 bias가 두개가 된다.\n",
    "    - bias의 shape: `(2, )`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression model\n",
    "모델은 weights `w`와 inputs `x`의 내적(dot product)한 값에 bias `b`를 더하는 함수.\n",
    "\n",
    "$$\n",
    "\\hspace{2.5cm} X \\hspace{1.1cm} \\cdot \\hspace{1.2cm} W \\hspace{1.2cm}  + \\hspace{1cm} b \\hspace{2cm}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left[ \\begin{array}{cc}\n",
    "73 & 67 & 43 \\\\\n",
    "91 & 88 & 64 \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "69 & 96 & 70\n",
    "\\end{array} \\right]\n",
    "%\n",
    "\\cdot\n",
    "%\n",
    "\\left[ \\begin{array}{cc}\n",
    "w_{11} & w_{21} \\\\\n",
    "w_{12} & w_{22} \\\\\n",
    "w_{13} & w_{23}\n",
    "\\end{array} \\right]\n",
    "%\n",
    "+\n",
    "%\n",
    "\\left[ \\begin{array}{cc}\n",
    "b_{1} & b_{2} \\\\\n",
    "b_{1} & b_{2} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "b_{1} & b_{2} \\\\\n",
    "\\end{array} \\right]\n",
    "$$\n",
    "\n",
    "\n",
    "$w_{11},\\,w_{12},\\,w_{13}$: 사과 생산량 계산시 각 feature들(생산환경)에 곱할 가중치   <br>\n",
    "$w_{21},\\,w_{22},\\,w_{23}$: 오렌지 생산량 계산시 각 feature들(생산환경)에 곱할 가중치    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/kgmyhGit/image_resource/main/deeplearning/figures/3_unit_layer.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight/bias 를 정의 -> 초기값은 random 값을 이용해서 생성.\n",
    "weight = torch.randn(3, 2, requires_grad=True)\n",
    "bias = torch.randn(2, requires_grad=True)\n",
    "\n",
    "weight.size(), bias.size()\n",
    "# weight: (3:input feature개수  ,  2:output 개수)\n",
    "# bias  : (2:output 개수, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2992, -1.5517],\n",
       "        [-0.9342, -2.4584],\n",
       "        [ 0.5761,  0.4386]], requires_grad=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.3955, -0.5672], requires_grad=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 73.,  67.,  43.],\n",
       "        [ 91.,  88.,  64.],\n",
       "        [ 87., 134.,  58.],\n",
       "        [102.,  43.,  37.],\n",
       "        [ 69.,  96.,  70.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한번 학습(최적화)\n",
    "## 추론\n",
    "pred = X @ weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -14.5876, -259.6920],\n",
       "        [ -16.7233, -330.0375],\n",
       "        [ -64.3521, -439.5497],\n",
       "        [  13.0530, -248.3207],\n",
       "        [ -27.3219, -312.9360]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pred.size())\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(95549.4219, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## loss 계산(MSE)\n",
    "loss = torch.mean((pred - y)**2) # 전체 추론한 결과의 평균오차를 계산. dim = 0이라 생략. \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss를 가지고 파라미터들(weight들, bias들)의 gradient 계산.\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2992, -1.5517],\n",
       "        [-0.9342, -2.4584],\n",
       "        [ 0.5761,  0.4386]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -7980.4316, -34402.0078],\n",
       "        [-10158.7656, -38095.3945],\n",
       "        [ -5875.5112, -23152.6855]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.3955, -0.5672]), tensor([ -98.1864, -410.1072]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.data, bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 업데이트\n",
    "lr = 0.00001\n",
    "weight.data = weight.data - lr * weight.grad\n",
    "bias.data = bias.data - lr * bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3790, -1.2077],\n",
       "        [-0.8327, -2.0775],\n",
       "        [ 0.6349,  0.6702]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 업데이트된 파라미터로 추정 -> loss 계산\n",
    "pred2 = X @ weight + bias\n",
    "loss2 = torch.mean((pred2 - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95549.421875 64843.8359375\n"
     ]
    }
   ],
   "source": [
    "print(loss.item(), loss2.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.randn(3, 2, requires_grad=True)\n",
    "bias = torch.randn(2, requires_grad=True)\n",
    "\n",
    "## 모델 정의\n",
    "def model(X):\n",
    "    return X @ weight + bias\n",
    "\n",
    "## loss 함수(MSE)\n",
    "def loss_fn(pred, y):\n",
    "    return torch.mean((pred - y)**2) # 전체 오차의 평균."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001/5000] - 7291.89209\n",
      "[0101/5000] - 779.96088\n",
      "[0201/5000] - 228.29524\n",
      "[0301/5000] - 71.95204\n",
      "[0401/5000] - 26.80233\n",
      "[0501/5000] - 13.07234\n",
      "[0601/5000] - 8.33968\n",
      "[0701/5000] - 6.28163\n",
      "[0801/5000] - 5.09849\n",
      "[0901/5000] - 4.26405\n",
      "[1001/5000] - 3.61306\n",
      "[1101/5000] - 3.08456\n",
      "[1201/5000] - 2.64934\n",
      "[1301/5000] - 2.28919\n",
      "[1401/5000] - 1.99067\n",
      "[1501/5000] - 1.74307\n",
      "[1601/5000] - 1.53767\n",
      "[1701/5000] - 1.36728\n",
      "[1801/5000] - 1.22592\n",
      "[1901/5000] - 1.10864\n",
      "[2001/5000] - 1.01134\n",
      "[2101/5000] - 0.93063\n",
      "[2201/5000] - 0.86365\n",
      "[2301/5000] - 0.80809\n",
      "[2401/5000] - 0.76200\n",
      "[2501/5000] - 0.72376\n",
      "[2601/5000] - 0.69204\n",
      "[2701/5000] - 0.66572\n",
      "[2801/5000] - 0.64388\n",
      "[2901/5000] - 0.62577\n",
      "[3001/5000] - 0.61074\n",
      "[3101/5000] - 0.59827\n",
      "[3201/5000] - 0.58792\n",
      "[3301/5000] - 0.57934\n",
      "[3401/5000] - 0.57222\n",
      "[3501/5000] - 0.56632\n",
      "[3601/5000] - 0.56142\n",
      "[3701/5000] - 0.55735\n",
      "[3801/5000] - 0.55398\n",
      "[3901/5000] - 0.55117\n",
      "[4001/5000] - 0.54885\n",
      "[4101/5000] - 0.54693\n",
      "[4201/5000] - 0.54533\n",
      "[4301/5000] - 0.54400\n",
      "[4401/5000] - 0.54290\n",
      "[4501/5000] - 0.54199\n",
      "[4601/5000] - 0.54123\n",
      "[4701/5000] - 0.54060\n",
      "[4801/5000] - 0.54008\n",
      "[4901/5000] - 0.53965\n",
      "[5000/5000] - 0.53929\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "lr = 0.00001  # 1e-5\n",
    "for epoch in range(epochs):\n",
    "    # 1. 추론\n",
    "    pred = model(X)\n",
    "    \n",
    "    # 2. loss 계산\n",
    "    loss = loss_fn(pred, y)\n",
    "    # 3. 파라미터 들의 gradient 계산\n",
    "    loss.backward()\n",
    "    # 4. 파라미터 업데이트\n",
    "    weight.data = weight.data - lr * weight.grad\n",
    "    bias.data = bias.data - lr * bias.grad\n",
    "    # 5. gradient 초기화\n",
    "    weight.grad = None\n",
    "    bias.grad = None\n",
    "    ## 100 epoch, 마지막 epoch에서 loss를 출력 => 학습 과정 log를 출력\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        print(f\"[{epoch+1:04d}/{epochs}] - {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.2655,  70.4142],\n",
       "        [ 82.1816, 100.6142],\n",
       "        [118.5912, 132.9187],\n",
       "        [ 21.0446,  36.9956],\n",
       "        [102.0218, 119.1773]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 데이터로 추론\n",
    "p = model(X)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x = torch.tensor([68, 82, 56], dtype=torch.float32)\n",
    "new_x = new_x.unsqueeze(dim=0) # dummy 축 하나 늘려서 데이터 shape 맞춰줌.\n",
    "new_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[80.8438, 95.6138]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    p = model(new_x)\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch built-in 모델을 사용해 Linear Regression 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "    [[73, 67, 43], \n",
    "     [91, 88, 64], \n",
    "     [87, 134, 58], \n",
    "     [102, 43, 37], \n",
    "     [69, 96, 70]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.tensor(\n",
    "    [[56, 70], \n",
    "    [81, 101], \n",
    "    [119, 133], \n",
    "    [22, 37], \n",
    "    [103, 119]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.Linear\n",
    "Pytorch는 torch.nn.Linear 클래스를 통해 Linear Regression 모델을 제공.  \n",
    "torch.nn.Linear에 입력 feature의 개수와 출력 값의 개수를 지정하면 random 값으로 초기화한 weight와 bias들을 생성해 모델을 구성.\n",
    "- `torch.nn.Linear(input feature의 개수 , output 값의 개수)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer와 Loss 함수 정의\n",
    "- **Optimizer**: 계산된 gradient값을 이용해 파라미터들을 업데이트 하는 함수\n",
    "- **Loss 함수**: 정답과 모델이 예측한 값사이의 차이(오차)를 계산하는 함수.\n",
    "  - 모델을 최적화하는 것은 이 함수의 값을 최소화하는 것을 말한다. \n",
    "- `torch.optim` 모듈에 다양한 Optimizer 클래스가 구현돼있다.\n",
    "- `torch.nn` 또는 `torch.nn.functional` 모듈에 다양한 Loss 함수가 제공. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형회귀 모델을 정의. torch.nn.Linear 클래스\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Linear(3, 2)  # 3: input feature 개수, 2: output 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4015,  0.8481,  0.6864],\n",
       "        [-0.3049,  0.7944,  0.9083]], requires_grad=True)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.1618, 0.3350], requires_grad=True)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x112805540>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4015,  0.8481,  0.6864],\n",
      "        [-0.3049,  0.7944,  0.9083]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1618, 0.3350], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for a in model.parameters():\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 함수\n",
    "loss_fn = torch.nn.MSELoss()  # 클래스\n",
    "loss_fn = torch.nn.functional.mse_loss # 함수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer (torch.optim 모듈에 정의): weight.data = weight.data - lr * weight.grad\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), # 최적화 대상 파라미터들을 model에서 조회해서 전달.\n",
    "    lr = 0.00001,       # Learning Rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.1200, -0.3668, -0.5452],\n",
       "         [-0.2150,  0.1306, -0.5634]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0009,  0.1378], requires_grad=True)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001/5000] - 0.5230908393859863\n",
      "[0101/5000] - 0.5230861306190491\n",
      "[0201/5000] - 0.5230798721313477\n",
      "[0301/5000] - 0.5230717062950134\n",
      "[0401/5000] - 0.5230673551559448\n",
      "[0501/5000] - 0.5230611562728882\n",
      "[0601/5000] - 0.5230522155761719\n",
      "[0701/5000] - 0.5230481028556824\n",
      "[0801/5000] - 0.5230424404144287\n",
      "[0901/5000] - 0.5230342149734497\n",
      "[1001/5000] - 0.5230284929275513\n",
      "[1101/5000] - 0.5230208039283752\n",
      "[1201/5000] - 0.523013710975647\n",
      "[1301/5000] - 0.5230101346969604\n",
      "[1401/5000] - 0.5230016112327576\n",
      "[1501/5000] - 0.5229915380477905\n",
      "[1601/5000] - 0.5229874849319458\n",
      "[1701/5000] - 0.5229817628860474\n",
      "[1801/5000] - 0.5229753255844116\n",
      "[1901/5000] - 0.5229697227478027\n",
      "[2001/5000] - 0.5229617953300476\n",
      "[2101/5000] - 0.5229564309120178\n",
      "[2201/5000] - 0.5229493975639343\n",
      "[2301/5000] - 0.5229436159133911\n",
      "[2401/5000] - 0.5229352116584778\n",
      "[2501/5000] - 0.5229302644729614\n",
      "[2601/5000] - 0.5229254961013794\n",
      "[2701/5000] - 0.5229184031486511\n",
      "[2801/5000] - 0.5229124426841736\n",
      "[2901/5000] - 0.5229045152664185\n",
      "[3001/5000] - 0.522896409034729\n",
      "[3101/5000] - 0.522892951965332\n",
      "[3201/5000] - 0.5228856801986694\n",
      "[3301/5000] - 0.5228774547576904\n",
      "[3401/5000] - 0.522869884967804\n",
      "[3501/5000] - 0.5228673815727234\n",
      "[3601/5000] - 0.522860050201416\n",
      "[3701/5000] - 0.5228501558303833\n",
      "[3801/5000] - 0.5228453874588013\n",
      "[3901/5000] - 0.5228393077850342\n",
      "[4001/5000] - 0.5228325128555298\n",
      "[4101/5000] - 0.5228263139724731\n",
      "[4201/5000] - 0.5228190422058105\n",
      "[4301/5000] - 0.5228128433227539\n",
      "[4401/5000] - 0.5228074789047241\n",
      "[4501/5000] - 0.5228008031845093\n",
      "[4601/5000] - 0.5227920413017273\n",
      "[4701/5000] - 0.5227856040000916\n",
      "[4801/5000] - 0.522779107093811\n",
      "[4901/5000] - 0.5227733254432678\n",
      "[5000/5000] - 0.5227667093276978\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 추론\n",
    "    pred = model(inputs)  \n",
    "\n",
    "    # loss 계산\n",
    "    loss = loss_fn(pred, targets) # torch.nn.functional.mse_loss(pred, targets) # (모델추정값, 정답)\n",
    "\n",
    "    # gradient 계산\n",
    "    loss.backward()\n",
    "\n",
    "    # 파라미터 업데이트: optimizer.step()\n",
    "    optimizer.step()  # w = weight - lr * g\n",
    "\n",
    "    # 파라미터 초기화 w.grad=None, b.grad=None\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 현재 epoch 학습 결과를 log로 출력\n",
    "    if epoch % 100 == 0 or epoch == epochs-1:\n",
    "        print(f\"[{epoch+1:04d}/{epochs}] - {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 => gradient 계산을 할 필요가 없다. ==> grad_fn을 만들 필요가 없다. 그래서 torch.no_grad() 블록에서 추론 작업을 실행한다.\n",
    "with torch.no_grad():\n",
    "    pred = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.1715,  70.3419],\n",
       "        [ 82.1559, 100.5835],\n",
       "        [118.7989, 133.1033],\n",
       "        [ 21.1111,  37.0539],\n",
       "        [101.8147, 118.9932]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 로직을 함수 구현\n",
    "def train(inputs, targets, epochs, model, loss_fn, optimizer):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 추론\n",
    "        pred = model(inputs)\n",
    "        # loss 계산\n",
    "        loss = loss_fn(pred, targets) # torch.nn.functional.mse_loss(pred, targets) # (모델추정값, 정답)\n",
    "        # gradient 계산\n",
    "        loss.backward()\n",
    "        # 파라미터 업데이트: optimizer.step()\n",
    "        optimizer.step()\n",
    "        # 파라미터 초기화 w.grad=None, b.grad=None\n",
    "        optimizer.zero_grad()\n",
    "        # 현재 epoch 학습 결과를 log로 출력\n",
    "        if epoch % 100 == 0 or epoch == epochs-1:\n",
    "            print(f\"[{epoch+1:04d}/{epochs}] - {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0001/5000] - 6789.21484375\n",
      "[0101/5000] - 0.9640099406242371\n",
      "[0201/5000] - 0.5908817052841187\n",
      "[0301/5000] - 0.5337421894073486\n",
      "[0401/5000] - 0.5249785780906677\n",
      "[0501/5000] - 0.5236315131187439\n",
      "[0601/5000] - 0.5234196186065674\n",
      "[0701/5000] - 0.5233834385871887\n",
      "[0801/5000] - 0.5233713388442993\n",
      "[0901/5000] - 0.5233637094497681\n",
      "[1001/5000] - 0.5233577489852905\n",
      "[1101/5000] - 0.5233473777770996\n",
      "[1201/5000] - 0.5233420133590698\n",
      "[1301/5000] - 0.5233361721038818\n",
      "[1401/5000] - 0.5233300924301147\n",
      "[1501/5000] - 0.5233222842216492\n",
      "[1601/5000] - 0.5233172178268433\n",
      "[1701/5000] - 0.5233108401298523\n",
      "[1801/5000] - 0.5233049392700195\n",
      "[1901/5000] - 0.5232974886894226\n",
      "[2001/5000] - 0.5232869982719421\n",
      "[2101/5000] - 0.5232809782028198\n",
      "[2201/5000] - 0.5232780575752258\n",
      "[2301/5000] - 0.5232701897621155\n",
      "[2401/5000] - 0.5232641696929932\n",
      "[2501/5000] - 0.52325838804245\n",
      "[2601/5000] - 0.5232487916946411\n",
      "[2701/5000] - 0.523244321346283\n",
      "[2801/5000] - 0.5232349634170532\n",
      "[2901/5000] - 0.5232311487197876\n",
      "[3001/5000] - 0.5232218503952026\n",
      "[3101/5000] - 0.5232185125350952\n",
      "[3201/5000] - 0.5232118368148804\n",
      "[3301/5000] - 0.5232065916061401\n",
      "[3401/5000] - 0.5231969952583313\n",
      "[3501/5000] - 0.5231892466545105\n",
      "[3601/5000] - 0.5231848359107971\n",
      "[3701/5000] - 0.5231792330741882\n",
      "[3801/5000] - 0.5231720805168152\n",
      "[3901/5000] - 0.5231636762619019\n",
      "[4001/5000] - 0.5231582522392273\n",
      "[4101/5000] - 0.5231506824493408\n",
      "[4201/5000] - 0.5231462121009827\n",
      "[4301/5000] - 0.5231387615203857\n",
      "[4401/5000] - 0.5231327414512634\n",
      "[4501/5000] - 0.5231294631958008\n",
      "[4601/5000] - 0.5231212377548218\n",
      "[4701/5000] - 0.5231107473373413\n",
      "[4801/5000] - 0.523107647895813\n",
      "[4901/5000] - 0.523099958896637\n",
      "[5000/5000] - 0.5230963826179504\n"
     ]
    }
   ],
   "source": [
    "train(inputs, targets, 5000, model, nn.functional.mse_loss, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
