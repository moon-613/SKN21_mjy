{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af72f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/4(목) 11:05 \n",
    "# korpora에서 댓글 데이터셋 불러오기가 안돼서 수업 진행 어려운 상황 발생. 강사님 노트북 파일 확인할 것. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c9500-6e1f-445a-a5e1-95e687853ae8",
   "metadata": {},
   "source": [
    "# Pytorch의 nn.Embedding\n",
    "- Pytorch의 Embedding Layer는 word2vec과 마찬가지로 word embedding vector를 찾는 **Lookup Table**이다.\n",
    "    - 단어의 **정수의 고유 index**가 입력으로 들어오면 Embedding Layer의 **그 index의 Vector**를 출력한다.\n",
    "    - 모델이 학습되는 동안 모델이 풀려는 문제에 맞는 값으로 Embedding Layer의 vector들이 업데이트 된다.\n",
    "    - Word2Vec의 embedding vector 학습을 nn.Embedding은 자신이 포함된 모델을 학습 하는 과정에서 한다고 생각하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d936d8f7-a203-4452-978f-e2da81b7dafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/c1/rj7tb8cj0031l588c7fyvw0w0000gn/T/ipykernel_29982/2951309242.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/jiyouxg/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "embedding_model = nn.Embedding(\n",
    "    num_embeddings=20000,    # vocab size (어휘 사전의 어휘 개수): 몇 개 단어 (토큰)에 대한 Embedding vector를 만들지 설정. \n",
    "    embedding_dim=200,   # Embedding vector의 차원 수\n",
    "    padding_idx=0         # 패딩 토큰의 index 지정 (임베딩 벡터를 0으로 고정). 패딩토큰은 글자 수를 맞추기 위해 채우는 값 (0) 그래서 embedding 값을 학습할 필요가 없다. \n",
    ")\n",
    "# 20000 X 200\n",
    "# nn.GRU(input_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d166e4e-4ced-4bc8-a188-12358670ad0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파라미터 확인\n",
    "weight = embedding_model.weight\n",
    "weight.shape\n",
    "weight[0]  # 0번 토큰(단어)의 embedding vector값을 조회.\n",
    "# weight[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde9c759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 200])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"나는-30 어제-100 밥을-600 먹었다-7200 .-5\"\n",
    "# 문장을 tokenizer를 통해 토큰화 한 결과\n",
    "\n",
    "doc_token_ids = torch.tensor([[30, 100, 600, 7200, 5]], dtype=torch.int64)\n",
    "doc_embedding_vector = embedding_model(doc_token_ids)\n",
    "\n",
    "doc_embedding_vector.shape   # [1: batch_size-1문장, 5: seq_length-단어(토큰)수, 200: embedding_dim-임베딩차원수]\n",
    "# [1, 5, 200], [batch_size, seq_length, embedding_vector_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59640a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3661,  0.2736, -1.5940, -0.5587,  1.6689,  1.1925, -1.1581,  0.7669,\n",
       "        -0.1785, -1.5646, -0.8603,  0.8577,  1.3014,  1.6246,  0.3349, -0.7494,\n",
       "        -1.7568,  0.2815,  0.7216, -0.6675,  0.8816, -0.4538, -0.5445, -0.1195,\n",
       "         0.1197,  1.8077,  0.9520,  0.5193, -0.0086, -1.0241,  2.7715, -2.4833,\n",
       "        -1.3126,  0.9705, -0.5737, -0.4253, -0.6245,  2.1834,  1.2593, -0.2604,\n",
       "         0.4742,  1.2209,  2.3599, -1.9013, -0.9517,  2.6534,  0.6080, -0.6992,\n",
       "         0.6498, -1.0720, -0.7771,  0.4495, -1.2358, -0.5564, -0.3749,  0.5292,\n",
       "         0.9882,  2.0443,  1.0115,  0.6730, -0.3268, -0.5663, -1.7366, -0.8600,\n",
       "         1.3401,  0.3480, -0.8513, -1.3936, -0.5857, -0.0341,  0.4205, -0.4875,\n",
       "        -0.0205, -0.3502,  0.6332,  2.3436,  0.2351,  0.4444,  0.5333,  0.2411,\n",
       "         1.7213,  0.3681,  0.2508, -1.0141,  1.0352,  0.8461, -0.1280,  1.5227,\n",
       "        -1.1653, -1.1710, -0.0084, -0.0869, -0.5819, -1.0744, -0.2761,  0.0477,\n",
       "         1.2089, -1.1032,  0.1097,  0.5752, -1.3237,  1.2845,  0.1704,  1.4975,\n",
       "         0.5180, -0.5441,  0.3652, -0.1978,  1.1404, -1.4714, -1.3417,  0.1604,\n",
       "         0.5870,  0.3294, -0.3375,  0.9495,  0.6849,  0.7645, -0.4174,  0.9176,\n",
       "         0.3992,  0.1187, -1.0868, -0.6382, -1.9279, -0.8969,  0.5202,  1.5485,\n",
       "         0.0760,  0.5238,  1.1955, -0.7532, -0.4539,  0.0277, -1.1044, -0.9521,\n",
       "        -1.3269, -0.5215,  0.3768, -0.3520, -0.8286, -0.2877, -1.3160,  1.8219,\n",
       "        -1.1286, -0.3391, -0.4175,  0.8037,  1.3744,  1.0009, -0.3142, -1.1019,\n",
       "         0.2546,  0.6158,  1.3227, -0.1314, -0.6055,  0.3035, -0.0807, -0.2609,\n",
       "        -0.2112, -1.3160, -1.0603,  0.0464, -1.1281,  0.1640, -0.2754, -0.8532,\n",
       "         0.3562, -1.7485,  0.6362,  0.5592, -0.2453,  0.8342, -0.0468, -0.0673,\n",
       "         1.1254,  1.1314,  1.0995,  1.1538,  0.1081,  0.5910, -0.3002,  0.3446,\n",
       "        -0.3628,  1.4412,  0.1400,  0.1758, -0.3880,  1.7570,  1.2054, -2.0720,\n",
       "        -0.9389, -1.0648, -0.8013, -2.1477,  0.4363, -0.0077,  0.5170,  0.4814],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embedding_vector[0][0]  # 첫번째 문장, 첫번째 단어(토큰)의 embedding vector 조회    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d1a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca59e731-381d-4a79-83c4-1fc20ba006e1",
   "metadata": {},
   "source": [
    "# 네이버 영화 댓글 감성분석(Sentiment Analysis)\n",
    "\n",
    "## 감성분석(Sentiment Analysis) 이란\n",
    "입력된 텍스트가 **긍적적인 글**인지 **부정적인**인지 또는 **중립적인** 글인지 분석하는 것을 감성(감정) 분석이라고 한다.   \n",
    "이를 통해 기업이 고객이 자신들의 기업 또는 제품에 대해 어떤 의견을 가지고 있는지 분석한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7034ada-08b9-4163-b18d-ce429aef275b",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader 생성\n",
    "\n",
    "## Korpora에서 Naver 영화 댓글 dataset 가져오기\n",
    "- https://github.com/ko-nlp/Korpora\n",
    "- http://github.com/e9t/nsmc/\n",
    "    - input: 영화댓글\n",
    "    - output: 0(부정적댓글), 1(긍정적댓글)\n",
    "### API\n",
    "- **corpus 가져오기**\n",
    "    - `Korpora.load('nsmc')`\n",
    "- **text/label 조회**\n",
    "    - `corpus.get_all_texts()` : 전체 corpus의 text들을 tuple로 반환\n",
    "    - `corpus.get_all_labels()`: 전체 corpus의 label들을 list로 반환\n",
    "- **train/test set 나눠서 조회**\n",
    "    - `corpus.train`\n",
    "    - `corpus.test`\n",
    "    - `LabeledSentenceKorpusData` 객체에 text와 label들을 담아서 제공.\n",
    "        - `LabeledSentenceKorpusData.texts`: text들 tuple로 반환.\n",
    "        - `LabeledSentenceKorpusData.labels`: label들 list로 반환."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0e2ea3-6123-4ebd-8e98-27b1db6406ed",
   "metadata": {},
   "source": [
    "## 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aebdb0ac-eaaa-47aa-a0de-11d49e8a427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : e9t@github\n",
      "    Repository : https://github.com/e9t/nsmc\n",
      "    References : www.lucypark.kr/docs/2015-pyconkr/#39\n",
      "\n",
      "    Naver sentiment movie corpus v1.0\n",
      "    This is a movie review dataset in the Korean language.\n",
      "    Reviews were scraped from Naver Movies.\n",
      "\n",
      "    The dataset construction is based on the method noted in\n",
      "    [Large movie review dataset][^1] from Maas et al., 2011.\n",
      "\n",
      "    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n",
      "\n",
      "    # License\n",
      "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
      "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
      "\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSSLCertVerificationError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:1344\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1344\u001b[39m     \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1338\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1337\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1384\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1383\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1333\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1093\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1096\u001b[39m \n\u001b[32m   1097\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1037\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:1479\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1477\u001b[39m     server_hostname = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m-> \u001b[39m\u001b[32m1479\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1480\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1041\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1040\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1319\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1318\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mSSLCertVerificationError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mURLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mKorpora\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Korpora\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m corpus = \u001b[43mKorpora\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnsmc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 한국어 감성 분석 데이터셋 (네이버 영화 리뷰)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/Korpora/loader.py:47\u001b[39m, in \u001b[36mKorpora.load\u001b[39m\u001b[34m(cls, corpus_names, root_dir, force_download)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_single:\n\u001b[32m     46\u001b[39m     corpus_names = [corpus_names]\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m corpora = [\u001b[43mKORPUS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcorpus_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m corpus_name \u001b[38;5;129;01min\u001b[39;00m corpus_names]\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_single:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m corpora[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/Korpora/korpus_nsmc.py:44\u001b[39m, in \u001b[36mNSMCKorpus.__init__\u001b[39m\u001b[34m(self, root_dir, force_download)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m root_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     43\u001b[39m     root_dir = default_korpora_path\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43mfetch_nsmc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m NSMC_FETCH_INFORMATION:\n\u001b[32m     47\u001b[39m     local_path = os.path.join(os.path.abspath(root_dir), info[\u001b[33m'\u001b[39m\u001b[33mdestination\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/Korpora/korpus_nsmc.py:73\u001b[39m, in \u001b[36mfetch_nsmc\u001b[39m\u001b[34m(root_dir, force_download)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m NSMC_FETCH_INFORMATION:\n\u001b[32m     72\u001b[39m     local_path = os.path.join(os.path.abspath(root_dir), info[\u001b[33m'\u001b[39m\u001b[33mdestination\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnsmc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/Korpora/utils.py:215\u001b[39m, in \u001b[36mfetch\u001b[39m\u001b[34m(remote_path, local_path, corpus_name, force_download, method)\u001b[39m\n\u001b[32m    212\u001b[39m check_dir(destination)\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mdownload\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     \u001b[43mweb_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremote_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mgoogle_drive\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    217\u001b[39m     google_drive_download(remote_path, destination, corpus_name, force_download)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/Korpora/utils.py:110\u001b[39m, in \u001b[36mweb_download\u001b[39m\u001b[34m(url, local_path, corpus_name, force_download)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mweb_download\u001b[39m(url, local_path, corpus_name=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, force_download=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     site = \u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     meta = site.info()\n\u001b[32m    112\u001b[39m     remote_size = \u001b[38;5;28mint\u001b[39m(meta[\u001b[33m'\u001b[39m\u001b[33mContent-Length\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:515\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    512\u001b[39m     req = meth(req)\n\u001b[32m    514\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    518\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:532\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    531\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:1392\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/urllib/request.py:1347\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1344\u001b[39m         h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[32m   1345\u001b[39m                   encode_chunked=req.has_header(\u001b[33m'\u001b[39m\u001b[33mTransfer-encoding\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m   1346\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m   1348\u001b[39m     r = h.getresponse()\n\u001b[32m   1349\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[31mURLError\u001b[39m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1010)>"
     ]
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "corpus = Korpora.load(\"nsmc\")  # 한국어 감성 분석 데이터셋 (네이버 영화 리뷰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b08d5-bfcd-4430-b4c0-44b19bbf4022",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels[:5]  # 결과: [0, 1, 0, 0, 1]  (0: 부정, 1: 긍정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a23c0-06c5-49b7-b601-1ede1198b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_inputs)  # 결과: 200000  (훈련+테스트 데이터셋의 문장 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e0669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(corpus.train))\n",
    "corpus.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccee530",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.train.texts[:5]  # 훈련 데이터셋의 첫 5개 문장 조회\n",
    "corpus.train.labels[:5]  # 훈련 데이터셋의 첫 5개 레이블 조회\n",
    "# 결과: [0, 1, 0, 0, 1]  (0: 부정, 1: 긍정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f184aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.test\n",
    "# 결과: NSMC.test: size=50000\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e7e54a-548d-4bf3-81aa-357ab249f41a",
   "metadata": {},
   "source": [
    "## 토큰화\n",
    "1. 형태소 단위 token화\n",
    "    - konlpy로 token화 한 뒤 다시 한 문장으로 만든다.\n",
    "2. 1에서 처리한 corpus를 BPE 로 token화\n",
    "   \n",
    "### 전처리 함수\n",
    "\n",
    "#### 형태소 단위 분절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbb39b-9f49-4d29-a969-4839c01f430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import string\n",
    "import re\n",
    "\n",
    "kiwi = Kiwi()\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    1. 영문 -> 소문자로 변환\n",
    "    2. 구두점 제거\n",
    "    3. 형태소 기반 토큰화\n",
    "    4. 형태소로 토큰화 한 뒤 다시 하나의 문자열로 묶어서 반환.\n",
    "    \"\"\"\n",
    "\n",
    "    text = text.lower()  # 1. 영문 -> 소문자로 변환\n",
    "    text = re.sub(f\"[{string.punctuation}]\", ' ', text)  # 2. 구두점(특수문자) 제거. ' '으로 변환\n",
    "    text = [token.lemma for token in kiwi.tokenize(text)]   # [a, b, c]  # 3. 형태소 기반 토큰화\n",
    "    return ' '.join(text)  # 4. 형태소로 토큰화 한 뒤 다시 하나의 문자열로 묶어서 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f45e2f-f76a-4011-b963-d7feb214cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_inputs[100])  # 100번째 문장 조회\n",
    "# 결과: '신카이 마코토의 작화와, 미유와 하나카나가 연기를 잘해줘서 더 대박이였다'\n",
    "\n",
    "text_preprocessing(all_inputs[100])  # 100번째 문장에 대해 전처리 수행\n",
    "# 결과: '신카이 마코토 의 작화 와 미유 와 하나카나 가 연기 를 잘 하다 어 주다 어서 더 대박 이다 였 다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e658962-2fd6-4b1d-b4ef-a38de3ecc847",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = corpus.train.texts\n",
    "train_inputs = [text_preprocessing(txt) for txt in train_texts]\n",
    "\n",
    "test_texts = corpus.test.texts\n",
    "test_inputs = [text_preprocessing(txt) for txt in test_texts]\n",
    "\n",
    "train_labels = corpus.train.labels\n",
    "test_labels = corpus.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a25c93-7e26-4512-a0c0-56218fcda100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 pkl로 저장\n",
    "import os\n",
    "\n",
    "os.makedirs('data/nsmc')\n",
    "            \n",
    "train_data = {\"text\": train_texts, \"label\": train_labels}\n",
    "test_data = {\"text\": test_texts, \"label\": test_labels}\n",
    "\n",
    "import pickle\n",
    "with open('data/nsmc/preprocessed_train.pkl', 'wb') as f:\n",
    "    pickle.dump(train_data, f)  \n",
    "\n",
    "with open('data/nsmc/preprocessed_test.pkl', 'wb') as f:\n",
    "    pickle.dump(test_data, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7cad7-23d9-4212-b07a-0e5da2ff73c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = train_inputs + test_inputs   # list + list\n",
    "# train/test set의 댓글들을 합치기. -> 토크나이저 (어휘사전) 생성을 위해. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e519a68-d3a0-4481-bcf7-b121d8ba813f",
   "metadata": {},
   "source": [
    "### 토큰화\n",
    "- Subword 방식 토큰화 적용\n",
    "- Byte Pair Encoding 방식으로 huggingface tokenizer 사용\n",
    "    - BPE: 토큰을 글자 단위로 나눈뒤 가장 자주 등장하는 글자 쌍(byte paire)를 찾아 합친뒤 어휘사전에 추가.\n",
    "    - https://huggingface.co/docs/tokenizers/quicktour\n",
    "    - `pip install tokenizers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f162bdf-fac9-4468-a264-c656e4b3164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf80ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = 30_000\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=vocab_size,\n",
    "    min_frequency=5,\n",
    "    special_tokens=[\"<pad>\", \"<unk>\"],\n",
    "    continuing_subword_prefix=\"##\"    # 시작 subword는 그대로. 연결 subword는 '##' 붙이기\n",
    "    # cowork: co, ## work\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(all_inputs, trainer=trainer)\n",
    "\n",
    "# 학습 데이터가 파일: tokenizer.train([\"파일경로\"])\n",
    "# 학습 데이터가 메모리에 iterable 타입으로 있는 경우: tokenizer.train_from_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b29e1-384a-44e8-ab19-e53f0c1303c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어휘사전 크기\n",
    "tokernizer.get_vocab_size()  # 결과: 25639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e998d38b-e762-4fd5-b37f-8f8a2b6f5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "tokenizer.save(\"saved_models/nsmc_bpe_tokenizer.json\")\n",
    "# 불러오기 : load_tokenizer = Tokenizer.from_file('경로')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dbcdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코딩 테스트\n",
    "idx = 100\n",
    "print(all_inputs[idx])  # 원문\n",
    "\n",
    "encode = tokenizer.encode(all_inputs[idx])\n",
    "\n",
    "print(encode.tokens)  # 토큰화 결과\n",
    "print(encode.ids)     # 토큰 id 결과\n",
    "# 결과: 신카이 마코토 의 작화 와 미유 와 하나카나 가 연기 를 잘 하다 어 주다 어서 더 대박 이다 였 다\n",
    "# ['신카이', '마코토', '의', '작화', '와', '미', '##유', '와', ]\n",
    "# [20880, 19369, 2206, 8352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae1d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(encode.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f5c31d-633c-4a31-8f66-dff2ecf8e86a",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbda65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.token_to_id(\"<pad>\") # 결과: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c534953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 5\n",
    "seq_len = 2\n",
    "[1, 2] + ([0] *(5-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27280e-dfb7-4947-9192-777e6984286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset - Raw 데이터셋에서 학습할 때 필요한 데이터를 하나씩 제공 역할\n",
    "#           subscriptable 타입 (indexing이 가능한 것)의 클래스로 구현 (__len__, __getitem__(indx) 메소드 구현 필요)\n",
    "#           Dataset 객체 [0]   0번 학습데이터를 제공 (x[0], y[0])\n",
    "# DataLoader - Batch 단위로 묶어서 데이터를 제공. \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NSMCDataset(Dataset):\n",
    "    def __init__(self, texts, labels, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        texts: list - 댓글 리스트. 리스트에 댓글들을 담아서 받는다. [\"댓글\", \"댓글\", ...]\n",
    "        labels: list - Label 리스트. (댓글의 긍부정 여부 - 긍정: 1, 부정: 0)\n",
    "        max_length: 개별 댓글의 token 개수. 모든 댓글의 토큰수를 max_length에 맞춘다.\n",
    "        tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.labels = labels\n",
    "        self.texts = [ self.__pad_token_sequences(tokenizer.tokenize(txt).ids) for txt in texts]\n",
    "        # 댓글 -> 토큰 ID, max_length 크기에 맞춤 (토큰 수가 적으면 <pad> 추가, 많으면 잘라내기)\n",
    "\n",
    "    ###########################################################################################\n",
    "    # id로 구성된 개별 문장 token list를 받아서 패딩 추가 [20, 2, 1] => [20, 2, 1, 0, 0, 0, ..]\n",
    "    ############################################################################################\n",
    "    def __pad_token_sequences(self, token_sequences):\n",
    "        \"\"\"\n",
    "        token id로 구성된 개별 문서(댓글)의 token_id list를 받아서 max_length 길이에 맞추는 메소드\n",
    "        max_length 보다 토큰수가 적으면 [PAD] 토큰 추가, 많으면 max_length 크기로 줄인다.\n",
    "            ex) max_length=5 이고 pad토큰 id가 0이라면\n",
    "                [20, 2, 1] => [20, 2, 1, 0, 0]\n",
    "                [20, 21, 30, 34, 60, 17, 21, 33] -> [20, 21, 30, 34, 60]\n",
    "        \"\"\"\n",
    "        # <pad> 토큰 id 조회\n",
    "        pad_token_id = self.tokenizer.token_to_id(\"<pad>\")\n",
    "        # 입력 받은 토큰 시퀀스의 토큰 개수\n",
    "        seq_len = len(token_sequences)\n",
    "        # truncate 또는 padding 처리\n",
    "        if self.max_length < seq_len:  # truncate\n",
    "            result = token_sequences[:self.max_length]\n",
    "        else: # <pad> 추가\n",
    "            result = token_sequences + ([pad_token_id] * (self.max_length - seq_len))\n",
    "\n",
    "        return result\n",
    "        \n",
    "    def __len__(self):\n",
    "        # 총 데이터 셋의 개수를 반환\n",
    "        return len(self.texts)\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        idx 번째 text와 label을 학습 가능한 type으로 변환해서 반환\n",
    "        Parameter\n",
    "            idx: int 조회할 index\n",
    "        Return\n",
    "            tuple: (torch.LongTensor, torch.FloatTensor) - 댓글 토큰_id 리스트, 정답 Label\n",
    "        \"\"\"\n",
    "        comment = torch.tensor(self.texts[idx], dtype=torch.int64)   # 개별 댓글 token ID: dtype - int64 (정수). 실수형 불가.\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)   # label: dtype - float32 (실수형) 정수 실수 상관없음.\n",
    "    \n",
    "        return comment, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515bb6f-703d-4277-b645-8869267f5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "trainset = NSMCDataset(train_inputs, train_labels, max_length, tokenizer)\n",
    "testset = NSMCDataset(test_inputs, test_labels, max_length, tokenizer)\n",
    "\n",
    "len(trainset), len(testset)  # 결과: (150000, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f63e1-4ba8-4ccc-8c62-422b1f30b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset[0] # 0번째 댓글의 (토큰ID 리스트, 레이블) 조회. 결과: (tensor([6495, ...]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee963d58-0008-4fa6-b426-e3e332591f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5f00e-70fa-475b-8e2d-d06d120e3bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader), len(test_loader)  # 결과: (2343, 782)   150000/64=2343.75 -> drop_last=True 이므로 2343. 50000/64=781.25 -> 782"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b5f038-b32c-4e4e-82c8-956c7cbe0c4d",
   "metadata": {},
   "source": [
    "# 모델링\n",
    "- Embedding Layer를 이용해 Word Embedding Vector를 추출.\n",
    "- LSTM을 이용해 Feature 추출\n",
    "- Linear + Sigmoid로 댓글 긍정일 확률 출력\n",
    "  \n",
    "![outline](figures/rnn/RNN_outline.png)\n",
    "\n",
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac88afd6-5c8f-4ade-b930-86c9425e86e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e9cbbd8-d8b4-4a51-ac7a-5765722f139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSMCModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=1, bidirectional=True, dropout=0.2):\n",
    "\n",
    "        super(NSMCModel, self).__init__()\n",
    "        # 모델 구성 Layer들: embedding layer (단어 임베딩), lstm layer(문서, 문장 임베딩), linear(classifier) 분류\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,    # num_embeddings X embedding_dim \n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=0   # Padding token의 idx 지정. 이 index의 embedding vector는 학습하지 않는다. \n",
    "        )\n",
    "        # embedding_model의 출력 shape: (batch_size, seq_length, embedding_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers >1 else 0.0\n",
    "        )\n",
    "        self.classifier = nn.Linear(\n",
    "            in_features=hidden_size * 2 if bidirectional else hidden_size, \n",
    "            out_features=1   # 이진분류의 출력 - 양성일 확률 1개\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X(torch.Tensor): 입력 문서의 토큰 ID 리스트. shape: [batch_size, seq_length(max_length)], [64, 30]\n",
    "            연산 순서 -> embedding_model => (transpose) => lstm => classifier => sigmoid\n",
    "        \"\"\"\n",
    "        embedding_vector = self.embedding(X)\n",
    "        # X: [batch_size, seq_length] - (embedding) -> embedding_vector: [batch_size, seq_length, embedding_dim]\n",
    "\n",
    "        # batch_size 축과 seq_length 축을 바꿔주기 (lstm 입력 shape에 맞추기 위해) : index: [10, 5, 7] -> [5, 10, 7]\n",
    "        embedding_vector = embedding_vector.transpose(1, 0)\n",
    "\n",
    "        # rnn/lstm/gru 입력 (batch_first=False): (seq_length <-> batch_size, embedding_dim)\n",
    "\n",
    "        out, _  = self.lstm(embedding_vector)  # out, (hidden, cell) | _: (hidden, cell) 은 사용하지 않는다는 뜻.\n",
    "        # out.shape: [seq_length, batch, hidden_size * 2 if bidirectional else hidden_size]\n",
    "\n",
    "        output = self.classifier(out[-1])  # 마지막 시점의 출력값을 분류기로 입력\n",
    "        last_output = self.sigmoid(output)  # 양성일 확률로 변환\n",
    "        return last_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a0171-371e-4cb5-9bd5-ad1e3c14480d",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7830d2b5-d5ed-4b53-a442-bebc83077aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_dim = 100\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary (모델, (100, 784)) shape을 지정: input tensor type을 float 만들어서 실행.\n",
    "# embedding 모델은 입력을 LongTensor(int64) 타입으로 받기 때문에 summary()에 직접 int 타입 dummy data를 생성해서 전달. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edbe5b3d-8b2f-4164-9b97-29e6aadced5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NSMCClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchinfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[32m      3\u001b[39m dummy_data = torch.randint(\u001b[32m1\u001b[39m, \u001b[32m10\u001b[39m, (\u001b[32m64\u001b[39m, max_length))\n\u001b[32m      4\u001b[39m summary(\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mNSMCClassifier\u001b[49m(vocab_size, embedding_dim, hidden_size, num_layers, bidirectional, dropout),\n\u001b[32m      6\u001b[39m     input_data=dummy_data\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'NSMCClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# torch info로 모델 확인\n",
    "from torchinfo import summary\n",
    "dummy_data = torch.randint(1, 10, (64, max_length))\n",
    "summary(\n",
    "    NSMCClassifier(vocab_size, embedding_dim, hidden_size, num_layers, bidirectional, dropout),\n",
    "    input_data=dummy_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d229e-9a99-4a28-9dfd-9582686ba052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bdd5885-8150-4529-ad3a-84931a8824c5",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a1bf6-d8eb-42d0-996e-f975e93888af",
   "metadata": {},
   "source": [
    "### Train/Test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46099bec-eee3-4cef-921b-ce9ee6cf0f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. epoch 학습 함수\n",
    "def train(model, dataloader, loss_fn, optimizer, device=\"cpu\"):\n",
    "    # 1. 모델을 train 모드로 변경\n",
    "    model.train()  # 모델을 학습 모드로 전환\n",
    "    # 2. 모델을 device로 이동\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 1. epoch 학습\n",
    "    train_loss = 0.0\n",
    "    for X, y in dataloader:\n",
    "        # 1 step 학습\n",
    "        # 1. X, y를 device로 이동\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 2. 추론\n",
    "        pred = model(X)\n",
    "\n",
    "        # 3. 손실 계산. loss 계산\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 4. gradient 값 계산 - 오차역전파\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. weight/bias(파라미터) 업데이트 = new_weight = weight.data - weight.grad * learning_rate (학습율)\n",
    "        optimizer.step()\n",
    "\n",
    "        # 6. optimizer의 gradient 값 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 누적 손실 계산. loss 값 누적\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # avg_loss = train_loss / len(dataloader)  # 평균 손실 계산\n",
    "    return train_loss / len(dataloader) # 1 epoch 학습 loss를 반환. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5eb3ea-78e8-4248-a8ce-d07a4c362d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad  # 이 함수는 gradient 계산을 하지 않음. 평가/검증 시에만 사용.\n",
    "def eval(model, dataloader, loss_fn, device=\"cpu\"):\n",
    "    \"\"\"모델 평가/검증 함수\"\"\"\n",
    "    # 모델을 evaluation 모드로 변경 (평가/추론)\n",
    "    model.eval()  # 모델을 평가 모드로 전환\n",
    "    model = device(device)    # 모델을 device로 이동\n",
    "\n",
    "    eval_loss, eval_acc = 0.0, 0.0\n",
    "    for X, y in dataloader:\n",
    "        # 1 step 평가/검증\n",
    "        # 1. X, y를 device로 이동\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 2. 추론 - 양성일 확률이 출력. \n",
    "        pred_proba = model(X)\n",
    "        pred_label = (pred_proba > 0.5).dtype(torch.int32) # 확률 -> 레이블 (0/1) 변환. 0.5 보다 크면 1, 아니면 0\n",
    "\n",
    "        # 3. 평가\n",
    "        eval_loss += loss_fn(pred_proba, y).item()\n",
    "        eval_acc += (pred_label == y).sum().item()   # 정답과 일치하는 개수 누적. 현재 step에서 몇 개 맞았는지 대입. \n",
    "\n",
    "    return eval_loss / len(dataloader), eval_acc / len(dataloader.dataset) \n",
    "           # 평균 손실 계산, 정확도 계산: 맞춘 개수 / 전체 개수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de42da4-8991-4bcb-9ce9-18155459dec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c8853d0-b137-47bb-8f0d-fc4f05700cf2",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd806dda-5058-4c44-a3f4-28cadc8a90d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e18c2-17bf-4621-b630-b47e16c34bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6ec21-1d3c-48c2-b7c3-314daea6576c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32690441-482a-46b1-b91b-b85329d2141f",
   "metadata": {},
   "source": [
    "## 모델저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c16618-1517-4371-8e37-ae3cf03428b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d41e8-0715-4f50-aa37-11a8e142706a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3de7ed5-f7f6-4206-b16f-f8535a03405c",
   "metadata": {},
   "source": [
    "# 서비스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827bdaa3-008d-4a93-aee6-0877e829ef32",
   "metadata": {},
   "source": [
    "## 전처리 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2661a9-3964-4117-b273-e5d8bd4194b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "def text_preprocessing(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]+\", ' ', text)\n",
    "    return ' '.join(okt.morphs(text, stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315603df-159b-4317-9fb4-7897546b7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_token_sequences(token_sequences, max_length):\n",
    "    \"\"\"padding 처리 메소드.\"\"\"\n",
    "    pad_token = tokenizer.token_to_id('[PAD]')  \n",
    "    seq_length = len(token_sequences)           \n",
    "    result = None\n",
    "    if seq_length > max_length:                 \n",
    "        result = token_sequences[:max_length]\n",
    "    else:                                            \n",
    "        result = token_sequences + ([pad_token] * (max_length - seq_length))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73070a-0ee5-4f35-996c-b0d11ba08516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data_preprocessing(text_list):\n",
    "    \"\"\"\n",
    "    모델에 입력할 수있는 input data를 생성\n",
    "    Parameter:\n",
    "        text_list: list - 추론할 댓글리스트\n",
    "    Return\n",
    "        torch.LongTensor - 댓글 token_id tensor\n",
    "    \"\"\"\n",
    "   \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e19997-6b61-446f-ac72-376cd34ee495",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb00ab-60d0-45f2-bb16-505a5f5cc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list = [\"아 진짜 재미없다.\", \"여기 식당 먹을만 해요\", \"이걸 영화라고 만들었냐?\", \"기대 안하고 봐서 그런지 괜찮은데.\", \"이걸 영화라고 만들었나?\", \"아! 뭐야 진짜.\", \"재미있는데.\", \"연기 짱 좋아. 한번 더 볼 의향도 있다.\", \"뭐 그럭저럭\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c330d-69ff-43fb-9ee9-ad1c6054f9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273ac02-81f3-4391-b802-f9dca1f8d032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0510a47-9189-4c2a-a6e9-33b04971f2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
