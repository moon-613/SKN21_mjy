{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af72f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/4(목) 11:05 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c9500-6e1f-445a-a5e1-95e687853ae8",
   "metadata": {},
   "source": [
    "# Pytorch의 nn.Embedding\n",
    "- Pytorch의 Embedding Layer는 word2vec과 마찬가지로 word embedding vector를 찾는 **Lookup Table**이다.\n",
    "    - 단어의 **정수의 고유 index**가 입력으로 들어오면 Embedding Layer의 **그 index의 Vector**를 출력한다.\n",
    "    - 모델이 학습되는 동안 모델이 풀려는 문제에 맞는 값으로 Embedding Layer의 vector들이 업데이트 된다.\n",
    "    - Word2Vec의 embedding vector 학습을 nn.Embedding은 자신이 포함된 모델을 학습 하는 과정에서 한다고 생각하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d936d8f7-a203-4452-978f-e2da81b7dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "embedding_model = nn.Embedding(\n",
    "    num_embeddings=20000,    # vocab size (어휘 사전의 어휘 개수): 몇 개 단어 (토큰)에 대한 Embedding vector를 만들지 설정. \n",
    "    embedding_dim=10,   # Embedding vector의 차원 수\n",
    "    padding_idx=0         # 패딩 토큰의 index 지정 (임베딩 벡터를 0으로 고정). 패딩토큰은 글자 수를 맞추기 위해 채우는 값 (0) 그래서 embedding 값을 학습할 필요가 없다. \n",
    ")\n",
    "# 20000 X 200\n",
    "# nn.GRU(input_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d166e4e-4ced-4bc8-a188-12358670ad0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파라미터 확인\n",
    "weight = embedding_model.weight\n",
    "weight.shape\n",
    "weight[0]  # 0번 토큰(단어)의 embedding vector값을 조회.\n",
    "# weight[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde9c759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"나는-30 어제-100 밥을-600 먹었다-7200 .-5\"\n",
    "# 문장을 tokenizer를 통해 토큰화 한 결과\n",
    "\n",
    "doc_token_ids = torch.tensor([[30, 100, 600, 7200, 5]], dtype=torch.int64)  # 한 문장\n",
    "doc_token_ids = torch.tensor([[30, 100, 600, 7200, 5],[30, 100, 600, 7200, 5],[30, 100, 600, 7200, 5]], dtype=torch.int64)  # 여러문장\n",
    "doc_embedding_vector = embedding_model(doc_token_ids)\n",
    "\n",
    "doc_embedding_vector.shape   # [1: batch_size-1문장, 5: seq_length-단어(토큰)수, 200: embedding_dim-임베딩차원수]\n",
    "# [1, 5, 200], [batch_size, seq_length, embedding_vector_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59640a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2768,  0.9660,  0.1252,  0.9686, -0.3707, -0.3167,  0.6619, -1.6899,\n",
       "        -0.9751,  0.7222], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embedding_vector[0][1]  # 첫번째 문장, 첫번째 단어(토큰)의 embedding vector 조회    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0d1a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca59e731-381d-4a79-83c4-1fc20ba006e1",
   "metadata": {},
   "source": [
    "# 네이버 영화 댓글 감성분석(Sentiment Analysis)\n",
    "\n",
    "## 감성분석(Sentiment Analysis) \n",
    ": 입력된 텍스트가 **긍적적인 글**인지 **부정적인**인지 또는 **중립적인** 글인지 분석하는 것.   \n",
    "이를 통해 기업이 고객이 자신들의 기업 또는 제품에 대해 어떤 의견을 가지고 있는지 분석."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7034ada-08b9-4163-b18d-ce429aef275b",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader 생성\n",
    "\n",
    "## Korpora에서 Naver 영화 댓글 dataset 가져오기\n",
    "- https://github.com/ko-nlp/Korpora\n",
    "- http://github.com/e9t/nsmc/\n",
    "    - input: 영화댓글\n",
    "    - output: 0(부정적댓글), 1(긍정적댓글)\n",
    "### API\n",
    "- **corpus 가져오기**\n",
    "    - `Korpora.load('nsmc')`\n",
    "- **text/label 조회**\n",
    "    - `corpus.get_all_texts()` : 전체 corpus의 text들을 tuple로 반환\n",
    "    - `corpus.get_all_labels()`: 전체 corpus의 label들을 list로 반환\n",
    "- **train/test set 나눠서 조회**\n",
    "    - `corpus.train`\n",
    "    - `corpus.test`\n",
    "    - `LabeledSentenceKorpusData` 객체에 text와 label들을 담아서 제공.\n",
    "        - `LabeledSentenceKorpusData.texts`: text들 tuple로 반환.\n",
    "        - `LabeledSentenceKorpusData.labels`: label들 list로 반환."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0e2ea3-6123-4ebd-8e98-27b1db6406ed",
   "metadata": {},
   "source": [
    "## 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebdb0ac-eaaa-47aa-a0de-11d49e8a427b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : e9t@github\n",
      "    Repository : https://github.com/e9t/nsmc\n",
      "    References : www.lucypark.kr/docs/2015-pyconkr/#39\n",
      "\n",
      "    Naver sentiment movie corpus v1.0\n",
      "    This is a movie review dataset in the Korean language.\n",
      "    Reviews were scraped from Naver Movies.\n",
      "\n",
      "    The dataset construction is based on the method noted in\n",
      "    [Large movie review dataset][^1] from Maas et al., 2011.\n",
      "\n",
      "    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n",
      "\n",
      "    # License\n",
      "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
      "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
      "\n",
      "[Korpora] Corpus `nsmc` is already installed at /Users/jiyouxg/Korpora/nsmc/ratings_train.txt\n",
      "[Korpora] Corpus `nsmc` is already installed at /Users/jiyouxg/Korpora/nsmc/ratings_test.txt\n"
     ]
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "corpus = Korpora.load(\"nsmc\")  # 한국어 감성 분석 데이터셋 (네이버 영화 리뷰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a9b6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = corpus.get_all_texts()   # X: 댓글\n",
    "all_labels = corpus.get_all_labels()  # y: label (0: 부정적, 1: 긍정적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c08b08d5-bfcd-4430-b4c0-44b19bbf4022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels[:5]  # 결과: [0, 1, 0, 0, 1]  (0: 부정, 1: 긍정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232a23c0-06c5-49b7-b601-1ede1198b4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_inputs)  # 결과: 200000  (훈련+테스트 데이터셋의 문장 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6e0669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Korpora.korpora.LabeledSentenceKorpusData'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NSMC.train: size=150000\n",
       "  - NSMC.train.texts : list[str]\n",
       "  - NSMC.train.labels : list[int]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(corpus.train))\n",
    "corpus.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ccee530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train.texts[:5]  # 훈련 데이터셋의 첫 5개 문장 조회\n",
    "corpus.train.labels[:5]  # 훈련 데이터셋의 첫 5개 레이블 조회\n",
    "# 결과: [0, 1, 0, 0, 1]  (0: 부정, 1: 긍정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3f184aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NSMC.test: size=50000\n",
       "  - NSMC.test.texts : list[str]\n",
       "  - NSMC.test.labels : list[int]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e7e54a-548d-4bf3-81aa-357ab249f41a",
   "metadata": {},
   "source": [
    "## 토큰화\n",
    "1. 형태소 단위 token화\n",
    "    - konlpy로 token화 한 뒤 다시 한 문장으로 만든다.\n",
    "2. 1에서 처리한 corpus를 BPE 로 token화\n",
    "   \n",
    "### 전처리 함수\n",
    "\n",
    "#### 형태소 단위 분절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ae9367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string \n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbb39b-9f49-4d29-a969-4839c01f430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from konlpy.tag import Okt\n",
    "from kiwipiepy import Kiwi\n",
    "import string\n",
    "import re\n",
    "\n",
    "kiwi = Kiwi()\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    1. 영문 -> 소문자로 변환\n",
    "    2. 구두점 제거\n",
    "    3. 형태소 기반 토큰화\n",
    "    4. 형태소로 토큰화 한 뒤 다시 하나의 문자열로 묶어서 반환.\n",
    "    \"\"\"\n",
    "    text = text.lower()  # 1. 영문 -> 소문자로 변환\n",
    "    text = re.sub(f\"[{string.punctuation}]\", ' ', text)  # 2. 구두점(특수문자) 제거. ' '으로 변환\n",
    "    text = [token.lemma for token in kiwi.tokenize(text)]   # [a, b, c]  # 3. 형태소 기반 토큰화\n",
    "    return ' '.join(text)  # 4. 형태소로 토큰화 한 뒤 다시 하나의 문자열로 묶어서 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35f45e2f-f76a-4011-b963-d7feb214cc35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mall_inputs\u001b[49m[\u001b[32m100\u001b[39m])  \u001b[38;5;66;03m# 100번째 문장 조회\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 결과: '신카이 마코토의 작화와, 미유와 하나카나가 연기를 잘해줘서 더 대박이였다'\u001b[39;00m\n\u001b[32m      4\u001b[39m text_preprocessing(all_inputs[\u001b[32m100\u001b[39m])  \u001b[38;5;66;03m# 100번째 문장에 대해 전처리 수행\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'all_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "print(all_inputs[100])  # 100번째 문장 조회\n",
    "# 결과: '신카이 마코토의 작화와, 미유와 하나카나가 연기를 잘해줘서 더 대박이였다'\n",
    "\n",
    "text_preprocessing(all_inputs[100])  # 100번째 문장에 대해 전처리 수행\n",
    "# 결과: '신카이 마코토 의 작화 와 미유 와 하나카나 가 연기 를 잘 하다 어 주다 어서 더 대박 이다 였 다'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e658962-2fd6-4b1d-b4ef-a38de3ecc847",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = corpus.train.texts\n",
    "train_inputs = [text_preprocessing(txt) for txt in train_texts]\n",
    "\n",
    "test_texts = corpus.test.texts\n",
    "test_inputs = [text_preprocessing(txt) for txt in test_texts]\n",
    "\n",
    "train_labels = corpus.train.labels\n",
    "test_labels = corpus.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a25c93-7e26-4512-a0c0-56218fcda100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 pkl로 저장\n",
    "import os\n",
    "\n",
    "os.makedirs('data/nsmc')\n",
    "            \n",
    "train_data = {\"text\": train_texts, \"label\": train_labels}\n",
    "test_data = {\"text\": test_texts, \"label\": test_labels}\n",
    "\n",
    "import pickle\n",
    "with open('data/nsmc/preprocessed_train.pkl', 'wb') as f:\n",
    "    pickle.dump(train_data, f)  \n",
    "\n",
    "with open('data/nsmc/preprocessed_test.pkl', 'wb') as f:\n",
    "    pickle.dump(test_data, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07c7cad7-23d9-4212-b07a-0e5da2ff73c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = train_inputs + test_inputs   # list + list\n",
    "# train/test set의 댓글들을 합치기. -> 토크나이저 (어휘사전) 생성을 위해. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e519a68-d3a0-4481-bcf7-b121d8ba813f",
   "metadata": {},
   "source": [
    "### 토큰화\n",
    "- Subword 방식 토큰화 적용\n",
    "- Byte Pair Encoding 방식으로 huggingface tokenizer 사용\n",
    "    - BPE: 토큰을 글자 단위로 나눈뒤 가장 자주 등장하는 글자 쌍(byte paire)를 찾아 합친뒤 어휘사전에 추가.\n",
    "    - https://huggingface.co/docs/tokenizers/quicktour\n",
    "    - `pip install tokenizers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f162bdf-fac9-4468-a264-c656e4b3164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cf80ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 30_000\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=vocab_size,\n",
    "    min_frequency=5,\n",
    "    special_tokens=[\"<pad>\", \"<unk>\"],\n",
    "    continuing_subword_prefix=\"##\"    # 시작 subword는 그대로. 연결 subword는 '##' 붙이기\n",
    "    # cowork: co, ## work\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(all_inputs, trainer=trainer)\n",
    "\n",
    "# 학습 데이터가 파일: tokenizer.train([\"파일경로\"])\n",
    "# 학습 데이터가 메모리에 iterable 타입으로 있는 경우: tokenizer.train_from_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de9b29e1-384a-44e8-ab19-e53f0c1303c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24309"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어휘사전 크기\n",
    "tokenizer.get_vocab_size()  # 결과: 25639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e998d38b-e762-4fd5-b37f-8f8a2b6f5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "tokenizer.save(\"saved_models/nsmc_bpe_tokenizer.json\")\n",
    "# 불러오기 : load_tokenizer = Tokenizer.from_file('경로')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28dbcdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신카이 마코토 의 작화 와 미유 와 하나카나 가 연기 를 잘 하다 어 주다 어서 더 대박 이다 였 다\n",
      "['신카이', '마코토', '의', '작화', '와', '미', '##유', '와', '하나', '##카', '##나', '가', '연기', '를', '잘', '하다', '어', '주다', '어서', '더', '대박', '이다', '였', '다']\n",
      "[19992, 18569, 2174, 8774, 2078, 1444, 3140, 2078, 5401, 3158, 3115, 530, 5330, 1301, 2202, 5308, 2002, 5321, 5314, 993, 5654, 5305, 2048, 957]\n"
     ]
    }
   ],
   "source": [
    "# 인코딩 테스트\n",
    "idx = 100\n",
    "print(all_inputs[idx])  # 원문\n",
    "\n",
    "encode = tokenizer.encode(all_inputs[idx])\n",
    "\n",
    "print(encode.tokens)  # 토큰화 결과\n",
    "print(encode.ids)     # 토큰 id 결과\n",
    "# 결과: 신카이 마코토 의 작화 와 미유 와 하나카나 가 연기 를 잘 하다 어 주다 어서 더 대박 이다 였 다\n",
    "# ['신카이', '마코토', '의', '작화', '와', '미', '##유', '와', ]\n",
    "# [20880, 19369, 2206, 8352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ae1d519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'신카이 마코토 의 작화 와 미 ##유 와 하나 ##카 ##나 가 연기 를 잘 하다 어 주다 어서 더 대박 이다 였 다'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encode.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f5c31d-633c-4a31-8f66-dff2ecf8e86a",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cbda65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.token_to_id(\"<pad>\") # 결과: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c534953c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 0, 0, 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 5\n",
    "seq_len = 2\n",
    "[1, 2] + ([0] *(5-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27280e-dfb7-4947-9192-777e6984286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset - Raw 데이터셋에서 학습할 때 필요한 데이터를 하나씩 제공 역할\n",
    "#           subscriptable 타입 (indexing이 가능한 것)의 클래스로 구현 (__len__, __getitem__(indx) 메소드 구현 필요)\n",
    "#           Dataset 객체 [0]   0번 학습데이터를 제공 (x[0], y[0])\n",
    "# DataLoader - Batch 단위로 묶어서 데이터를 제공. \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NSMCDataset(Dataset):\n",
    "    def __init__(self, texts, labels, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        texts: list - 댓글 리스트. 리스트에 댓글들을 담아서 받는다. [\"댓글\", \"댓글\", ...]\n",
    "        labels: list - Label 리스트. (댓글의 긍부정 여부 - 긍정: 1, 부정: 0)\n",
    "        max_length: 개별 댓글의 token 개수. 모든 댓글의 토큰수를 max_length에 맞춘다.\n",
    "        tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.labels = labels\n",
    "        self.texts = [ self.__pad_token_sequences(tokenizer.encode(txt).ids) for txt in texts]\n",
    "        # 댓글 -> 토큰 ID, max_length 크기에 맞춤 (토큰 수가 적으면 <pad> 추가, 많으면 잘라내기)\n",
    "\n",
    "    ###########################################################################################\n",
    "    # id로 구성된 개별 문장 token list를 받아서 패딩 추가 [20, 2, 1] => [20, 2, 1, 0, 0, 0, ..]\n",
    "    ############################################################################################\n",
    "    def __pad_token_sequences(self, token_sequences):\n",
    "        \"\"\"\n",
    "        token id로 구성된 개별 문서(댓글)의 token_id list를 받아서 max_length 길이에 맞추는 메소드\n",
    "        max_length 보다 토큰수가 적으면 [PAD] 토큰 추가, 많으면 max_length 크기로 줄인다.\n",
    "            ex) max_length=5 이고 pad토큰 id가 0이라면\n",
    "                [20, 2, 1] => [20, 2, 1, 0, 0]\n",
    "                [20, 21, 30, 34, 60, 17, 21, 33] -> [20, 21, 30, 34, 60]\n",
    "        \"\"\"\n",
    "        # <pad> 토큰 id 조회\n",
    "        pad_token_id = self.tokenizer.token_to_id(\"<pad>\")\n",
    "        # 입력 받은 토큰 시퀀스의 토큰 개수\n",
    "        seq_len = len(token_sequences)\n",
    "        # truncate 또는 padding 처리\n",
    "        if self.max_length < seq_len:  # truncate\n",
    "            result = token_sequences[:self.max_length]\n",
    "        else: # <pad> 추가\n",
    "            result = token_sequences + ([pad_token_id] * (self.max_length - seq_len))\n",
    "\n",
    "        return result\n",
    "        \n",
    "    def __len__(self):\n",
    "        # 총 데이터 셋의 개수를 반환\n",
    "        return len(self.texts)\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        idx 번째 text와 label을 학습 가능한 type으로 변환해서 반환\n",
    "        Parameter\n",
    "            idx: int 조회할 index\n",
    "        Return\n",
    "            tuple: (torch.LongTensor, torch.FloatTensor) - 댓글 토큰_id 리스트, 정답 Label\n",
    "        \"\"\"\n",
    "        comment = torch.tensor(self.texts[idx], dtype=torch.int64)   # 개별 댓글 token ID: dtype - int64 (정수). 실수형 불가.\n",
    "        label = torch.tensor([self.labels[idx]], dtype=torch.float32)   # label: dtype - float32 (실수형) 정수 실수 상관없음.\n",
    "    \n",
    "        return comment, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9515bb6f-703d-4277-b645-8869267f5297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 50000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 30\n",
    "trainset = NSMCDataset(train_inputs, train_labels, max_length, tokenizer)\n",
    "testset = NSMCDataset(test_inputs, test_labels, max_length, tokenizer)\n",
    "\n",
    "len(trainset), len(testset)  # 결과: (150000, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "161f63e1-4ba8-4ccc-8c62-422b1f30b431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1959, 5778, 5332, 5488, 5351, 5327, 5946,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0] # 0번째 댓글의 (토큰ID 리스트, 레이블) 조회. 결과: (tensor([6495, ...]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee963d58-0008-4fa6-b426-e3e332591f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eea5f00e-70fa-475b-8e2d-d06d120e3bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2343, 50000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)  # 결과: (2343, 782)   150000/64=2343.75 -> drop_last=True 이므로 2343. 50000/64=781.25 -> 782"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b5f038-b32c-4e4e-82c8-956c7cbe0c4d",
   "metadata": {},
   "source": [
    "# 모델링\n",
    "- Embedding Layer를 이용해 Word Embedding Vector를 추출.\n",
    "- LSTM을 이용해 Feature 추출\n",
    "- Linear + Sigmoid로 댓글 긍정일 확률 출력\n",
    "  \n",
    "![outline](figures/rnn/RNN_outline.png)\n",
    "\n",
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac88afd6-5c8f-4ade-b930-86c9425e86e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9cbbd8-d8b4-4a51-ac7a-5765722f139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSMCClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=1, bidirectional=True, dropout=0.2):\n",
    "\n",
    "        super().__init__()\n",
    "        # 모델 구성 Layer들: embedding layer (단어 임베딩), lstm layer(문서, 문장 임베딩), linear(classifier) 분류\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size,    # num_embeddings X embedding_dim \n",
    "            embedding_dim=embedding_dim,\n",
    "            padding_idx=0   # Padding token의 idx 지정. 이 index의 embedding vector는 학습하지 않는다. \n",
    "        )\n",
    "        # embedding_model의 출력 shape: (batch_size, seq_length, embedding_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers >1 else 0.0\n",
    "        )\n",
    "        self.classifier = nn.Linear(\n",
    "            in_features=hidden_size * 2 if bidirectional else hidden_size, \n",
    "            out_features=1   # 이진분류의 출력 - 양성일 확률 1개\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X(torch.Tensor): 입력 문서의 토큰 ID 리스트. shape: [batch_size, seq_length(max_length)], [64, 30]\n",
    "            연산 순서 -> embedding_model => (transpose) => lstm => classifier => sigmoid\n",
    "        \"\"\"\n",
    "        embedding_vector = self.embedding(x)\n",
    "        # X: [batch_size, seq_length] - (embedding) -> embedding_vector: [batch_size, seq_length, embedding_dim]\n",
    "\n",
    "        # batch_size 축과 seq_length 축을 바꿔주기 (lstm 입력 shape에 맞추기 위해) : index: [10, 5, 7] -> [5, 10, 7]\n",
    "        embedding_vector = embedding_vector.transpose(1, 0)\n",
    "\n",
    "        # rnn/lstm/gru 입력 (batch_first=False): (seq_length <-> batch_size, embedding_dim)\n",
    "\n",
    "        out, _  = self.lstm(embedding_vector)  # out, (hidden, cell) | _: (hidden, cell) 은 사용하지 않는다는 뜻.\n",
    "        # out.shape: [seq_length, batch, hidden_size * 2 if bidirectional else hidden_size]\n",
    "\n",
    "        # 추론\n",
    "        output = self.classifier(out[-1])  # 마지막 시점의 출력값을 분류기로 입력\n",
    "        last_output = self.sigmoid(output)  # 양성일 확률로 변환\n",
    "        return last_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1a0171-371e-4cb5-9bd5-ad1e3c14480d",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7830d2b5-d5ed-4b53-a442-bebc83077aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_dim = 100\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary (모델, (100, 784)) shape을 지정: input tensor type을 float 만들어서 실행.\n",
    "# embedding 모델은 입력을 LongTensor(int64) 타입으로 받기 때문에 summary()에 직접 int 타입 dummy data를 생성해서 전달. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd70771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 147ms\u001b[0m\u001b[0m                                          \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m     0 B/19.39 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 16.00 KiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 32.00 KiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 48.00 KiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 64.00 KiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 80.00 KiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 96.00 KiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 112.00 KiB/19.39 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 128.00 KiB/19.39 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 144.00 KiB/19.39 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 160.00 KiB/19.39 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 176.00 KiB/19.39 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 192.00 KiB/19.39 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 208.00 KiB/19.39 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 224.00 KiB/19.39 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 240.00 KiB/19.39 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 256.00 KiB/19.39 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 464.00 KiB/19.39 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 1.65 MiB/19.39 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 2.61 MiB/19.39 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 2.72 MiB/19.39 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 3.09 MiB/19.39 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 3.36 MiB/19.39 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 3.74 MiB/19.39 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 6.11 MiB/19.39 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 8.39 MiB/19.39 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------------\u001b[0m\u001b[0m 9.40 MiB/19.39 MiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠸\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)\u001b[2m----------\u001b[0m\u001b[0m 12.72 MiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)----\u001b[2m------\u001b[0m\u001b[0m 15.07 MiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)------\u001b[2m----\u001b[0m\u001b[0m 16.64 MiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠼\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)-------\u001b[2m---\u001b[0m\u001b[0m 17.39 MiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)--------\u001b[2m--\u001b[0m\u001b[0m 17.72 MiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)---------\u001b[2m-\u001b[0m\u001b[0m 18.40 MiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠴\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/1)---------\u001b[2m-\u001b[0m\u001b[0m 18.66 MiB/19.39 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 922ms\u001b[0m\u001b[0m                                                  \u001b[1A\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 30ms\u001b[0m\u001b[0m                                 \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !uv pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "edbe5b3d-8b2f-4164-9b97-29e6aadced5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NSMCClassifier                           [64, 1]                   --\n",
       "├─Embedding: 1-1                         [64, 30, 100]             2,430,900\n",
       "├─LSTM: 1-2                              [30, 64, 128]             184,320\n",
       "├─Linear: 1-3                            [64, 1]                   129\n",
       "├─Sigmoid: 1-4                           [64, 1]                   --\n",
       "==========================================================================================\n",
       "Total params: 2,615,349\n",
       "Trainable params: 2,615,349\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 509.48\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 3.50\n",
       "Params size (MB): 10.46\n",
       "Estimated Total Size (MB): 13.98\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch info로 모델 확인\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "dummy_data = torch.randint(1, 10, (64, max_length))\n",
    "summary(\n",
    "    NSMCClassifier(vocab_size, embedding_dim, hidden_size, num_layers, bidirectional, dropout),\n",
    "    input_data=dummy_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d229e-9a99-4a28-9dfd-9582686ba052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bdd5885-8150-4529-ad3a-84931a8824c5",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a1bf6-d8eb-42d0-996e-f975e93888af",
   "metadata": {},
   "source": [
    "### Train/Test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46099bec-eee3-4cef-921b-ce9ee6cf0f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. epoch 학습 함수\n",
    "def train(model, dataloader, loss_fn, optimizer, device=\"cpu\"):\n",
    "    # 1. 모델을 train 모드로 변경\n",
    "    model.train()  # 모델을 학습 모드로 전환\n",
    "    # 2. 모델을 device로 이동\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 1. epoch 학습\n",
    "    train_loss = 0.0\n",
    "    for X, y in dataloader:\n",
    "        # 1 step 학습\n",
    "        # 1. X, y를 device로 이동\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 2. 추론\n",
    "        pred = model(X)\n",
    "\n",
    "        # 정답 레이블 y의 차원을 [batch_size] -> [batch_size, 1]로 확장\n",
    "        y_reshaped = y.unsqueeze(1)\n",
    "\n",
    "        # 3. 손실 계산. loss 계산\n",
    "        loss = loss_fn(pred, y_reshaped)\n",
    "\n",
    "        # 4. gradient 값 계산 - 오차역전파\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. weight/bias(파라미터) 업데이트 = new_weight = weight.data - weight.grad * learning_rate (학습율)\n",
    "        optimizer.step()\n",
    "\n",
    "        # 6. optimizer의 gradient 값 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 누적 손실 계산. loss 값 누적\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # avg_loss = train_loss / len(dataloader)  # 평균 손실 계산\n",
    "    return train_loss / len(dataloader) # 1 epoch 학습 loss를 반환. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4c5eb3ea-78e8-4248-a8ce-d07a4c362d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad  # 이 함수는 gradient 계산을 하지 않음. 평가/검증 시에만 사용.\n",
    "def eval(model, dataloader, loss_fn, device=\"cpu\"):\n",
    "    \"\"\"모델 평가/검증 함수\"\"\"\n",
    "    # 모델을 evaluation 모드로 변경 (평가/추론)\n",
    "    model.eval()  # 모델을 평가 모드로 전환\n",
    "    model.to(device)    # 모델을 device로 이동\n",
    "\n",
    "    eval_loss, eval_acc = 0.0, 0.0\n",
    "    for X, y in dataloader:\n",
    "        # 1 step 평가/검증\n",
    "        # 1. X, y를 device로 이동\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 2. 추론 - 양성일 확률이 출력. \n",
    "        pred_proba = model(X)\n",
    "        pred_label = (pred_proba > 0.5).type(torch.int32) # 확률 -> 레이블 (0/1) 변환. 0.5 보다 크면 1, 아니면 0\n",
    "\n",
    "        # 3. 평가\n",
    "        y_reshaped = y.unsqueeze(1) # 새로 정의\n",
    "        pred_label = (pred_proba > 0.5).type(torch.int32)\n",
    "        eval_loss += loss_fn(pred_proba, y_reshaped).item()\n",
    "        eval_acc += (pred_label == y_reshaped).sum().item()   # 정답과 일치하는 개수 누적. 현재 step에서 몇 개 맞았는지 대입. \n",
    "\n",
    "    return eval_loss / len(dataloader), eval_acc / len(dataloader.dataset) \n",
    "           # 평균 손실 계산, 정확도 계산: 맞춘 개수 / 전체 개수 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8853d0-b137-47bb-8f0d-fc4f05700cf2",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd806dda-5058-4c44-a3f4-28cadc8a90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "epochs = 3\n",
    "\n",
    "model = NSMCClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_size=hidden_size, \n",
    "    num_layers=num_layers, \n",
    "    bidirectional=bidirectional, \n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()  # 이진분류 손실 함수\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "816e18c2-17bf-4621-b630-b47e16c34bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6916674014293787 || 0.6917111043435336 || 0.51292\n",
      "0.6909147689752583 || 0.6914717893743515 || 0.51286\n",
      "0.6904817252549869 || 0.6913353633409739 || 0.51362\n",
      "학습에 걸린 시간: 569.3155970573425 초\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "s = time()\n",
    "\n",
    "train_loss_list = []\n",
    "eval_loss_list = []\n",
    "eval_acc_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, loss_fn, optimizer, device)\n",
    "    eval_loss, eval_acc = eval(model, test_loader, loss_fn, device)\n",
    "    train_loss_list.append(train_loss)\n",
    "    eval_loss_list.append(eval_loss)\n",
    "    eval_acc_list.append(eval_acc)\n",
    "    print(train_loss, eval_loss, eval_acc, sep=\" || \")\n",
    "\n",
    "e = time()\n",
    "print(\"학습에 걸린 시간:\", (e - s), \"초\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32690441-482a-46b1-b91b-b85329d2141f",
   "metadata": {},
   "source": [
    "## 모델저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80c16618-1517-4371-8e37-ae3cf03428b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "save() missing 1 required positional argument: 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msaved_models/nsmc_lstm_model.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: save() missing 1 required positional argument: 'f'"
     ]
    }
   ],
   "source": [
    "torch.save(\"saved_models/nsmc_lstm_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d41e8-0715-4f50-aa37-11a8e142706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = torch.load(\"saved_models/nsmc_lstm_model.pth\", weights_only = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de7ed5-f7f6-4206-b16f-f8535a03405c",
   "metadata": {},
   "source": [
    "# 서비스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827bdaa3-008d-4a93-aee6-0877e829ef32",
   "metadata": {},
   "source": [
    "## 전처리 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2661a9-3964-4117-b273-e5d8bd4194b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from kiwipiepy import Kiwi\n",
    "import string\n",
    "import re\n",
    "\n",
    "kiwi = Kiwi()\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    1. 영문 -> 소문자로 변환\n",
    "    2. 구두점 제거\n",
    "    3. 형태소 기반 토큰화\n",
    "    4. 형태소로 토큰화 한 뒤 다시 하나의 문자열로 묶어서 반환.\n",
    "    \"\"\"\n",
    "\n",
    "    text = text.lower()  # 1. 영문 -> 소문자로 변환\n",
    "    text = re.sub(f\"[{string.punctuation}]\", ' ', text)  # 2. 구두점(특수문자) 제거. ' '으로 변환\n",
    "    text = [token.lemma for token in kiwi.tokenize(text)]   # [a, b, c]  # 3. 형태소 기반 토큰화\n",
    "    return ' '.join(text)  # 4. 형태소로 토큰화 한 뒤 다시 하나의 문자열로 묶어서 반환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315603df-159b-4317-9fb4-7897546b7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_token_sequences(token_sequences, max_length):\n",
    "    \"\"\"padding 처리 메소드.\"\"\"\n",
    "    pad_token = tokenizer.token_to_id('<pad>')  \n",
    "    seq_length = len(token_sequences)           \n",
    "    result = None\n",
    "    if seq_length > max_length:                 \n",
    "        result = token_sequences[:max_length]\n",
    "    else:                                            \n",
    "        result = token_sequences + ([pad_token] * (max_length - seq_length))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73070a-0ee5-4f35-996c-b0d11ba08516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data_preprocessing(text_list):\n",
    "    \"\"\"\n",
    "    모델에 입력할 수있는 input data를 생성\n",
    "    Parameter:\n",
    "        text_list: list - 추론할 댓글리스트\n",
    "    Return\n",
    "        torch.LongTensor - 댓글 token_id tensor\n",
    "    \"\"\"\n",
    "   \n",
    "    # 기본 전처리\n",
    "    text_list = [text_preprocessing(txt) for txt in text_list]\n",
    "    # 토큰화 + token_id 변환 + padding 처리\n",
    "    token_id_list = [tokenizer.encode(txt).ids for txt in text_list]\n",
    "    # 토큰 개수 max_length 맞추기\n",
    "    token_list = [pad_token_sequences(token, max_length) for token in token_list]\n",
    "\n",
    "    return torch.tensor(token_list, dtype=torch.int64)  # 정수 형태로 바꿔줌. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e19997-6b61-446f-ac72-376cd34ee495",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb00ab-60d0-45f2-bb16-505a5f5cc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list = [\"아 진짜 재미없다.\", \"여기 식당 먹을만 해요\", \"이걸 영화라고 만들었냐?\", \"기대 안하고 봐서 그런지 괜찮은데.\", \"이걸 영화라고 만들었나?\", \"아! 뭐야 진짜.\", \"재미있는데.\", \"연기 짱 좋아. 한번 더 볼 의향도 있다.\", \"뭐 그럭저럭\"]\n",
    "input_tensor = predict_data_preprocessing(comment_list)\n",
    "input_tensor.shape  # 결과: torch.Size([9, 30])  9개 댓글, 30 토큰 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c330d-69ff-43fb-9ee9-ad1c6054f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273ac02-81f3-4391-b802-f9dca1f8d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred_proba = model(input_tensor)\n",
    "    pred_label = (pred_proba > 0.5).type(torch.int32)\n",
    "    for txt, pred_label in zip(comment_list, pred_label):\n",
    "        print(txt, end=\" ||||||| \")\n",
    "        print(\"긍정적 댓글\" if pred_label.item() == 1 else \"부정적 댓글\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
