{"cells":[{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkirS4goue2W","executionInfo":{"status":"ok","timestamp":1765172744609,"user_tz":-540,"elapsed":49,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"b72423ee-96b6-4b63-985e-f1b753859e10"},"id":"jkirS4goue2W","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Dec  8 05:45:44 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   46C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":2,"id":"d15df675","metadata":{"id":"d15df675","executionInfo":{"status":"ok","timestamp":1765172744615,"user_tz":-540,"elapsed":2,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["# 12/5(금) 9:20"]},{"cell_type":"markdown","id":"8389555c-17d0-41ed-abfc-42046bf8aeaa","metadata":{"id":"8389555c-17d0-41ed-abfc-42046bf8aeaa"},"source":["# Encoder–Decoder 구조\n","\n","- Encoder–Decoder 구조는 어떤 형태의 입력 시퀀스를 받아 **의미를 해석**한 뒤, 새로운 **출력 시퀀스를 생성**해야 하는 거의 모든 AI 문제를 해결하는 딥러닝 모델 구조다.\n","- 이 구조는 Encoder와 Decoder 두개의 딥러닝 모델을 연결한 구조로 **입력 데이터를 하나의 표현으로 압축한 뒤, 이를 다시 출력 데이터로 변환하는 방식**으로 동작한다.\n","\n","- **Encoder Network**\n","  - 입력 데이터를 해석(이해)하는 역할을 수행.\n","  - 입력 시퀀스에 담긴 의미적 정보를 하나의 고정된 벡터 형태로 요약.\n","\n","- **Decoder Network**\n","  - Encoder가 생성한 요약 정보를 바탕으로 최종 출력을 생성.\n","  - 즉, Encoder의 “이해 결과”를 이용해 새로운 시퀀스를 만들어낸다.\n","\n","## Seq2Seq (Sequence-to-Sequence)\n","\n","Seq2Seq 모델: **Encoder–Decoder 구조를 RNN(Recurrent Neural Network) 계열에 적용한 대표적인 시퀀스 변환 모델**.  \n","입력과 출력이 모두 “시퀀스(sequence)” 형태라는 점에서 *Sequence-to-Sequence*라는 이름이 붙었다.\n","\n","### Encoder의 역할: 입력 시퀀스 이해 및 Context Vector 생성\n","\n","Encoder는 입력으로 들어온 **전체 시퀀스**(sequence)를 순차적으로 처리한 뒤,  그 의미를 **하나의 고정 길이 벡터**(Vector)로 압축하여 출력한다.  \n","이 벡터를 **Context Vector**(컨텍스트 벡터)라고 한다.\n","- **Context Vector란?**  \n","  - 입력 시퀀스 전체의 의미, 문맥, 핵심 정보를 요약해 담고 있는 벡터 표현이다.\n","  - **기계 번역**(Machine Translation)의 경우  \n","    - 번역할 원문 문장에서 **번역 결과를 생성하는 데 필요한 핵심 의미 정보**(feature)\n","  - **챗봇**(Chatbot)의 경우  \n","    - 사용자가 입력한 질문에서 **적절한 답변을 생성하는 데 필요한 의미 정보**(feature)\n","\n","### Decoder의 역할: Context Vector를 바탕으로 출력 시퀀스 생성\n","\n","Decoder는 Encoder가 출력한 **Context Vector를 입력으로 받아**, 이를 바탕으로 **목표 출력 시퀀스**를 한 토큰(token)씩 순차적으로 생성.\n","\n","- **기계 번역**(Machine Translation)의 경우  \n","  - 입력 문장의 의미를 반영한 **번역 문장** 생성.\n","- **챗봇**(Chatbot)  \n","  - 질문에 대한 **자연스러운 답변 문장** 생성.\n","\n","Decoder는 매 시점(time step)마다\n","  - 이전에 생성한 단어\n","  - 그리고 Context Vector에 담긴 입력 문맥\n","을 함께 고려해 다음 단어를 예측.\n","\n","\n","![seq2seq](figures/seq2seq.png)"]},{"cell_type":"markdown","id":"9887d108-2ac6-425e-9643-d351e44282c7","metadata":{"id":"9887d108-2ac6-425e-9643-d351e44282c7"},"source":["# Seq2Seq 를 이용한 Chatbot 모델 구현\n","- Encoder를 이용해 질문의 특성을 추출하고 Decoder를 이용해 답변을 생성한다."]},{"cell_type":"markdown","id":"daec7aee-1d3b-4990-b934-a4254a6e17ef","metadata":{"id":"daec7aee-1d3b-4990-b934-a4254a6e17ef"},"source":["# Chatbot Dataset\n","\n","- https://github.com/songys/Chatbot_data\n","- columns\n","    - Q: 질문\n","    - A: 답\n","    - label: 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2\n","- **Download**\n","\n","![dataset](figures/chatbot.png)"]},{"cell_type":"markdown","id":"3fa75cf8-9cd9-4a72-a610-4392b80ca6b5","metadata":{"id":"3fa75cf8-9cd9-4a72-a610-4392b80ca6b5"},"source":["# Chatbot Dataset Loading 및 확인"]},{"cell_type":"markdown","id":"5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c","metadata":{"id":"5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c"},"source":["## 데이터셋 다운로드 및 확인"]},{"cell_type":"code","execution_count":4,"id":"876b85c4","metadata":{"id":"876b85c4","executionInfo":{"status":"ok","timestamp":1765180414081,"user_tz":-540,"elapsed":514,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["import requests\n","import os\n","\n","os.makedirs('data', exist_ok=True)\n","os.makedirs('saved_models', exist_ok=True)\n","\n","url = \"https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\"\n","res = requests.get(url)\n","if res.status_code == 200:\n","    with open(\"data/chatbot_data.csv\", \"wt\", encoding=\"utf-8\") as fw:\n","        fw.write(res.text)\n","else:\n","    print(\"다운 실패:\", res.status_code)"]},{"cell_type":"code","execution_count":5,"id":"395565ac","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"395565ac","executionInfo":{"status":"ok","timestamp":1765180415509,"user_tz":-540,"elapsed":269,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"437047f3-09ea-4ef4-c213-e5f17aa524e9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11823, 3)"]},"metadata":{},"execution_count":5}],"source":["import pandas as pd\n","\n","df = pd.read_csv(\"data/chatbot_data.csv\", encoding=\"utf-8\")\n","df.shape"]},{"cell_type":"code","execution_count":5,"id":"56432716","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56432716","executionInfo":{"status":"ok","timestamp":1765172745185,"user_tz":-540,"elapsed":20,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"76c9bd77-8f9e-4058-878e-54a6cc273474"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 11823 entries, 0 to 11822\n","Data columns (total 3 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   Q       11823 non-null  object\n"," 1   A       11823 non-null  object\n"," 2   label   11823 non-null  int64 \n","dtypes: int64(1), object(2)\n","memory usage: 277.2+ KB\n"]}],"source":["df.info()"]},{"cell_type":"code","execution_count":6,"id":"bf714bef","metadata":{"id":"bf714bef","executionInfo":{"status":"ok","timestamp":1765172745187,"user_tz":-540,"elapsed":14,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["df.drop(columns='label', inplace=True)"]},{"cell_type":"code","execution_count":7,"id":"cd68f4aa","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"cd68f4aa","executionInfo":{"status":"ok","timestamp":1765172745222,"user_tz":-540,"elapsed":33,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"a39e207f-2389-40e6-9999-5b69405a4418"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                         Q                   A\n","0                   12시 땡!          하루가 또 가네요.\n","1              1지망 학교 떨어졌어           위로해 드립니다.\n","2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.\n","3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.\n","4                  PPL 심하네          눈살이 찌푸려지죠.\n","5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.\n","6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.\n","7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.\n","8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.\n","9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요."],"text/html":["\n","  <div id=\"df-ecf2f59d-b146-4b01-a124-9d37034fd00d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12시 땡!</td>\n","      <td>하루가 또 가네요.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1지망 학교 떨어졌어</td>\n","      <td>위로해 드립니다.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3박4일 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3박4일 정도 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL 심하네</td>\n","      <td>눈살이 찌푸려지죠.</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>SD카드 망가졌어</td>\n","      <td>다시 새로 사는 게 마음 편해요.</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>SD카드 안돼</td>\n","      <td>다시 새로 사는 게 마음 편해요.</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n","      <td>잘 모르고 있을 수도 있어요.</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n","      <td>시간을 정하고 해보세요.</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n","      <td>시간을 정하고 해보세요.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecf2f59d-b146-4b01-a124-9d37034fd00d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ecf2f59d-b146-4b01-a124-9d37034fd00d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ecf2f59d-b146-4b01-a124-9d37034fd00d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-b28230ba-e7d7-4709-a388-d78c68a51adf\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b28230ba-e7d7-4709-a388-d78c68a51adf')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-b28230ba-e7d7-4709-a388-d78c68a51adf button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 11823,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11662,\n        \"samples\": [\n          \"\\uc0ac\\ub791\\ud558\\ub294 \\uc0ac\\ub78c \\uc78a\\ub294 \\ubc95\",\n          \"\\uc220 \\uc548 \\uba39\\uc73c\\uba74 \\uce5c\\uad6c\\ub791 \\ubb50\\ud558\\uc9c0\",\n          \"\\uc9dd\\ub0a8\\uc774 \\uace0\\uc2dc\\uc0dd\\uc774\\uba74 \\uae30\\ub2e4\\ub824\\uc57c \\ud558\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7779,\n        \"samples\": [\n          \"\\uc720\\uba38\\ucf54\\ub4dc\\uac00 \\ub9de\\ub294 \\uc0ac\\ub78c\\uc744 \\ucc3e\\uc544\\ubcf4\\uc138\\uc694.\",\n          \"\\uc5ec\\ud589\\uc744 \\ub5a0\\ub098 \\ubcf4\\uc138\\uc694.\",\n          \"\\ud589\\ubcf5\\ud560 \\uac70\\ub77c \\uc0dd\\uac01\\ud574\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":7}],"source":["df.head(10)"]},{"cell_type":"code","execution_count":8,"id":"b6273de4","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"b6273de4","executionInfo":{"status":"ok","timestamp":1765172745237,"user_tz":-540,"elapsed":5,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"de247056-d046-49f0-bd01-1d3866fd26d1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             Q                                            A\n","11813   회사에 좋아하는 남자가 생겼어 어떡하지?                              사랑하기 힘든 관계인가봐요.\n","11814   회사에서 어떤 사람이랑 자꾸 눈 마추쳐.                      눈 마주치는 게 우연인지 잘 살펴 보세요.\n","11815      회식 중이라고 하는데 연락이 안돼.  정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.\n","11816        회식하는데 나만 챙겨줘. 썸임?          호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.\n","11817            후회 없이 사랑하고 싶어                                진심으로 다가가 보세요.\n","11818           훔쳐보는 것도 눈치 보임.                           티가 나니까 눈치가 보이는 거죠!\n","11819           훔쳐보는 것도 눈치 보임.                                훔쳐보는 거 티나나봐요.\n","11820              흑기사 해주는 짝남.                                       설렜겠어요.\n","11821  힘든 연애 좋은 연애라는게 무슨 차이일까?                     잘 헤어질 수 있는 사이 여부인 거 같아요.\n","11822               힘들어서 결혼할까봐                           도피성 결혼은 하지 않길 바라요."],"text/html":["\n","  <div id=\"df-f9c0280b-db82-4560-879b-c1b836d81b46\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>11813</th>\n","      <td>회사에 좋아하는 남자가 생겼어 어떡하지?</td>\n","      <td>사랑하기 힘든 관계인가봐요.</td>\n","    </tr>\n","    <tr>\n","      <th>11814</th>\n","      <td>회사에서 어떤 사람이랑 자꾸 눈 마추쳐.</td>\n","      <td>눈 마주치는 게 우연인지 잘 살펴 보세요.</td>\n","    </tr>\n","    <tr>\n","      <th>11815</th>\n","      <td>회식 중이라고 하는데 연락이 안돼.</td>\n","      <td>정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.</td>\n","    </tr>\n","    <tr>\n","      <th>11816</th>\n","      <td>회식하는데 나만 챙겨줘. 썸임?</td>\n","      <td>호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.</td>\n","    </tr>\n","    <tr>\n","      <th>11817</th>\n","      <td>후회 없이 사랑하고 싶어</td>\n","      <td>진심으로 다가가 보세요.</td>\n","    </tr>\n","    <tr>\n","      <th>11818</th>\n","      <td>훔쳐보는 것도 눈치 보임.</td>\n","      <td>티가 나니까 눈치가 보이는 거죠!</td>\n","    </tr>\n","    <tr>\n","      <th>11819</th>\n","      <td>훔쳐보는 것도 눈치 보임.</td>\n","      <td>훔쳐보는 거 티나나봐요.</td>\n","    </tr>\n","    <tr>\n","      <th>11820</th>\n","      <td>흑기사 해주는 짝남.</td>\n","      <td>설렜겠어요.</td>\n","    </tr>\n","    <tr>\n","      <th>11821</th>\n","      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n","      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n","    </tr>\n","    <tr>\n","      <th>11822</th>\n","      <td>힘들어서 결혼할까봐</td>\n","      <td>도피성 결혼은 하지 않길 바라요.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9c0280b-db82-4560-879b-c1b836d81b46')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f9c0280b-db82-4560-879b-c1b836d81b46 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f9c0280b-db82-4560-879b-c1b836d81b46');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-425c50f1-c315-463d-ae84-256a4758262c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-425c50f1-c315-463d-ae84-256a4758262c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-425c50f1-c315-463d-ae84-256a4758262c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"\\ud798\\ub4e0 \\uc5f0\\uc560 \\uc88b\\uc740 \\uc5f0\\uc560\\ub77c\\ub294\\uac8c \\ubb34\\uc2a8 \\ucc28\\uc774\\uc77c\\uae4c?\",\n          \"\\ud68c\\uc0ac\\uc5d0\\uc11c \\uc5b4\\ub5a4 \\uc0ac\\ub78c\\uc774\\ub791 \\uc790\\uafb8 \\ub208 \\ub9c8\\ucd94\\uccd0.\",\n          \"\\ud6d4\\uccd0\\ubcf4\\ub294 \\uac83\\ub3c4 \\ub208\\uce58 \\ubcf4\\uc784.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\uc798 \\ud5e4\\uc5b4\\uc9c8 \\uc218 \\uc788\\ub294 \\uc0ac\\uc774 \\uc5ec\\ubd80\\uc778 \\uac70 \\uac19\\uc544\\uc694.\",\n          \"\\ub208 \\ub9c8\\uc8fc\\uce58\\ub294 \\uac8c \\uc6b0\\uc5f0\\uc778\\uc9c0 \\uc798 \\uc0b4\\ud3b4 \\ubcf4\\uc138\\uc694.\",\n          \"\\ud2f0\\uac00 \\ub098\\ub2c8\\uae4c \\ub208\\uce58\\uac00 \\ubcf4\\uc774\\ub294 \\uac70\\uc8e0!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":8}],"source":["df.tail(10)"]},{"cell_type":"code","execution_count":9,"id":"b75b95d9","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"id":"b75b95d9","executionInfo":{"status":"ok","timestamp":1765172745268,"user_tz":-540,"elapsed":15,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"f3c912ff-f3cf-4d12-a2d4-90ffe3fc46c2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Q    0\n","A    0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Q</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>A</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":9}],"source":["df.isnull().sum()"]},{"cell_type":"markdown","id":"d1aad072-2245-41e8-9863-a0b451262fdd","metadata":{"id":"d1aad072-2245-41e8-9863-a0b451262fdd"},"source":["# Dataset, DataLoader 정의"]},{"cell_type":"markdown","id":"cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c","metadata":{"id":"cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c"},"source":["## Tokenization\n","\n","### Subword방식"]},{"cell_type":"code","execution_count":10,"id":"67feeef0","metadata":{"id":"67feeef0","executionInfo":{"status":"ok","timestamp":1765172745299,"user_tz":-540,"elapsed":28,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["# 토큰화를 위해서 문장을 q + a 형식으로 만든다.\n","# 어휘사전을 만들 때 Q와 A에 있는 모든 단어들이 다 들어가게 하기 위해.\n","question_texts = df['Q']\n","answer_texts = df['A']\n","\n","all_texts = list(question_texts+\" \"+answer_texts)  # series + 문자열 + series (원소 단위 연산)"]},{"cell_type":"code","execution_count":11,"id":"6d1990cf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6d1990cf","executionInfo":{"status":"ok","timestamp":1765172745320,"user_tz":-540,"elapsed":19,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"780c048f-b922-416f-8f04-b590b318f882"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['12시 땡! 하루가 또 가네요.',\n"," '1지망 학교 떨어졌어 위로해 드립니다.',\n"," '3박4일 놀러가고 싶다 여행은 언제나 좋죠.',\n"," '3박4일 정도 놀러가고 싶다 여행은 언제나 좋죠.',\n"," 'PPL 심하네 눈살이 찌푸려지죠.',\n"," 'SD카드 망가졌어 다시 새로 사는 게 마음 편해요.',\n"," 'SD카드 안돼 다시 새로 사는 게 마음 편해요.',\n"," 'SNS 맞팔 왜 안하지ㅠㅠ 잘 모르고 있을 수도 있어요.',\n"," 'SNS 시간낭비인 거 아는데 매일 하는 중 시간을 정하고 해보세요.',\n"," 'SNS 시간낭비인데 자꾸 보게됨 시간을 정하고 해보세요.']"]},"metadata":{},"execution_count":11}],"source":["all_texts[:10]"]},{"cell_type":"code","execution_count":12,"id":"d96bf6ee","metadata":{"id":"d96bf6ee","executionInfo":{"status":"ok","timestamp":1765172746206,"user_tz":-540,"elapsed":884,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["from tokenizers import Tokenizer\n","from tokenizers.models import BPE\n","from tokenizers.pre_tokenizers import Whitespace\n","from tokenizers.trainers import BpeTrainer\n","\n","tokenizer = Tokenizer(\n","    BPE(unk_token=\"<unk>\")\n",")\n","tokenizer.pre_tokenizer = Whitespace()\n","trainer = BpeTrainer(\n","    vocab_size=10_000,    # 최대 어휘 수\n","    min_frequency=5,      # 어휘사전에 등록할 단어의 최소 빈도 수 (5회 이상은 나와야 등록)\n","    continuing_subword_prefix='##',    # 연결 subword 앞에 붙일 접두어를 ##로 지정. cowork: co + ##work\n","    special_tokens=[\"<pad>\", \"<unk>\", \"<sos>\"]   # <sos>는 문장의 시작을 의미하는 특수 토큰\n",")\n","tokenizer.train_from_iterator(all_texts, trainer=trainer)"]},{"cell_type":"code","execution_count":13,"id":"d70ae898","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d70ae898","executionInfo":{"status":"ok","timestamp":1765172746216,"user_tz":-540,"elapsed":6,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"5b0c23ef-0d90-456f-acb3-3a685e9cabca"},"outputs":[{"output_type":"stream","name":"stdout","text":["총 어휘 수: 7041\n"]}],"source":["print(\"총 어휘 수:\", tokenizer.get_vocab_size())"]},{"cell_type":"code","execution_count":14,"id":"a3b6d0ae","metadata":{"id":"a3b6d0ae","executionInfo":{"status":"ok","timestamp":1765172746220,"user_tz":-540,"elapsed":2,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["encode = tokenizer.encode(\"오늘 날씨가 너무 좋습니다. 이런 날씨에 뭘 하면 좋을까요?\")"]},{"cell_type":"code","execution_count":15,"id":"d0dfbd98","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0dfbd98","executionInfo":{"status":"ok","timestamp":1765172746244,"user_tz":-540,"elapsed":21,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"4420c1fe-55c8-4e14-b996-136bc3df549c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['오늘', '날씨가', '너무', '좋습니다', '.', '이런', '날씨', '##에', '뭘', '하면', '좋을까요', '?']"]},"metadata":{},"execution_count":15}],"source":["encode.tokens"]},{"cell_type":"code","execution_count":16,"id":"78448374","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78448374","executionInfo":{"status":"ok","timestamp":1765172746254,"user_tz":-540,"elapsed":8,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"fbf6c197-d2e2-4ed5-e1d7-17d886bf9064"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2290, 3851, 2258, 5914, 8, 2752, 2841, 1285, 527, 2530, 5532, 20]"]},"metadata":{},"execution_count":16}],"source":["encode.ids"]},{"cell_type":"code","execution_count":17,"id":"2b85dffc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2b85dffc","executionInfo":{"status":"ok","timestamp":1765172746264,"user_tz":-540,"elapsed":11,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"199101c2-99af-4341-95df-dabeae81fd88"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2530"]},"metadata":{},"execution_count":17}],"source":["tokenizer.id_to_token(1500)  # id로 토큰 문자열 조회\n","tokenizer.token_to_id(\"하면\") # 토큰 문자열로 id (정수)를 조회"]},{"cell_type":"markdown","id":"80caf0b3-01d5-4631-87c1-f48ab2f5bafc","metadata":{"id":"80caf0b3-01d5-4631-87c1-f48ab2f5bafc"},"source":["### Tokenizer 저장"]},{"cell_type":"code","execution_count":18,"id":"4a8eea16","metadata":{"id":"4a8eea16","executionInfo":{"status":"ok","timestamp":1765172746266,"user_tz":-540,"elapsed":2,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["tokenizer.save(\"saved_models/chatbot_bpe.json\")"]},{"cell_type":"code","execution_count":19,"id":"1d3e5ae9","metadata":{"id":"1d3e5ae9","executionInfo":{"status":"ok","timestamp":1765172746270,"user_tz":-540,"elapsed":2,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["load_tokenizer = Tokenizer.from_file(\"saved_models/chatbot_bpe.json\")"]},{"cell_type":"markdown","id":"ba2b068c-ead0-4f75-bd01-4a0ebf486774","metadata":{"id":"ba2b068c-ead0-4f75-bd01-4a0ebf486774"},"source":["## Dataset, DataLoader 정의\n","\n","\n","### Dataset 정의 및 생성\n","- 모든 문장의 토큰 수는 동일하게 맞춰준다.\n","    - DataLoader는 batch 를 구성할 때 batch에 포함되는 데이터들의 shape이 같아야 한다. 그래야 하나로 묶을 수 있다.\n","    - 문장의 최대 길이를 정해주고 **최대 길이보다 짧은 문장은 `<PAD>` 토큰을 추가**하고 **최대길이보다 긴 문장은 최대 길이에 맞춰 짤라준다.**"]},{"cell_type":"code","execution_count":20,"id":"92338cf3","metadata":{"id":"92338cf3","executionInfo":{"status":"ok","timestamp":1765172752865,"user_tz":-540,"elapsed":6593,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# device = \"mps\"  # 맥 M1 이상 쓰는 사람들"]},{"cell_type":"code","execution_count":21,"id":"c6418051","metadata":{"id":"c6418051","executionInfo":{"status":"ok","timestamp":1765172752888,"user_tz":-540,"elapsed":5,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["class ChatbotDataset(Dataset):\n","\n","    def __init__(self, question_texts, answer_texts, max_length, tokenizer):\n","        # __init__ 함수는 ChatbotDataset 객체를 만들 때 가장 먼저 실행. 필요한 모든 준비물 생성.\n","        \"\"\"\n","        Args:\n","            question_texts (list[str]): 질문 text 리스트. [\"질문1\", \"질문2\", ..]\n","            answer_texts (list[str]): 답변 text 리스트. [\"답변1\", \"답변2\", ...]\n","            max_length (int): 개별 문장의 최대 토큰 수\n","            tokenizer (Tokenzier): 위에서 훈련시킨 토크나이저 도구 (텍스트 -> 숫자 ID 변환)\n","        \"\"\"\n","        self.max_length = max_length\n","        self.tokenizer = tokenizer\n","        # \"질문\" -> Tensor(토큰 id)\n","        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n","        self.answer_texts = [self.__process_sequence(a) for a in answer_texts]\n","\n","    def __pad_token_sequence(self, token_sequence):\n","        \"\"\"\n","        token_sequence를 self.max_length 길이에 맞추는 메소드.\n","        max_length보다 적으면 <pad>를 추가, 크면 잘라낸다.\n","        Args:\n","            token_sequence (list[int]): 한 문장의 토큰 id 리스트. [2334, 7100, 257, ..]\n","        Returns:\n","            list[int]: 길이를 max_length에 맞춘 토큰 id 리스트\n","        \"\"\"\n","        pad_token = self.tokenizer.token_to_id('<pad>')\n","        seq_length = len(token_sequence)\n","        if seq_length > self.max_length: #잘라내기\n","            result = token_sequence[:self.max_length]\n","        else: # <pad> 추가 (padding 처리)\n","            result = token_sequence + [pad_token] * (self.max_length - seq_length)\n","\n","        return result\n","\n","    def __process_sequence(self, text):\n","        # 텍스트를 숫자로 변환하고 길이 맞추기\n","        # 하나의 텍스트(str)를 받아서 모델이 이해할 수 있는 숫자 형태의 텐서로 변환하는 메인 처리 과정.\n","        \"\"\"\n","        한 문장(text-str)을 받아서 token화 한 뒤 max_length에 개수를 맞춰서 반환.\n","        max_length에 맞추는 작업은 __pad_token_sequence() 를 이용\n","        Args:\n","            text (str): 토큰화할 문장\n","        Returns:\n","            torch.Tensor[int64]: 토큰화한 토큰 id 리스트\n","        \"\"\"\n","        encode = self.tokenizer.encode(text)\n","        token_ids = encode.ids # \"나는 학생이다.\" -> [4020, 1003, 3932]\n","        # [4020, 1003, 3932] -> [4020, 1003, 3932, 0, 0, 0 ] 패딩 처리.\n","        return torch.tensor(self.__pad_token_sequence(token_ids), dtype=torch.int64)\n","        #torch.tensor(...): 파이토치 모델이 학습할 수 있는 자료형인 텐서(torch.Tensor)로 최종 변환하여 반환\n","\n","    def __len__(self):    # 총 몇 쌍의 질문-답변 데이터가 있는지 반환.\n","        return len(self.question_texts)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        index의 (question, answer) 쌍을 반환.\n","        Args:\n","            index (int) : 몇번 질문-답변 쌍인지 index\n","        Return:\n","            tuple[Tensor(int64), Tensor(int64)]\n","        \"\"\"\n","        q = self.question_texts[index]\n","        a = self.answer_texts[index]\n","        return q, a"]},{"cell_type":"code","execution_count":22,"id":"a801ef2e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a801ef2e","executionInfo":{"status":"ok","timestamp":1765172753023,"user_tz":-540,"elapsed":131,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"e59669f9-e7bf-43ad-e1a6-d28367b5e2a3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["21"]},"metadata":{},"execution_count":22}],"source":["# max_length. 가장 긴 문장의 토큰 수\n","max([len(tokenizer.encode(sent).ids) for sent in question_texts]) # 결과: (제일 긴 토큰 수) 21."]},{"cell_type":"code","execution_count":23,"id":"0d0fe94c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0d0fe94c","executionInfo":{"status":"ok","timestamp":1765172753164,"user_tz":-540,"elapsed":129,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"29c7c749-7914-45c5-8794-d9601190f439"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["29"]},"metadata":{},"execution_count":23}],"source":["max([len(tokenizer.encode(sent).ids) for sent in answer_texts]) # 결과: 29. 제일 긴 토큰 수 29."]},{"cell_type":"code","execution_count":24,"id":"211c01ec","metadata":{"id":"211c01ec","executionInfo":{"status":"ok","timestamp":1765172753217,"user_tz":-540,"elapsed":49,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["####### 블로그 여기서부터 ########"]},{"cell_type":"code","execution_count":25,"id":"3adcf7d1","metadata":{"id":"3adcf7d1","executionInfo":{"status":"ok","timestamp":1765172753718,"user_tz":-540,"elapsed":512,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["max_length = 29   # 단순히 함수나 메소드의 입력값 (매개변수)이거나 내부에서만 생성되고 사용되는 지역변수 (local variable)\n","# self.max_length는 인스턴스 변수. 클래스로 만들어진 객체 (메소드)에 영구적으로 소속되는 변수\n","#    - 객체의 모든 메소드 (__init__, __pad_token_sequence, __process_sequence에서 self.접두사를 통해 접근하고 사용 가능.\n","dataset = ChatbotDataset(\n","    list(question_texts),\n","    list(answer_texts),\n","    max_length,\n","    tokenizer\n",")"]},{"cell_type":"code","execution_count":26,"id":"18d34e55","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18d34e55","executionInfo":{"status":"ok","timestamp":1765172753735,"user_tz":-540,"elapsed":14,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"c9aa82b1-9f45-4f1c-94d9-4c6e8e74a0d3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["11823"]},"metadata":{},"execution_count":26}],"source":["len(dataset)"]},{"cell_type":"code","execution_count":27,"id":"18a3659c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"18a3659c","executionInfo":{"status":"ok","timestamp":1765172753804,"user_tz":-540,"elapsed":66,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"5cdbe758-7b2a-4593-f4de-acf0895b6501"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([  10, 1688, 1423,  368,    3,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0]),\n"," tensor([6119,  378,   47, 2252,    8,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0]))"]},"metadata":{},"execution_count":27}],"source":["dataset[0]"]},{"cell_type":"markdown","id":"2b6d2b6f-ccf7-4aec-9c08-176a2456e813","metadata":{"id":"2b6d2b6f-ccf7-4aec-9c08-176a2456e813"},"source":["### Trainset / Testset 나누기\n","train : test = 0.95 : 0.05"]},{"cell_type":"code","execution_count":28,"id":"9c0c8fef","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9c0c8fef","executionInfo":{"status":"ok","timestamp":1765172753804,"user_tz":-540,"elapsed":19,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"2f632fdf-8fb8-4782-b197-40519ab7b862"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11231, 592)"]},"metadata":{},"execution_count":28}],"source":["train_size = int(len(dataset) * 0.95)\n","test_size = len(dataset) - train_size\n","train_size, test_size"]},{"cell_type":"code","execution_count":29,"id":"0b5d84a9","metadata":{"id":"0b5d84a9","executionInfo":{"status":"ok","timestamp":1765172753817,"user_tz":-540,"elapsed":17,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["train_set, test_set = random_split(dataset, [train_size, test_size])"]},{"cell_type":"code","execution_count":30,"id":"f9b45594","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9b45594","executionInfo":{"status":"ok","timestamp":1765172753834,"user_tz":-540,"elapsed":15,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"ef55bfe4-1902-497e-885a-02b95a1c90c8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.utils.data.dataset.Subset, torch.utils.data.dataset.Subset)"]},"metadata":{},"execution_count":30}],"source":["type(train_set), type(test_set)"]},{"cell_type":"code","execution_count":31,"id":"086a490e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"086a490e","executionInfo":{"status":"ok","timestamp":1765172753851,"user_tz":-540,"elapsed":14,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"3ca5a9e0-fdaf-488f-de8b-89474bc4f0b9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11231, 592)"]},"metadata":{},"execution_count":31}],"source":["len(train_set), len(test_set)"]},{"cell_type":"markdown","id":"3d4b274f-8c8a-4aa6-af6d-a66bf5c38210","metadata":{"id":"3d4b274f-8c8a-4aa6-af6d-a66bf5c38210"},"source":["### DataLoader 생성"]},{"cell_type":"code","execution_count":32,"id":"a1ad8cd9","metadata":{"id":"a1ad8cd9","executionInfo":{"status":"ok","timestamp":1765172753868,"user_tz":-540,"elapsed":21,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["train_loader = DataLoader(train_set, batch_size=64, shuffle=True, drop_last=True)\n","test_loader = DataLoader(test_set, batch_size=64)"]},{"cell_type":"code","execution_count":33,"id":"0a596315","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0a596315","executionInfo":{"status":"ok","timestamp":1765172753872,"user_tz":-540,"elapsed":22,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"fbb0e59f-edee-419f-866d-2a55ccf0f571"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(175, 10)"]},"metadata":{},"execution_count":33}],"source":["len(train_loader), len(test_loader)"]},{"cell_type":"markdown","id":"1cdaf424-c7de-46be-b74b-88a3efcdf352","metadata":{"id":"1cdaf424-c7de-46be-b74b-88a3efcdf352"},"source":["# 모델 정의\n","\n","## Seq2Seq 모델 정의\n","- Seq2Seq 모델은 Encoder와 Decoder의 입력 Sequence의 길이와 순서가 자유롭기 때문에 챗봇이나 번역에 이상적인 구조다.\n","    - 단일 RNN은 각 timestep 마다 입력과 출력이 있기 때문에 입/출력 sequence의 개수가 같아야 한다.\n","    - 챗봇의 질문/답변이나 번역의 대상/결과 문장의 경우는 사용하는 어절 수가 다른 경우가 많기 때문에 단일 RNN 모델은 좋은 성능을 내기 어렵다.\n","    - Seq2Seq는 **입력처리(질문,번역대상)처리 RNN과 출력 처리(답변, 번역결과) RNN 이 각각 만들고 그 둘을 연결한 형태로 길이가 다르더라도 상관없다.**"]},{"cell_type":"markdown","id":"e17d7410-a73e-4be1-b41d-9ea07d6b0911","metadata":{"id":"e17d7410-a73e-4be1-b41d-9ea07d6b0911"},"source":["## Encoder\n","Encoder는 하나의 Vector를 생성하며 그 Vector는 **입력 문장의 의미**를 N 차원 공간 저장하고 있다. 이 Vector를 **Context Vector** 라고 한다.    \n","![encoder](figures/seq2seq_encoder.png)"]},{"cell_type":"code","execution_count":34,"id":"0c8e8f6e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0c8e8f6e","executionInfo":{"status":"ok","timestamp":1765172753884,"user_tz":-540,"elapsed":16,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"d65bec7e-625e-4623-a3de-324d3066547a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[ 0.4437,  1.6229, -0.3730, -1.3440, -0.4414],\n","        [ 0.7348,  1.1359,  0.8620, -1.0334, -0.6263],\n","        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n","        [ 1.1294,  1.3087,  0.4740, -0.0779, -0.3797],\n","        [-0.3300, -0.3802,  1.0529,  0.1690, -0.4074],\n","        [-0.2940, -0.4099,  1.4110,  0.1749, -0.5372],\n","        [ 0.3936, -0.8466, -0.6153,  1.8404, -0.7762],\n","        [-0.6639, -0.8016,  0.4594,  0.0857,  0.2158],\n","        [ 1.2846, -0.0233, -1.1615,  0.8319,  1.0113],\n","        [-1.2540, -0.1888, -1.9043, -1.1500,  0.5018],\n","        [ 0.7758, -0.0719, -0.9424,  0.6382,  3.1382],\n","        [ 0.2905, -2.0901, -0.7081,  0.3937,  0.6949],\n","        [-0.9438, -0.3324,  0.2988,  1.3795, -0.4842],\n","        [ 1.0343,  0.7396,  0.6721, -1.1905,  1.6577],\n","        [-0.1991, -0.3999, -1.5060, -0.1968, -1.0367],\n","        [-0.2924, -0.1986, -2.0274, -0.1313, -0.9454],\n","        [ 0.0778,  2.0525,  1.7324,  0.4729, -0.7755],\n","        [ 1.2765, -0.1781,  2.0201, -0.9284,  0.2085],\n","        [ 1.1320, -1.8938, -0.6679,  0.5575, -0.0243],\n","        [-1.1543,  0.3786, -0.2084,  0.3996, -0.4691],\n","        [-0.4751, -0.5471, -0.6309,  1.0160,  0.2544],\n","        [-1.4730,  1.2245, -1.1171, -0.0971, -0.8188],\n","        [ 0.1902,  0.8024, -0.4763, -0.3627, -2.6541],\n","        [-1.2734, -2.0873, -0.2851, -1.0143, -1.2339],\n","        [ 0.1731,  2.3966, -0.5866,  0.3845, -0.5391],\n","        [ 1.2085,  1.2359, -0.0347,  0.5962, -0.3643],\n","        [-0.9174, -0.9046, -0.8763,  0.6652, -0.4309],\n","        [-0.3964, -0.0839,  0.8602, -0.2456, -1.7671],\n","        [-1.0751, -0.0334, -0.0694, -1.6426, -0.2816],\n","        [ 2.3677,  2.2496,  0.8421, -1.1984,  1.3949],\n","        [ 0.0929, -0.4011, -1.1456, -0.0407,  1.3252],\n","        [ 1.8682,  0.3565, -0.9685, -1.1663,  0.2214],\n","        [ 0.9121, -0.6091, -0.1428,  1.0150,  0.3298],\n","        [-1.5102,  1.0291,  1.1279, -0.1975, -0.0583],\n","        [ 1.2634, -0.1670,  1.3093,  0.2186, -0.0454],\n","        [-1.2506, -1.7577, -0.4794,  2.1332,  0.4721],\n","        [ 0.0142,  2.9721, -0.5501,  0.0650,  0.6693],\n","        [-0.9461,  1.1855, -0.8019, -0.0842,  0.3058],\n","        [-1.6699,  2.2920, -0.4828,  0.4661, -0.9612],\n","        [-0.0929,  0.5354,  0.0382, -1.6349,  1.6877],\n","        [-0.2009,  0.3533, -0.9062, -2.5446,  1.2510],\n","        [ 0.6002, -0.1133, -2.4711, -1.4745, -0.0048],\n","        [-0.2785,  0.6353,  0.7369, -0.6156,  0.4607],\n","        [ 0.4737, -0.7465, -1.1809, -0.9091, -1.1134],\n","        [ 1.9734, -2.8121,  0.7511, -1.2043, -0.2179],\n","        [ 2.0122,  1.2149, -0.3560,  2.5084, -0.6898],\n","        [-0.3393, -0.2970, -0.5236, -0.9566,  0.9102],\n","        [ 0.3199,  1.0615, -0.2874, -0.5860,  0.2957],\n","        [ 0.1469,  0.3801,  0.9400, -0.4835, -0.9857],\n","        [-0.0774, -0.0338, -0.0346,  1.3607,  1.8039],\n","        [ 1.9330, -0.7106,  0.3041,  0.3501,  0.6535],\n","        [-1.3142, -0.2222, -0.0772,  1.1852,  0.8080],\n","        [ 0.6580, -0.3848,  0.3820,  0.0602, -2.0632],\n","        [-0.9294,  0.0679,  0.6407,  1.9939, -0.0269],\n","        [-0.7785, -0.7430,  1.0681, -1.0181,  1.5345],\n","        [-0.6683,  0.2789,  0.1776,  1.3586, -0.4283],\n","        [ 1.1410,  0.9891, -0.0773, -0.5005,  1.0232],\n","        [ 0.7531,  1.4034,  0.4692,  0.8895,  0.8168],\n","        [ 1.6732, -0.2434,  0.9001, -1.2413,  0.2679],\n","        [-0.3317, -1.0212, -0.4092, -1.3326, -0.8142],\n","        [-2.3976, -0.7850,  0.8064, -2.1217, -1.7430],\n","        [-0.9589,  0.1316, -0.6462, -1.6261, -0.5543],\n","        [ 0.9440, -0.3376, -1.4263, -0.5286,  1.3496],\n","        [-0.9722,  0.3489, -1.5182, -0.1036,  0.7743],\n","        [ 0.4314, -1.5763,  0.2502, -0.1238, -0.3646],\n","        [-0.1807, -1.5852, -0.5076,  0.3846, -0.6389],\n","        [ 0.6667,  0.0345, -1.6426,  0.1262, -0.0526],\n","        [-0.3346, -0.8788,  1.2119,  0.3996, -2.0210],\n","        [ 2.2045, -1.9328, -0.9886,  0.5027, -1.5893],\n","        [-0.8263, -0.8596,  1.6257, -0.5684,  1.8280],\n","        [ 0.0818, -1.1567,  0.4178,  1.8895, -0.0883],\n","        [-1.0517,  0.7120, -1.7281,  1.8124, -0.2636],\n","        [ 0.8621, -0.3231,  1.1035,  0.0885,  0.9669],\n","        [-0.2913,  0.4237, -2.0679,  0.9282,  0.2568],\n","        [ 0.6782,  0.5609,  0.7934, -0.0071,  0.2973],\n","        [-0.3347,  0.8565,  0.1058,  1.7756, -0.1913],\n","        [ 0.1402, -0.0520, -0.3788,  0.1367, -0.2064],\n","        [-1.9932,  1.6183, -0.7037,  0.8623, -1.7534],\n","        [ 2.0572, -1.0769, -0.5727,  1.5231, -0.7044],\n","        [ 0.8771,  0.2932, -0.0876, -0.3130, -2.3658],\n","        [ 1.4431, -0.4453, -0.0746,  0.8249,  0.3972],\n","        [ 0.4498, -1.9243,  0.6351,  1.4633,  0.5987],\n","        [-0.2901,  0.0734,  0.8465, -0.0293, -0.6775],\n","        [-0.1826,  0.9126,  0.6589,  0.2951, -0.1360],\n","        [-0.5641,  1.1145, -0.2233, -1.0170,  0.9569],\n","        [-0.0741, -0.8239, -0.1042, -0.0338, -0.0975],\n","        [-0.1382,  2.7398, -0.3958,  0.8458, -1.8221],\n","        [ 0.6068, -0.6509,  0.0195,  1.2557,  0.2115],\n","        [ 2.1823,  0.3613,  0.8215, -1.1062,  0.5975],\n","        [ 0.2036,  0.1558,  0.5377,  0.5313, -0.1683],\n","        [-0.5914, -0.5486, -0.2799,  0.5962, -0.1263],\n","        [-0.1954, -1.6252,  0.5087,  0.2786,  0.3235],\n","        [ 0.7734, -0.1661,  0.0227,  0.7662,  1.1309],\n","        [-0.1252, -0.8446,  1.3605,  0.0041,  1.4648],\n","        [-0.6048,  0.3777,  0.5371, -0.4452, -0.5700],\n","        [ 0.5359,  0.8345, -0.2746,  0.7124,  0.7027],\n","        [-0.4421, -1.2307, -0.9157,  0.9913, -1.1663],\n","        [-2.8409, -0.6749, -0.9186, -0.7668, -1.7289],\n","        [ 0.6328, -0.6761,  1.8886, -1.4064,  0.5655],\n","        [-0.2443,  0.5837, -0.1739,  0.7907,  0.8292]], requires_grad=True)"]},"metadata":{},"execution_count":34}],"source":["a = nn.Embedding(100, 5, padding_idx=2)\n","a.weight"]},{"cell_type":"code","execution_count":35,"id":"477135dd","metadata":{"id":"477135dd","executionInfo":{"status":"ok","timestamp":1765172753903,"user_tz":-540,"elapsed":20,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","\n","    def __init__(\n","            self,\n","            vocab_size: int,   # 총 어휘 수\n","            embedding_dim: int,   # Embedding Vector의 차원\n","            hidden_size: int, # GRU의 hidden 개수\n","            bidirectional: bool = True,   # GRU의 양방향 여부\n","            num_layers: int = 1,   # GRU의 layer stack 수\n","            dropout: float = 0.2   # dropout의 비율\n","        ):\n","            super().__init__()\n","            self.vocab_size = vocab_size\n","            # X -> (Embedding Model) -> (GRU) -> Context Vector -> (Decoder)\n","            # Encoder의 목적은 (질문의) Context Vector를 추출하는 것이 목적.\n","            self.embedding = nn.Embedding(\n","                 vocab_size,\n","                 embedding_dim,  # (vocab_size X embedding_dim)\n","                 padding_idx=0\n","            )\n","\n","            self.gru = nn.GRU(\n","                 input_size=embedding_dim,\n","                 hidden_size=hidden_size,\n","                 num_layers=num_layers,\n","                 bidirectional=bidirectional,\n","                 dropout=dropout if num_layers > 1 else 0.0\n","            )\n","\n","    def forward(self, X):\n","        # X.shape [batch, seq_length]\n","        embedding_vector = self.embedding(X)  # [batch, seq_length]\n","        embedding_vector = embedding_vector.transpose(1, 0) # [seq_length, batch, emb_dim]\n","        out, hidden = self.gru(embedding_vector)\n","        # out: 모든 time step의 hidden_state, hidden: 마지막 time step의 hidden_state\n","        return out, hidden"]},{"cell_type":"code","execution_count":36,"id":"7e85d3df","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7e85d3df","executionInfo":{"status":"ok","timestamp":1765172753941,"user_tz":-540,"elapsed":34,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"0979aee6-8176-4e4f-98cd-c8412242121b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2385, 2260, 3149, 5202, 2676,    8,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0])"]},"metadata":{},"execution_count":36}],"source":["train_set[0][0]"]},{"cell_type":"code","source":["%pip install torchinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-CwFZyEvPEb","executionInfo":{"status":"ok","timestamp":1765172758906,"user_tz":-540,"elapsed":4974,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"e540e018-0a13-429d-a3c5-4c6de7aeac59"},"id":"1-CwFZyEvPEb","execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n"]}]},{"cell_type":"code","execution_count":38,"id":"c0cf51c5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0cf51c5","executionInfo":{"status":"ok","timestamp":1765172767338,"user_tz":-540,"elapsed":8432,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"62bc0c58-4dca-4a2c-c043-154fd450ddf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[3, 5, 7,  ..., 6, 5, 6],\n","        [2, 2, 1,  ..., 8, 4, 0],\n","        [7, 3, 6,  ..., 9, 6, 5],\n","        ...,\n","        [4, 0, 9,  ..., 9, 7, 8],\n","        [1, 1, 5,  ..., 5, 7, 1],\n","        [6, 8, 5,  ..., 3, 5, 6]])"]},"metadata":{},"execution_count":38}],"source":["!pip install torchinfo\n","from torchinfo import summary\n","dummy_input = torch.randint(10, size=(64, 20), dtype=torch.int64)\n","dummy_input"]},{"cell_type":"code","execution_count":39,"id":"14d6f13c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14d6f13c","executionInfo":{"status":"ok","timestamp":1765172767390,"user_tz":-540,"elapsed":25,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"20d2216d-99c7-45e3-d326-7c729a052e80"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","Encoder                                  [20, 64, 40]              --\n","├─Embedding: 1-1                         [64, 20, 100]             100,000\n","├─GRU: 1-2                               [20, 64, 40]              14,640\n","==========================================================================================\n","Total params: 114,640\n","Trainable params: 114,640\n","Non-trainable params: 0\n","Total mult-adds (Units.MEGABYTES): 25.14\n","==========================================================================================\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 1.43\n","Params size (MB): 0.46\n","Estimated Total Size (MB): 1.90\n","=========================================================================================="]},"metadata":{},"execution_count":39}],"source":["summary(Encoder(1000, 100, 20), input_data=dummy_input)"]},{"cell_type":"code","execution_count":39,"id":"99e8344f-8cf7-45a8-8092-ab20365cdb91","metadata":{"id":"99e8344f-8cf7-45a8-8092-ab20365cdb91","executionInfo":{"status":"ok","timestamp":1765172767397,"user_tz":-540,"elapsed":3,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":[]},{"cell_type":"markdown","id":"24779603-15ac-4ba1-a24c-6e86658b3ad6","metadata":{"id":"24779603-15ac-4ba1-a24c-6e86658b3ad6"},"source":["## Decoder\n","- Encoder의 출력(context vector)를 받아서 번역 결과 sequence를 출력한다.\n","- Decoder는 매 time step의 입력으로 **이전 time step에서 예상한 단어와 hidden state값이** 입력된다.\n","- Decoder의 처리결과 hidden state를 Estimator(Linear+Softmax)로 입력하여 **입력 단어에 대한 번역 단어가 출력된다.** (이 출력단어가 다음 step의 입력이 된다.)\n","    - Decoder의 첫 time step 입력은 문장의 시작을 의미하는 <SOS>(start of string) 토큰이고 hidden state는 context vector(encoder 마지막 hidden state) 이다.\n","\n","![decoder](figures/seq2seq_decoder.png)"]},{"cell_type":"code","execution_count":40,"id":"0c842666","metadata":{"id":"0c842666","executionInfo":{"status":"ok","timestamp":1765172767404,"user_tz":-540,"elapsed":4,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split"]},{"cell_type":"code","execution_count":41,"id":"10b3ef35","metadata":{"id":"10b3ef35","executionInfo":{"status":"ok","timestamp":1765172767451,"user_tz":-540,"elapsed":33,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["class Decoder(nn.Module):\n","\n","    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=1, bidirectional=False, # Decoder는 생성. 뒤에 토큰들을 알지 못하기 때문에 단방향 처리.\n","                          dropout=0.2\n","                         ):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","\n","        self.gru = nn.GRU(\n","            embedding_dim,\n","            hidden_size,\n","            num_layers=num_layers,\n","            dropout= dropout if num_layers > 1 else 0.0\n","        )\n","\n","        self.classifier = nn.Linear(\n","            hidden_size,   # 입력 - gru의 마지막 hidden state값.\n","            vocab_size     # 출력 - 다중분류: 어휘사전의 단어들 중 다음 단어 한 개를 찾는 다중분류.\n","        )\n","\n","    def forward(self, X, hidden):\n","        \"\"\"\n","        X: 한 개 토큰. shape: [batch] []\n","        hidden: 이전 처리 hidden state. 첫 번째 time step: Encoder의 context vector\n","                [seq_length: 1, batch, hidden_size]\n","        \"\"\"\n","        # [batch] -> [batch, 1] 1: seq_length\n","        X = X.unsqueeze(1)\n","        embedding_vector = self.embedding(X)   # 입력: int64, [batch, seq_length(1)]\n","        # [batch, seq_length, embedding_dim] -> [seq_length, batch, embedding_dim]\n","        embedding_vector = embedding_vector.transpose(1, 0)\n","\n","        #[seq_length(1), batch, embedding_dim -> out, hidden\n","        # out (모든 time step의 hidden state 모음): [seq_length(1), batch_size, hidden_size]\n","        # hidden (마지막 time step의 hidden state): [num_layers, batch_size, hidden_size]\n","        out, hidden = self.gru(embedding_vector, hidden)\n","\n","        # Linear (분류기) 넣어서 다음 단어를 예측\n","        last_out = self.classifier(out[-1])\n","\n","        # last_out: 다음 단어일 확률, [batch, vocab_size]\n","        # hidden: 다음 단어를 예측할 때 넣어줄 context vector (hidden state)\n","        return last_out, hidden"]},{"cell_type":"code","execution_count":42,"id":"07570b64","metadata":{"id":"07570b64","executionInfo":{"status":"ok","timestamp":1765172767474,"user_tz":-540,"elapsed":18,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["from torchinfo import summary"]},{"cell_type":"code","execution_count":43,"id":"e27e9182","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e27e9182","executionInfo":{"status":"ok","timestamp":1765172767986,"user_tz":-540,"elapsed":516,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"83ebe4f5-1c19-4cb0-8a21-c3ac4a81ce01"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","Decoder                                  [64, 10000]               --\n","├─Embedding: 1-1                         [64, 1, 200]              2,000,000\n","├─GRU: 1-2                               [1, 64, 200]              241,200\n","├─Linear: 1-3                            [64, 10000]               2,010,000\n","==========================================================================================\n","Total params: 4,251,200\n","Trainable params: 4,251,200\n","Non-trainable params: 0\n","Total mult-adds (Units.MEGABYTES): 272.08\n","==========================================================================================\n","Input size (MB): 0.05\n","Forward/backward pass size (MB): 5.32\n","Params size (MB): 17.00\n","Estimated Total Size (MB): 22.38\n","=========================================================================================="]},"metadata":{},"execution_count":43}],"source":["dummy_input = torch.ones([64], dtype=torch.int64, device=device)  # 64: batch\n","dummy_hidden = torch.ones((1, 64, 200), dtype=torch.float32, device=device)\n","# hidden shape: [1-gru layer 개수, 64: batch, 200: hidden_size]\n","# gru layer 개수: num_layers * 2 if bidirectional else 1\n","\n","dummy_decoder = Decoder(10000, 200, 200, num_layers=1).to(device)\n","summary(dummy_decoder, input_data=(dummy_input, dummy_hidden))"]},{"cell_type":"code","execution_count":44,"id":"eff7b81d","metadata":{"id":"eff7b81d","executionInfo":{"status":"ok","timestamp":1765172767989,"user_tz":-540,"elapsed":5,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["next_word, hidden = dummy_decoder(dummy_input, dummy_hidden)"]},{"cell_type":"code","execution_count":45,"id":"b1d95199","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b1d95199","executionInfo":{"status":"ok","timestamp":1765172768007,"user_tz":-540,"elapsed":8,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"ea2bef58-8122-4a5a-a1db-e6bdd37b33bd"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 10000])\n","torch.Size([1, 64, 200])\n"]}],"source":["print(next_word.shape)\n","print(hidden.shape)"]},{"cell_type":"code","execution_count":46,"id":"52cdf137-057b-4e41-95cd-c58219032b67","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52cdf137-057b-4e41-95cd-c58219032b67","executionInfo":{"status":"ok","timestamp":1765172768036,"user_tz":-540,"elapsed":18,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"581cee5f-6f1f-4c12-cf1f-0f537b4fff2e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855,\n","        855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855,\n","        855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855,\n","        855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855, 855,\n","        855, 855, 855, 855, 855, 855, 855, 855], device='cuda:0')"]},"metadata":{},"execution_count":46}],"source":["next_word.max(dim=-1).indices"]},{"cell_type":"markdown","id":"3563f5b2-f18b-42b5-9bd4-f4f8abd767ac","metadata":{"id":"3563f5b2-f18b-42b5-9bd4-f4f8abd767ac"},"source":["## Seq2Seq 모델\n","\n","- Encoder - Decoder 를 Layer로 가지며 Encoder로 질문의 feature를 추출하고 Decoder로 답변을 생성.\n","\n","### Teacher Forcing\n","- **Teacher forcing** 기법은, RNN계열 모델이 다음 단어를 예측할 때, 이전 timestep에서 예측된 단어를 입력으로 사용하는 대신 **실제 정답 단어(ground truth) 단어를** 입력으로 사용하는 방법.\n","    - 모델은 이전 시점의 출력 단어를 다음 시점의 입력으로 사용한다. 그러나 모델이 학습할 때 초반에는 정답과 많이 다른 단어가 생성되어 엉뚱한 입력이 들어가 학습이 빠르게 되지 않는 문제가 있다.\n","- **장점**\n","    - **수렴 속도 증가**: 정답 단어를 사용하기 때문에 모델이 더 빨리 학습 가능.\n","    - **안정적인 학습**: 초기 학습 단계에서 모델의 예측이 불안정할 때, 잘못된 예측으로 인한 오류가 다음 단계로 전파되는 것을 막아줍니다.\n","- **단점**\n","    - **노출 편향(Exposure Bias) 문제:** 실제 예측 시에는 정답을 제공할 수 없으므로 모델은 전 단계의 출력값을 기반으로 예측해 나가야 한다. 학습 과정과 추론과정의 이러한 차이 때문에 모델의 성능이 떨어질 수있다.\n","        - 이런 문제를 해결하기 학습 할 때 **Teacher forcing을 random하게 적용하여 학습시킨다.**\n","![seq2seq](figures/seq2seq.png)"]},{"cell_type":"code","execution_count":47,"id":"4acaa23d","metadata":{"id":"4acaa23d","executionInfo":{"status":"ok","timestamp":1765172768040,"user_tz":-540,"elapsed":2,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["import random\n","SOS_TOKEN = tokenizer.token_to_id(\"<sos>\")\n","\n","class Seq2Seq(nn.Module):\n","\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__() # Fix: Add parentheses after super\n","        self.encoder = encoder.to(device)\n","        self.decoder = decoder.to(device)\n","        self.device = device\n","\n","    def forward(self, inputs, outputs, teacher_forcing_rate=0.99):\n","        \"\"\"\n","        Args:\n","            inputs: 질문 (batch, seq_length)\n","            outputs: 답변(정답) (batch, seq_length) -> teacher forcing 때 사용.\n","            teacher_forcing_rate: teacher forcing은 random하게 적용. 적용될 확률.\n","        \"\"\"\n","        # 질문과 답변이 1차원일 경우 2차원으로 reshape\n","        # if [batch] -> [batch(1), seq_length]\n","        if inputs.dim() ==1:\n","            inputs = inputs.unsqueeze(0)\n","        if outputs.dim() == 1:\n","            outputs = outputs.unsqueeze(0)\n","\n","        batch_size, output_length = outputs.shape   # output_length: output의 max_length. 답변 문장의 토큰 수를 여기에 맞출 것.\n","        output_vocab_size = self.encoder.vocab_size\n","\n","\n","        ##############################################################\n","        # 생성된 문장을 저장할 tensor 생성 (모델이 생성한 예측 문장)\n","        # (seq_length, batch_size, vocab_size)\n","        # [나는, 학생, 이다.]\n","        # [\n","        # vocab_size의 각 단어가 \"나는\"일 확률\n","        # vocab_size의 각 단어가 \"학생\"일 확률\n","        # vocab_size의 각 단어가 \"이다\"일 확률\n","        # ]\n","        ##################################\n","\n","        predicted_outputs = torch.zeros(output_length, batch_size, output_vocab_size).to(self.device)\n","\n","        ##############################################################\n","        # 추론\n","        # 1. encoder를 이용해서 context vector 추출 (한번에 처리)\n","        # 2. decoder를 이용해서 답변 문장을 생성 (개별 토큰 별로 생성) 반복.\n","        ##############################################################\n","        # encode를 이용해 context vector 추출\n","\n","        encoder_out, _ = self.encoder(inputs)   # encoder_out: 전체 hidden state 모음\n","\n","        # context vector == encoder_out[-1] => Decoder의 첫 번째 time step의 hidden으로 입력.\n","        decoder_hidden = encoder_out[-1].unsqueeze(0)\n","        # decoder에 입력할 첫 번째 time step값: <sos> 토큰 ID\n","        decoder_input = torch.full([batch_size], fill_value=SOS_TOKEN, device=self.device)\n","\n","        ####################################\n","        # Decoder를 이용해서 한 단어 (토큰)씩 생성\n","        ####################################\n","        for t in range(output_length):\n","            decoder_out, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n","\n","            # predicted_outputs = decoder_out  # t번째 예측 단어.  <-- This line is incorrect, it should assign to predicted_outputs[t]\n","            predicted_outputs[t] = decoder_out\n","\n","            # 다음 time step의 input을 생성 (decoder_input 값을 생성)\n","            # teacher forcing 적용 -> t번째 정답 토큰\n","            #                 적용 안 함 -> Decoder가 생성한 decoder_out에서 token id값.\n","            # teacher_forcing_rate 비율로 teacher forcing을 적용\n","            teacher_forcing = teacher_forcing_rate > random.random()\n","            teacher_forcing_rate *= 0.99  # 반복하면서 teacher forcing 적용 확률을 줄여나간다.\n","\n","            top1 = decoder_out.argmax(dim=-1)     # 다음 단어일 확률이 가장 높은 단어의 토큰 ID\n","            decoder_input = outputs[:, t] if teacher_forcing else top1\n","\n","\n","        return predicted_outputs.transpose(1, 0)   # [seq_length <-> batch, vocab_size]"]},{"cell_type":"code","execution_count":48,"id":"0f4e3ca6","metadata":{"id":"0f4e3ca6","executionInfo":{"status":"ok","timestamp":1765172768060,"user_tz":-540,"elapsed":12,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["# tokenizer.encode(\"안녕하세요. 반가워요.\").ids\n","# b, o = [64, 29]\n","# b, o"]},{"cell_type":"code","execution_count":49,"id":"56953ff7","metadata":{"id":"56953ff7","executionInfo":{"status":"ok","timestamp":1765172768093,"user_tz":-540,"elapsed":31,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["# a = torch.tensor([[1, 2], [3, 4]])\n","# a.shape\n","# a[-1].unsqueeze(0).shape"]},{"cell_type":"code","execution_count":50,"id":"8c178a70","metadata":{"id":"8c178a70","executionInfo":{"status":"ok","timestamp":1765172768094,"user_tz":-540,"elapsed":21,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["# random.random()  # 0~1 사이의 실수 반환. 모든 실수는 같은 확률로 나온다."]},{"cell_type":"markdown","id":"6e89fed5-b059-4371-b836-c3eb59bebdfb","metadata":{"id":"6e89fed5-b059-4371-b836-c3eb59bebdfb"},"source":["# 학습"]},{"cell_type":"markdown","id":"6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7","metadata":{"id":"6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7"},"source":["## 모델생성"]},{"cell_type":"code","execution_count":51,"id":"1aba84d5","metadata":{"id":"1aba84d5","executionInfo":{"status":"ok","timestamp":1765172768095,"user_tz":-540,"elapsed":8,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["# hyper parameter 정의\n","vocab_size = tokenizer.get_vocab_size()\n","encoder_bidirectional = True  # encoder는 양방향\n","encoder_hidden_size = 200\n","\n","# encoder의 hidden(context vector)과 decoder hidden을 맞춰준다.\n","decoder_hidden_size = encoder_hidden_size * 2 if encoder_bidirectional else encoder_hidden_size\n","\n","embedding_dim = 256\n","teacher_forcing_rate = 0.9"]},{"cell_type":"code","execution_count":52,"id":"1bce8d66","metadata":{"id":"1bce8d66","executionInfo":{"status":"ok","timestamp":1765172768178,"user_tz":-540,"elapsed":88,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["# 모델 생성\n","encoder = Encoder(\n","    vocab_size=vocab_size,\n","    embedding_dim=embedding_dim,\n","    hidden_size=encoder_hidden_size,\n","    num_layers=1,\n","    bidirectional=encoder_bidirectional\n",")\n","decoder = Decoder(\n","    vocab_size=vocab_size,\n","    embedding_dim=embedding_dim,\n","    hidden_size=decoder_hidden_size,\n","    num_layers=1\n",")\n","seq2seq = Seq2Seq(encoder, decoder, device)"]},{"cell_type":"code","execution_count":53,"id":"cfdd289e","metadata":{"id":"cfdd289e","executionInfo":{"status":"ok","timestamp":1765172768182,"user_tz":-540,"elapsed":3,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["d_input = torch.zeros((64, 30),dtype=torch.int64, device=device)"]},{"cell_type":"markdown","id":"6ba83263-e042-4579-9784-2403eb3c3fa1","metadata":{"id":"6ba83263-e042-4579-9784-2403eb3c3fa1"},"source":["## loss함수, optimizer"]},{"cell_type":"code","execution_count":54,"id":"e8000c89","metadata":{"id":"e8000c89","executionInfo":{"status":"ok","timestamp":1765172780315,"user_tz":-540,"elapsed":12100,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["lr = 0.001\n","# model = seq2seq(device) # seq2seq는 이미 인스턴스화된 모델 객체이므로 다시 호출할 필요가 없습니다.\n","model = seq2seq # 올바른 모델 할당\n","loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.token_to_id('<pad>')) # padding_idx를 ignore_index로 설정\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)"]},{"cell_type":"markdown","id":"6a659df1-87a2-4fe0-a095-e031ed130e68","metadata":{"id":"6a659df1-87a2-4fe0-a095-e031ed130e68"},"source":["## train/evaluation 함수 정의\n","\n","### train 함수정의"]},{"cell_type":"code","execution_count":55,"id":"c8d12a24","metadata":{"id":"c8d12a24","executionInfo":{"status":"ok","timestamp":1765172780339,"user_tz":-540,"elapsed":21,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["def train(model, dataloader, optimizer, loss_fn, device, teacher_forcing_rate=0.9):\n","    model.train()\n","    train_loss=0.0\n","\n","    for X, y in dataloader:\n","        X, y = X.to(device), y.to(device)\n","        pred = model(X, y, teacher_forcing_rate)  # seq2seq\n","        # pred: [batch, seq_length, vocab_size]\n","        # pred: [batch, seq_length, vocab_size]\n","        y_hat = pred.reshape(-1, pred.shape[2])  # loss 계산을 위해서\n","        y = y.reshape(-1)   # [batch, seq_length] -> [batch * seq_length]\n","        # CrossEntropyLoss입력: 정답 - [batch,], 추론: [batch, class 개수 - vocab_size]\n","        loss = loss_fn(y_hat, y)\n","        loss.backward()   # gradient 계산.\n","        optimizer.step()  # update\n","        optimizer.zero_grad() # 오타 수정: zero_grad\n","        train_loss += loss.item()\n","\n","    return train_loss / len(dataloader)"]},{"cell_type":"markdown","id":"8981388d-ad33-4318-844b-29a5a434d2a7","metadata":{"id":"8981388d-ad33-4318-844b-29a5a434d2a7"},"source":["### Test 함수"]},{"cell_type":"code","execution_count":56,"id":"ab2c9109","metadata":{"id":"ab2c9109","executionInfo":{"status":"ok","timestamp":1765172780341,"user_tz":-540,"elapsed":22,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["@torch.no_grad()\n","def eval(model, dataloader, loss_fn, device):\n","    model.eval()\n","    eval_loss = 0.0\n","\n","    for X, y in dataloader:\n","        X, y = X.to(device), y.to(device)\n","        pred = model (X, y, teacher_forcing_rate=0.0)  # teacher_forcing 적용하면 안 됨\n","        y_hat = pred.reshape(-1, pred.shape[-1])\n","        y = y.reshape(-1)\n","        eval_loss += loss_fn(y_hat, y).item()\n","\n","    return eval_loss / len(dataloader)"]},{"cell_type":"markdown","id":"4a71e20c-8a03-44f4-bbbc-8f4e51b85636","metadata":{"id":"4a71e20c-8a03-44f4-bbbc-8f4e51b85636"},"source":["### Training"]},{"cell_type":"code","execution_count":57,"id":"7b5b463d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7b5b463d","executionInfo":{"status":"ok","timestamp":1765172943668,"user_tz":-540,"elapsed":163345,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"b86371f4-5ae0-44d8-fb99-38a78a504457"},"outputs":[{"output_type":"stream","name":"stdout","text":["1 에서 저장 -------------\n","1 6.667282036372593 6.849553871154785\n","2 5.641226425170898 7.116566514968872\n","3 4.783788855416434 6.946818447113037\n","4 4.007306680679322 8.041972732543945\n","5 3.3970713683537075 7.98205246925354\n","6 3.0833013275691443 7.571499919891357\n","7 2.690405624934605 8.72975778579712\n","8 2.3925314351490568 8.794736289978028\n","9 2.2699955872126987 8.9253436088562\n","10 2.00575379712241 9.113865947723388\n"]}],"source":["epochs = 10\n","model_save_path = \"saved_models/chatbot_seq2seq.pth\"\n","# 가장 validation loss가 좋은 모델을 저장.\n","best_loss = torch.inf\n","\n","for epoch in range(epochs):\n","    train_loss = train(model, train_loader, optimizer, loss_fn, device, teacher_forcing_rate)\n","    eval_loss = eval(model, test_loader, loss_fn, device)\n","\n","    if best_loss > eval_loss:  # 성능 개선\n","        torch.save(model, model_save_path)\n","        print(epoch+1, \"에서 저장 -------------\")\n","        best_loss = eval_loss\n","\n","    print(epoch+1, train_loss, eval_loss)"]},{"cell_type":"code","source":["torch.save(model, 'saved_models/chatbot_seq2seq_last_train.pth')"],"metadata":{"id":"HjZEg7gdzMvL","executionInfo":{"status":"ok","timestamp":1765172943682,"user_tz":-540,"elapsed":6,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"id":"HjZEg7gdzMvL","execution_count":58,"outputs":[]},{"cell_type":"code","execution_count":59,"id":"4627557f","metadata":{"id":"4627557f","executionInfo":{"status":"ok","timestamp":1765172943700,"user_tz":-540,"elapsed":4,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["## 저장 모델 Load\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# map_location=device : 다른 device에 학습/저장한 모델을 읽어올 때 현재 device를 지정해서  현재 device에 맞춰 load하도록한다.\n","best_model = torch.load(model_save_path, weights_only=False, map_location=device)\n","best_model.device = device"]},{"cell_type":"markdown","id":"6fe0585a-eb35-47dd-88bf-276d749f5f00","metadata":{"id":"6fe0585a-eb35-47dd-88bf-276d749f5f00"},"source":["# 결과확인"]},{"cell_type":"markdown","id":"287b94a1-bc0a-474a-8415-57dc5ea4b894","metadata":{"id":"287b94a1-bc0a-474a-8415-57dc5ea4b894"},"source":["- Sampler:\n","    -  DataLoader가 Datatset의 값들을 읽어서 batch를 만들때 index 순서를 정해주는 객체.\n","    -  DataLoader의 기본 sampler는 SequentialSampler 이다. shuffle=True 일경우 RandomSampler: 랜덤한 순서로 제공."]},{"cell_type":"code","execution_count":60,"id":"e32e3181","metadata":{"id":"e32e3181","executionInfo":{"status":"ok","timestamp":1765172943707,"user_tz":-540,"elapsed":4,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["# ds = Dataset(...)\n","\n","# d_loader = DataLoader(ds, 200, shuffle=True)\n","# index = [0~999]\n","# 1. new_idx = shuffle(index) [920, 1, 87, 234, ...] 0~199, 200~399"]},{"cell_type":"code","execution_count":61,"id":"eff6bedd","metadata":{"id":"eff6bedd","executionInfo":{"status":"ok","timestamp":1765172943714,"user_tz":-540,"elapsed":4,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["def handle_special_tokens(decoded_string):\n","    \"\"\"\n","    Subword 처리\n","    subword는 단어의 시작으로 쓰인 것과 중간 부분(연결)에 사용된 두가지 subword가 있다.  연결 subword는 `#`과 같은 특수문자로 시작 한다.\n","    tokenizer.decode() 결과 문자열은 subword의 특수문자('##')을 처리하지 않는다. 이것을 처리하는 함수\n","    ex) \"이 기회 ##는 내 ##꺼 ##야\" ==> \"이 기회는 내꺼야\"\n","\n","    Parameter\n","        decoded_string: str - Tokenizer가 decode한 중간 subword의 특수문자 처리가 안된 문자열.\n","    Return\n","        str: subword 특수문자 처리한 문자열\n","    \"\"\"\n","\n","    tokens = decoded_string.split() # 공백기준으로 토큰화.\n","    new_tokens = []\n","    for token in tokens:\n","        if token.startswith(\"##\"): # 연결 토큰\n","            if new_tokens: # len(new_tokens) != 0 원소가 하나라도 있으면\n","                # 토큰에서 ##을 제거하고 리스트의 마지막 원소(문자열) 뒤에 붙인다.\n","                new_tokens[-1] += token[2:]\n","            else: # new_tokens가 빈 리스트. 현재 token이 첫번째 단어. ##을 지우고 append\n","                new_tokens.append(token[2:])\n","        else: # 단어의 시작인 토큰. (##이 없는 토큰) -> list에 추가.\n","            new_tokens.append(' '+token)\n","\n","    return \"\".join(new_tokens)\n"]},{"cell_type":"code","execution_count":62,"id":"a0822c18","metadata":{"id":"a0822c18","executionInfo":{"status":"ok","timestamp":1765172943737,"user_tz":-540,"elapsed":24,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["from torch.utils.data import SubsetRandomSampler\n","# sampler는 “Dataset에서 어떤 순서로 index를 뽑을지 결정하는 객체”이다. DataLoader는 sampler가 제공하는 index를 이용해 Dataset에서 데이터를 추출한다.\n","## shuffle=True 이면 RandomSampler가 사용된다. False이면 SequentialSampler가 사용된다.\n","\n","\n","#  dataset에서 일부 데이터들을 가지고 확인\n","def random_evaluation(model, dataset, device, n=10):\n","    \"\"\"\n","    Dataset에서 일부 질문-답변 쌍들을 가져다 모델에 질문을 넣어 추론한 결과와 함께 확인.\n","    Parameter\n","        model: 학습된 seq2seq 모델\n","        dataset: 질문-답변 쌍울 추출할 dataset\n","        device\n","        n: int - 추출할 질문-답변 쌍 개수 default: 10\n","    \"\"\"\n","    ## 평가할 데이터셋을 만들기\n","    n_samples = len(dataset)       # Dataset의 총 데이터개수\n","    # index = list(range(n_samples)) # Dataset의 index만들기.  [0, 1, 2, ...., dataset_length]\n","    # np.random.shuffle(index)       # 값들을 랜덤하게 섞어준다. [100, 23, 590, 10, ...]\n","    # sample_index = index[ : n]     # 평가할 데이터 개수만큼 index 생성.\n","\n","\n","    sample_index = torch.randint(0, n_samples, size=[n])\n","\n","    # Dataloader 생성\n","    # SubsetRandomSampler: 지정한 index들 안에서 random한 순서로 제공.\n","    # sample_index=[1, 20, 4, 5, 100], dataset에서 [1, 20, 4, 5, 100] index의 값만 추출\n","    sampler = SubsetRandomSampler(sample_index)\n","    sample_loader = DataLoader(dataset, batch_size=n, sampler=sampler)\n","\n","    ## 추론 후 확인\n","    model.to(device)\n","    model.eval()\n","    with torch.no_grad():\n","        for X, y in sample_loader:\n","            X, y = X.to(device), y.to(device)\n","            output = model(X, y, 0.0) # [batch, seq_len, vocab_size]\n","\n","            # torch.Tensor -> ndarray (tokenizer decode에 넣기 위해.)\n","            ## tensor를 cpu로 이동후 변환가능.\n","            ### tensor가 grad를 가지고 있으면(계산그래프에 포함돼 있으면)\n","            ####                               -> tensor.detach().cpu().ndarray()\n","\n","            pred = output.cpu().numpy()  # X.to(\"cpu\") # 모델추정 답변\n","            X = X.cpu().numpy()   # 정답-질문\n","            y = y.cpu().numpy()   # 정답-답변 (batch, seq_len, vocab)\n","\n","            for i in range(n):\n","                q = handle_special_tokens(tokenizer.decode(X[i]))\n","                a = handle_special_tokens(tokenizer.decode(y[i]))\n","                p = handle_special_tokens(tokenizer.decode(pred[i].argmax(-1)))\n","                print(f\"질문: {q}\")\n","                print(f\"정답: {a}\")\n","                print(f\"예측: {p}\")\n","                print('==================================================')"]},{"cell_type":"code","execution_count":63,"id":"476eae22-4c6a-4f55-8dd2-87f8dd1ba46d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"476eae22-4c6a-4f55-8dd2-87f8dd1ba46d","executionInfo":{"status":"ok","timestamp":1765172943744,"user_tz":-540,"elapsed":24,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"ce85243d-6a65-465c-c996-b264cc6a7b40"},"outputs":[{"output_type":"stream","name":"stdout","text":["질문:  나랑 썸 타던 여자애가 내 친구랑 사귄대\n","정답:  뒷통수 맞았네요 .\n","예측:  못 당해요 . 무시하세요 . . . . . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  네일 할까\n","정답:  기분전환을 해보세요 .\n","예측:  잘 살 수 있을 거예요 . 조금만 더 힘내세요 . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  이별한지 두달이 넘고 얼굴 안본지 한달이 넘은\n","정답:  기억의 저편으로 남겨두세요 .\n","예측:  좋은 꾹꾹 ! 힘내세요 . ! 그게 제일 편한거 같아요 . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  택배 왔나\n","정답:  현관문 살펴보세요 .\n","예측:  그 사람을 무의식 중에 생각했나봅니다 . . . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  매일매일 사랑해\n","정답:  표현하는 게 좋죠 .\n","예측:  그 사람을 무의식 중에 생각했나봅니다 . . . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  매주 월요일 그를 볼 수 있어 .\n","정답:  일주일이 즐겁겠어요 .\n","예측:  연예인 걱정이 준비하니 일반인보다 다 예쁘겠죠 . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  취업 준비 기간이 길어진다\n","정답:  다음 공채때는 될 거예요 .\n","예측:  잘 살 수 있어요 . 그렇지만 조금 더 상황을 지켜보세요 . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  신청했더니 정말로 왔네ㅎㅎ\n","정답:  좋은 결과길 바라요 .\n","예측:  좋은 꾹꾹 ! 힘내세요 . ! 그게 제일 편한거 같아요 . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  더워서 잠을 못자\n","정답:  잠이 최고의 보약이에요 . 노력해보세요 .\n","예측:  잘 볼 수 있을 거예요 . . . . . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  음 . 반복이냐\n","정답:  인생은 반복의 연속이지요 .\n","예측:  잘 볼 수 있을 거예요 . . . . . . . . . . . . . . . . . . . . . . . .\n","==================================================\n"]}],"source":["random_evaluation(model, train_set, device)"]},{"cell_type":"code","source":["random_evaluation(model, test_set, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J2ccXdf_0EcV","executionInfo":{"status":"ok","timestamp":1765172943858,"user_tz":-540,"elapsed":113,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"4ebee011-7a63-4cf9-af87-15f6e941a33f"},"id":"J2ccXdf_0EcV","execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["질문:  옷장이 점점 줄어들어\n","정답:  지난 계절 옷을 잘 정리해 보세요 .\n","예측:  이제 앞모습을 보세요 . . . . . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  조모임 왜 이케 많아\n","정답:  요즘은 팀워크가 더 중요해졌어요 .\n","예측:  원하는 것을 당당하게 말하세요 . . . . . . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  친척들 만나는 거 싫어\n","정답:  만나지 마세요 .\n","예측:  충분한 대화를 나눠보세요 . . . . . . . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  또 야근\n","정답:  얼른 집에 가서 쉬시길 바랄게요 .\n","예측:  많이 지쳤나봐요 . . . . . . . . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  남자친구가 진짜 잘 챙겨줘\n","정답:  당신도 잘 챙겨주세요 .\n","예측:  잘 살 수 있을 거예요 . 조금만 더 힘내세요 . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  나만 좋아하는 것 같아 자존감 떨어져 .\n","정답:  더 좋아하게 만들면 돼요 .\n","예측:  나쁜 사람이네요 . 헤어지세요 . . . . . . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  비 오는 날\n","정답:  우산 들고 나가세요 .\n","예측:  마음의 정리가 아직인가 봅니다 . . . . . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  새신발 신었는데 비와\n","정답:  얼른 실내로 들어가세요 .\n","예측:  잘 살 수 있을 거예요 . 조금만 더 힘내세요 . . . . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  적금 더 들까\n","정답:  절약하면 할 수 있어요 .\n","예측:  좋은 꾹꾹 ! 힘내세요 . ! 그게 제일 편한거 같아요 . . . . . . . . . . . . . . . . .\n","==================================================\n","질문:  그리워서 죽고 싶다는 생각이 드네 .\n","정답:  무서운 생각하지마세요 .\n","예측:  짝사랑 앞에 장사 없지요 . . . . . . . . . . . . . . . . . . . . . . .\n","==================================================\n"]}]},{"cell_type":"code","source":["-torch.log(torch.tensor(0.06))\n","# 결과: tensor(2.8134)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNOx5apO0koM","executionInfo":{"status":"ok","timestamp":1765172943864,"user_tz":-540,"elapsed":32,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"3cae003e-21c8-4ebf-cd87-32dc3407a60c"},"id":"HNOx5apO0koM","execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.8134)"]},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","id":"3c4965d1-a305-4465-8f64-f689d55490ac","metadata":{"id":"3c4965d1-a305-4465-8f64-f689d55490ac"},"source":["# 학습모델을 이용한 대화"]},{"cell_type":"code","execution_count":66,"id":"8f5dea07","metadata":{"id":"8f5dea07","executionInfo":{"status":"ok","timestamp":1765172943868,"user_tz":-540,"elapsed":3,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["class ChatbotInputDataset(Dataset):\n","    \"\"\"\n","    질문만 받아서 생성하는 Dataset\n","    - 새로운 데이터 추론용.\n","    \"\"\"\n","\n","    def __init__(self, question_texts, max_length, tokenizer):\n","        \"\"\"\n","        parameter\n","            question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n","            max_length: 개별 문장의 token 개수. 모든 문장의 토큰수를 max_length에 맞춘다.\n","            tokenizer: Tokenizer\n","        \"\"\"\n","        self.max_length = max_length\n","        self.tokenizer = tokenizer\n","        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n","\n","    def __pad_token_sequence(self, token_sequence):\n","        \"\"\"\n","        max_length 길이에 맞춰 token_id 리스트를 구성한다.\n","        max_length 보다 길면 뒤에를 자르고 max_length 보다 짧으면 [PAD] 토큰을 추가한다.\n","\n","        Parameter\n","            token_sentence: list[int] - 길이를 맞출 한 문장 token_id 목록\n","        Return\n","            list[int] - length가 max_length인 token_id 목록\n","        \"\"\"\n","        pad_token = self.tokenizer.token_to_id('<pad>')\n","        seq_len = len(token_sequence) # 입력 문장의 토큰수\n","        if seq_len > self.max_length: # 문장 최대 토큰수 보다 길다면.\n","            return token_sequence[:self.max_length]\n","        else:\n","            return token_sequence + ([pad_token] * (self.max_length - seq_len))\n","\n","    def __process_sequence(self, text):\n","        \"\"\"\n","        한 문장(str)을 받아서 padding이 추가된 token_id 리스트로 변환 후 반환\n","        Parameter\n","            text: str - token_id 리스트로 변환할 한 문장\n","        Return\n","            list[int] - 입력받은 문장에 대한 token_id 리스트\n","        \"\"\"\n","        # encoding\n","        encode = self.tokenizer.encode(text) # \"........\" => [. , . , .]\n","        # max_length 크기에 맞춘다.\n","        token_ids = self.__pad_token_sequence(encode.ids) #[3400, 20, 6, 0, 0, 0 ..]\n","        return token_ids\n","\n","    def __len__(self):\n","        return len(self.question_texts)\n","\n","\n","    def __getitem__(self, index):\n","        # 질문만 반환.\n","        q = self.question_texts[index]  # List\n","\n","        # List->LongTensor. nn.Embedding()의 입력(정수타입)으로 들어간다.\n","        return torch.tensor(q, dtype=torch.int64)\n",""]},{"cell_type":"code","execution_count":67,"id":"5313038f","metadata":{"id":"5313038f","executionInfo":{"status":"ok","timestamp":1765172943891,"user_tz":-540,"elapsed":3,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["# 질문:  창업하고 싶다 .\n","# 정답:  확신이 들 때까지 준비해보세요 .\n","\n","input_data = [\n","    \"난 가족들과 주말에 여행갈 거야.\",\n","    \"와! 내일 주말이다.\",\n","    \"너무 피곤하네요.\",\n","    \"지금 몇시에요?\",\n","    \"여자 친구와 데이트 약속했어.\",\n","    \"창업하고 싶다\",\n","    \"창업하고 싶다 .\"\n","]\n","input_dataset = ChatbotInputDataset(input_data, max_length, tokenizer)"]},{"cell_type":"code","execution_count":68,"id":"03b72a02","metadata":{"id":"03b72a02","executionInfo":{"status":"ok","timestamp":1765172943899,"user_tz":-540,"elapsed":3,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["def predict(dataset, model, device):\n","    model.eval()\n","    model.to(device)\n","    with torch.no_grad():\n","        for X in dataset:  # Dataset에서 한 질문씩을 조회\n","            X = X.to(device)\n","            output = model(X.unsqueeze(0), X.unsqueeze(0), 0.0)\n","            pred = output.cpu().numpy()\n","            X = X.cpu().numpy()\n","            q = handle_special_tokens(tokenizer.decode(X))\n","            a = handle_special_tokens(tokenizer.decode(pred[0].argmax(-1)))\n","            print(f\"질문: {q}\")\n","            print(f\"예상답: {a}\")\n","            print(\"=========================================================\")"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hX96TH5u8WQz","executionInfo":{"status":"ok","timestamp":1765180375954,"user_tz":-540,"elapsed":25410,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"a5446465-67ac-4b4f-88b5-232fee808122"},"id":"hX96TH5u8WQz","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["predict(input_dataset, model, device)"],"metadata":{"id":"nIEvhbJs_9-j","executionInfo":{"status":"aborted","timestamp":1765173065287,"user_tz":-540,"elapsed":320954,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"id":"nIEvhbJs_9-j","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 저장된 모델, 데이터 디렉토리를 구글드라이브로 복사\n","## 구글드라이브 연결\n","## 저장할 구글 드라이브 디렉토리의 경로 복사\n","## !cp 원본 타겟\n","## 디렉토리 채 복사: !cp -r 원본 타겟\n","\n","# 학습 데이터셋: 구글 드라이브에 저장 후 학습할 때 코랩으로 복사\n","# 모델 저장: 학습 도중 저장할 경우 코랩에 저장하고 코랩에 저장하고 끝나면 구글 드라이브로 복사"],"metadata":{"id":"zSMwvYUl9FJd","executionInfo":{"status":"aborted","timestamp":1765173065292,"user_tz":-540,"elapsed":1,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"id":"zSMwvYUl9FJd","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -r data \"/content/drive/MyDrive/Colab Notebooks\""],"metadata":{"id":"jxpvuN329Y9g","executionInfo":{"status":"ok","timestamp":1765180465637,"user_tz":-540,"elapsed":117,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"id":"jxpvuN329Y9g","execution_count":6,"outputs":[]},{"cell_type":"code","source":["!cp - r saved_models \"/content/sample_data\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59gySF8N9jov","executionInfo":{"status":"ok","timestamp":1765176691810,"user_tz":-540,"elapsed":124,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}},"outputId":"85e0cb6d-37f4-4705-d6ca-cbf44b8ea8c0"},"id":"59gySF8N9jov","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat '-': No such file or directory\n","cp: cannot stat 'r': No such file or directory\n","cp: cannot stat 'saved_models': No such file or directory\n"]}]},{"cell_type":"code","execution_count":null,"id":"55c89f81","metadata":{"id":"55c89f81","executionInfo":{"status":"aborted","timestamp":1765173065304,"user_tz":-540,"elapsed":4,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"outputs":[],"source":["## 코랩에서 학습한 모델 load\n","# Encoder, Decoder, Seq2seq 클래스 정의는 실행해서 메모리에 올린다.\n","import torch\n","\n","load_model = torch.load(\n","    \"saved_models/chatbot_seq2seq.pth\",\n","    weights_only=False,\n","    map_location=device\n",")\n","load_model.device = device"]},{"cell_type":"code","source":["# ChatbotInputDataset 실행. handle_special_tokens(), predict() 함수 정의 실행.\n","predict(input_dataset, load_model, device)"],"metadata":{"id":"JdAmhMemAvav","executionInfo":{"status":"aborted","timestamp":1765173065306,"user_tz":-540,"elapsed":4,"user":{"displayName":"jiyoung","userId":"11441891921512308577"}}},"id":"JdAmhMemAvav","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}