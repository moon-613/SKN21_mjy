{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15df675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/5(금) 9:20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8389555c-17d0-41ed-abfc-42046bf8aeaa",
   "metadata": {},
   "source": [
    "# Encoder–Decoder 구조\n",
    "\n",
    "- Encoder–Decoder 구조는 어떤 형태의 입력 시퀀스를 받아 **의미를 해석**한 뒤, 새로운 **출력 시퀀스를 생성**해야 하는 거의 모든 AI 문제를 해결하는 딥러닝 모델 구조다.\n",
    "- 이 구조는 Encoder와 Decoder 두개의 딥러닝 모델을 연결한 구조로 **입력 데이터를 하나의 표현으로 압축한 뒤, 이를 다시 출력 데이터로 변환하는 방식**으로 동작한다.\n",
    "\n",
    "- **Encoder Network**\n",
    "  - 입력 데이터를 해석(이해)하는 역할을 수행.\n",
    "  - 입력 시퀀스에 담긴 의미적 정보를 하나의 고정된 벡터 형태로 요약.\n",
    "\n",
    "- **Decoder Network**\n",
    "  - Encoder가 생성한 요약 정보를 바탕으로 최종 출력을 생성.\n",
    "  - 즉, Encoder의 “이해 결과”를 이용해 새로운 시퀀스를 만들어낸다.\n",
    "\n",
    "## Seq2Seq (Sequence-to-Sequence)\n",
    "\n",
    "Seq2Seq 모델: **Encoder–Decoder 구조를 RNN(Recurrent Neural Network) 계열에 적용한 대표적인 시퀀스 변환 모델**.  \n",
    "입력과 출력이 모두 “시퀀스(sequence)” 형태라는 점에서 *Sequence-to-Sequence*라는 이름이 붙었다.\n",
    "\n",
    "### Encoder의 역할: 입력 시퀀스 이해 및 Context Vector 생성\n",
    "\n",
    "Encoder는 입력으로 들어온 **전체 시퀀스**(sequence)를 순차적으로 처리한 뒤,  그 의미를 **하나의 고정 길이 벡터**(Vector)로 압축하여 출력한다.  \n",
    "이 벡터를 **Context Vector**(컨텍스트 벡터)라고 한다.\n",
    "- **Context Vector란?**  \n",
    "  - 입력 시퀀스 전체의 의미, 문맥, 핵심 정보를 요약해 담고 있는 벡터 표현이다.\n",
    "  - **기계 번역**(Machine Translation)의 경우  \n",
    "    - 번역할 원문 문장에서 **번역 결과를 생성하는 데 필요한 핵심 의미 정보**(feature)\n",
    "  - **챗봇**(Chatbot)의 경우  \n",
    "    - 사용자가 입력한 질문에서 **적절한 답변을 생성하는 데 필요한 의미 정보**(feature)\n",
    "\n",
    "### Decoder의 역할: Context Vector를 바탕으로 출력 시퀀스 생성\n",
    "\n",
    "Decoder는 Encoder가 출력한 **Context Vector를 입력으로 받아**, 이를 바탕으로 **목표 출력 시퀀스**를 한 토큰(token)씩 순차적으로 생성.\n",
    "\n",
    "- **기계 번역**(Machine Translation)의 경우  \n",
    "  - 입력 문장의 의미를 반영한 **번역 문장** 생성.\n",
    "- **챗봇**(Chatbot)  \n",
    "  - 질문에 대한 **자연스러운 답변 문장** 생성.\n",
    "\n",
    "Decoder는 매 시점(time step)마다\n",
    "  - 이전에 생성한 단어\n",
    "  - 그리고 Context Vector에 담긴 입력 문맥\n",
    "을 함께 고려해 다음 단어를 예측.\n",
    "\n",
    "\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887d108-2ac6-425e-9643-d351e44282c7",
   "metadata": {},
   "source": [
    "# Seq2Seq 를 이용한 Chatbot 모델 구현\n",
    "- Encoder를 이용해 질문의 특성을 추출하고 Decoder를 이용해 답변을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec7aee-1d3b-4990-b934-a4254a6e17ef",
   "metadata": {},
   "source": [
    "# Chatbot Dataset\n",
    "\n",
    "- https://github.com/songys/Chatbot_data\n",
    "- columns\n",
    "    - Q: 질문\n",
    "    - A: 답\n",
    "    - label: 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2\n",
    "- **Download**\n",
    "\n",
    "![dataset](figures/chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa75cf8-9cd9-4a72-a610-4392b80ca6b5",
   "metadata": {},
   "source": [
    "# Chatbot Dataset Loading 및 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c",
   "metadata": {},
   "source": [
    "## 데이터셋 다운로드 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\"\n",
    "res = requests.get(url)\n",
    "if res.status_code == 200:\n",
    "    with open(\"data/chatbot_data.csv\", \"wt\", encoding=\"utf-8\") as fw:\n",
    "        fw.write(res.text)\n",
    "else:\n",
    "    print(\"다운 실패:\", res.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395565ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/chatbot_data.csv\", encoding=\"utf-8\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56432716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf714bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68f4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Q",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8d8aa365-5d8c-4d66-8fb5-43edaffe93fe",
       "rows": [
        [
         "0",
         "12시 땡!",
         "하루가 또 가네요."
        ],
        [
         "1",
         "1지망 학교 떨어졌어",
         "위로해 드립니다."
        ],
        [
         "2",
         "3박4일 놀러가고 싶다",
         "여행은 언제나 좋죠."
        ],
        [
         "3",
         "3박4일 정도 놀러가고 싶다",
         "여행은 언제나 좋죠."
        ],
        [
         "4",
         "PPL 심하네",
         "눈살이 찌푸려지죠."
        ],
        [
         "5",
         "SD카드 망가졌어",
         "다시 새로 사는 게 마음 편해요."
        ],
        [
         "6",
         "SD카드 안돼",
         "다시 새로 사는 게 마음 편해요."
        ],
        [
         "7",
         "SNS 맞팔 왜 안하지ㅠㅠ",
         "잘 모르고 있을 수도 있어요."
        ],
        [
         "8",
         "SNS 시간낭비인 거 아는데 매일 하는 중",
         "시간을 정하고 해보세요."
        ],
        [
         "9",
         "SNS 시간낭비인데 자꾸 보게됨",
         "시간을 정하고 해보세요."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                   A\n",
       "0                   12시 땡!          하루가 또 가네요.\n",
       "1              1지망 학교 떨어졌어           위로해 드립니다.\n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.\n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.\n",
       "4                  PPL 심하네          눈살이 찌푸려지죠.\n",
       "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.\n",
       "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.\n",
       "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.\n",
       "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.\n",
       "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6273de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Q",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a0952fa8-69bb-4e79-b39c-1267b600c063",
       "rows": [
        [
         "11813",
         "회사에 좋아하는 남자가 생겼어 어떡하지?",
         "사랑하기 힘든 관계인가봐요."
        ],
        [
         "11814",
         "회사에서 어떤 사람이랑 자꾸 눈 마추쳐.",
         "눈 마주치는 게 우연인지 잘 살펴 보세요."
        ],
        [
         "11815",
         "회식 중이라고 하는데 연락이 안돼.",
         "정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요."
        ],
        [
         "11816",
         "회식하는데 나만 챙겨줘. 썸임?",
         "호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요."
        ],
        [
         "11817",
         "후회 없이 사랑하고 싶어",
         "진심으로 다가가 보세요."
        ],
        [
         "11818",
         "훔쳐보는 것도 눈치 보임.",
         "티가 나니까 눈치가 보이는 거죠!"
        ],
        [
         "11819",
         "훔쳐보는 것도 눈치 보임.",
         "훔쳐보는 거 티나나봐요."
        ],
        [
         "11820",
         "흑기사 해주는 짝남.",
         "설렜겠어요."
        ],
        [
         "11821",
         "힘든 연애 좋은 연애라는게 무슨 차이일까?",
         "잘 헤어질 수 있는 사이 여부인 거 같아요."
        ],
        [
         "11822",
         "힘들어서 결혼할까봐",
         "도피성 결혼은 하지 않길 바라요."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11813</th>\n",
       "      <td>회사에 좋아하는 남자가 생겼어 어떡하지?</td>\n",
       "      <td>사랑하기 힘든 관계인가봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11814</th>\n",
       "      <td>회사에서 어떤 사람이랑 자꾸 눈 마추쳐.</td>\n",
       "      <td>눈 마주치는 게 우연인지 잘 살펴 보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11815</th>\n",
       "      <td>회식 중이라고 하는데 연락이 안돼.</td>\n",
       "      <td>정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>회식하는데 나만 챙겨줘. 썸임?</td>\n",
       "      <td>호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>후회 없이 사랑하고 싶어</td>\n",
       "      <td>진심으로 다가가 보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                                            A\n",
       "11813   회사에 좋아하는 남자가 생겼어 어떡하지?                              사랑하기 힘든 관계인가봐요.\n",
       "11814   회사에서 어떤 사람이랑 자꾸 눈 마추쳐.                      눈 마주치는 게 우연인지 잘 살펴 보세요.\n",
       "11815      회식 중이라고 하는데 연락이 안돼.  정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.\n",
       "11816        회식하는데 나만 챙겨줘. 썸임?          호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.\n",
       "11817            후회 없이 사랑하고 싶어                                진심으로 다가가 보세요.\n",
       "11818           훔쳐보는 것도 눈치 보임.                           티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.                                훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                                       설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?                     잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐                           도피성 결혼은 하지 않길 바라요."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b95d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "6d163fad-6c1c-4e12-bcea-79f4e04b026c",
       "rows": [
        [
         "Q",
         "0"
        ],
        [
         "A",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "Q    0\n",
       "A    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aad072-2245-41e8-9863-a0b451262fdd",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "### Subword방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67feeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화를 위해서 문장을 q + a 형식으로 만든다. \n",
    "# 어휘사전을 만들 때 Q와 A에 있는 모든 단어들이 다 들어가게 하기 위해.\n",
    "question_texts = df['Q']\n",
    "answer_texts = df['A']\n",
    "\n",
    "all_texts = list(question_texts+\" \"+answer_texts)  # series + 문자열 + series (원소 단위 연산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1990cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡! 하루가 또 가네요.',\n",
       " '1지망 학교 떨어졌어 위로해 드립니다.',\n",
       " '3박4일 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " '3박4일 정도 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " 'PPL 심하네 눈살이 찌푸려지죠.',\n",
       " 'SD카드 망가졌어 다시 새로 사는 게 마음 편해요.',\n",
       " 'SD카드 안돼 다시 새로 사는 게 마음 편해요.',\n",
       " 'SNS 맞팔 왜 안하지ㅠㅠ 잘 모르고 있을 수도 있어요.',\n",
       " 'SNS 시간낭비인 거 아는데 매일 하는 중 시간을 정하고 해보세요.',\n",
       " 'SNS 시간낭비인데 자꾸 보게됨 시간을 정하고 해보세요.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96bf6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    BPE(unk_token=\"<unk>\")\n",
    ")\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=10_000,    # 최대 어휘 수\n",
    "    min_frequency=5,      # 어휘사전에 등록할 단어의 최소 빈도 수 (5회 이상은 나와야 등록)\n",
    "    continuing_subword_prefix='##',    # 연결 subword 앞에 붙일 접두어를 ##로 지정. cowork: co + ##work\n",
    "    special_tokens=[\"<pad>\", \"<unk>\", \"<sos>\"]   # <sos>는 문장의 시작을 의미하는 특수 토큰\n",
    ")\n",
    "tokenizer.train_from_iterator(all_texts, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ae898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 어휘 수: 7040\n"
     ]
    }
   ],
   "source": [
    "print(\"총 어휘 수:\", tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = tokenizer.encode(\"오늘 날씨가 너무 좋습니다. 이런 날씨에 뭘 하면 좋을까요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dfbd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오늘', '날씨가', '너무', '좋습니다', '.', '이런', '날씨', '##에', '뭘', '하면', '좋을까요', '?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78448374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2290, 3852, 2258, 5913, 8, 2752, 2841, 1256, 527, 2530, 5533, 20]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85dffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2530"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_token(1500)  # id로 토큰 문자열 조회\n",
    "tokenizer.token_to_id(\"하면\") # 토큰 문자열로 id (정수)를 조회"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80caf0b3-01d5-4631-87c1-f48ab2f5bafc",
   "metadata": {},
   "source": [
    "### Tokenizer 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8eea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"saved_models/chatbot_bpe.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_tokenizer = Tokenizer.from_file(\"saved_models/chatbot_bpe.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b068c-ead0-4f75-bd01-4a0ebf486774",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader 정의\n",
    "\n",
    "\n",
    "### Dataset 정의 및 생성\n",
    "- 모든 문장의 토큰 수는 동일하게 맞춰준다.\n",
    "    - DataLoader는 batch 를 구성할 때 batch에 포함되는 데이터들의 shape이 같아야 한다. 그래야 하나로 묶을 수 있다.\n",
    "    - 문장의 최대 길이를 정해주고 **최대 길이보다 짧은 문장은 `<PAD>` 토큰을 추가**하고 **최대길이보다 긴 문장은 최대 길이에 맞춰 짤라준다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92338cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"mps\"  # 맥 M1 이상 쓰는 사람들 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6418051",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "\n",
    "    def __init__(self, question_texts, answer_texts, max_length, tokenizer):\n",
    "        # __init__ 함수는 ChatbotDataset 객체를 만들 때 가장 먼저 실행. 필요한 모든 준비물 생성. \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            question_texts (list[str]): 질문 text 리스트. [\"질문1\", \"질문2\", ..]\n",
    "            answer_texts (list[str]): 답변 text 리스트. [\"답변1\", \"답변2\", ...]\n",
    "            max_length (int): 개별 문장의 최대 토큰 수\n",
    "            tokenizer (Tokenzier): 위에서 훈련시킨 토크나이저 도구 (텍스트 -> 숫자 ID 변환)\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        # \"질문\" -> Tensor(토큰 id)\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "        self.answer_texts = [self.__process_sequence(a) for a in answer_texts]\n",
    "\n",
    "    def __pad_token_sequence(self, token_sequence):\n",
    "        \"\"\"\n",
    "        token_sequence를 self.max_length 길이에 맞추는 메소드.\n",
    "        max_length보다 적으면 <pad>를 추가, 크면 잘라낸다.\n",
    "        Args:\n",
    "            token_sequence (list[int]): 한 문장의 토큰 id 리스트. [2334, 7100, 257, ..]\n",
    "        Returns:\n",
    "            list[int]: 길이를 max_length에 맞춘 토큰 id 리스트\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('<pad>')\n",
    "        seq_length = len(token_sequence)\n",
    "        if seq_length > self.max_length: #잘라내기\n",
    "            result = token_sequence[:self.max_length]\n",
    "        else: # <pad> 추가 (padding 처리)\n",
    "            result = token_sequence + [pad_token] * (self.max_length - seq_length)\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    def __process_sequence(self, text):\n",
    "        # 텍스트를 숫자로 변환하고 길이 맞추기 \n",
    "        # 하나의 텍스트(str)를 받아서 모델이 이해할 수 있는 숫자 형태의 텐서로 변환하는 메인 처리 과정.\n",
    "        \"\"\"\n",
    "        한 문장(text-str)을 받아서 token화 한 뒤 max_length에 개수를 맞춰서 반환.\n",
    "        max_length에 맞추는 작업은 __pad_token_sequence() 를 이용\n",
    "        Args:\n",
    "            text (str): 토큰화할 문장\n",
    "        Returns:\n",
    "            torch.Tensor[int64]: 토큰화한 토큰 id 리스트\n",
    "        \"\"\"\n",
    "        encode = self.tokenizer.encode(text)\n",
    "        token_ids = encode.ids # \"나는 학생이다.\" -> [4020, 1003, 3932]\n",
    "        # [4020, 1003, 3932] -> [4020, 1003, 3932, 0, 0, 0 ] 패딩 처리.\n",
    "        return torch.tensor(self.__pad_token_sequence(token_ids), dtype=torch.int64)\n",
    "        #torch.tensor(...): 파이토치 모델이 학습할 수 있는 자료형인 텐서(torch.Tensor)로 최종 변환하여 반환\n",
    "\n",
    "    def __len__(self):    # 총 몇 쌍의 질문-답변 데이터가 있는지 반환. \n",
    "        return len(self.question_texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        index의 (question, answer) 쌍을 반환.\n",
    "        Args:\n",
    "            index (int) : 몇번 질문-답변 쌍인지 index\n",
    "        Return:\n",
    "            tuple[Tensor(int64), Tensor(int64)]\n",
    "        \"\"\"\n",
    "        q = self.question_texts[index]\n",
    "        a = self.answer_texts[index]\n",
    "        return q, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801ef2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_length. 가장 긴 문장의 토큰 수 \n",
    "max([len(tokenizer.encode(sent).ids) for sent in question_texts]) # 결과: (제일 긴 토큰 수) 21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0fe94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.encode(sent).ids) for sent in answer_texts]) # 결과: 29. 제일 긴 토큰 수 29."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c01ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### 블로그 여기서부터 ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adcf7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 29   # 단순히 함수나 메소드의 입력값 (매개변수)이거나 내부에서만 생성되고 사용되는 지역변수 (local variable)\n",
    "# self.max_length는 인스턴스 변수. 클래스로 만들어진 객체 (메소드)에 영구적으로 소속되는 변수\n",
    "#    - 객체의 모든 메소드 (__init__, __pad_token_sequence, __process_sequence에서 self.접두사를 통해 접근하고 사용 가능.\n",
    "dataset = ChatbotDataset(\n",
    "    list(question_texts),\n",
    "    list(answer_texts),\n",
    "    max_length,\n",
    "    tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d34e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3659c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  10, 1464, 1294,  368,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0]),\n",
       " tensor([6119,  378,   47, 2252,    8,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d2b6f-ccf7-4aec-9c08-176a2456e813",
   "metadata": {},
   "source": [
    "### Trainset / Testset 나누기\n",
    "train : test = 0.95 : 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c8fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11231, 592)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(dataset) * 0.95)\n",
    "test_size = len(dataset) - train_size\n",
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b45594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataset.Subset, torch.utils.data.dataset.Subset)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_set), type(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a490e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11231, 592)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b274f-8c8a-4aa6-af6d-a66bf5c38210",
   "metadata": {},
   "source": [
    "### DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad8cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a596315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdaf424-c7de-46be-b74b-88a3efcdf352",
   "metadata": {},
   "source": [
    "# 모델 정의\n",
    "\n",
    "## Seq2Seq 모델 정의\n",
    "- Seq2Seq 모델은 Encoder와 Decoder의 입력 Sequence의 길이와 순서가 자유롭기 때문에 챗봇이나 번역에 이상적인 구조다.\n",
    "    - 단일 RNN은 각 timestep 마다 입력과 출력이 있기 때문에 입/출력 sequence의 개수가 같아야 한다.\n",
    "    - 챗봇의 질문/답변이나 번역의 대상/결과 문장의 경우는 사용하는 어절 수가 다른 경우가 많기 때문에 단일 RNN 모델은 좋은 성능을 내기 어렵다.\n",
    "    - Seq2Seq는 **입력처리(질문,번역대상)처리 RNN과 출력 처리(답변, 번역결과) RNN 이 각각 만들고 그 둘을 연결한 형태로 길이가 다르더라도 상관없다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d7410-a73e-4be1-b41d-9ea07d6b0911",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Encoder는 하나의 Vector를 생성하며 그 Vector는 **입력 문장의 의미**를 N 차원 공간 저장하고 있다. 이 Vector를 **Context Vector** 라고 한다.    \n",
    "![encoder](figures/seq2seq_encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e8f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3878, -0.2407, -0.7084, -0.5376,  0.4590],\n",
       "        [ 0.7614, -2.3023,  0.4863,  1.4747,  0.1179],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.4192, -0.8022, -0.6512,  0.6792,  0.4380],\n",
       "        [-1.4338, -0.0480, -0.2202,  0.3836,  0.1374],\n",
       "        [ 0.7502, -0.1611,  0.9635, -1.0538, -0.3368],\n",
       "        [-0.8508,  1.4465,  0.1885,  0.6573,  0.7363],\n",
       "        [ 0.9614, -0.0447, -0.9787, -1.4607,  0.1769],\n",
       "        [-0.2596,  0.1841, -0.7803,  0.1845, -0.0351],\n",
       "        [-0.1488, -1.3017,  0.3861, -0.0372,  0.6094],\n",
       "        [-1.6507, -0.6879,  1.9730, -0.0060, -0.1055],\n",
       "        [ 0.9414,  1.1964,  0.4580, -1.1133,  1.9118],\n",
       "        [-1.4245, -0.2467, -0.7848, -0.0780, -1.2669],\n",
       "        [-0.7771, -0.0900, -1.1654, -1.5151,  0.9880],\n",
       "        [-0.4361, -0.0627, -0.7369, -0.2241, -0.3267],\n",
       "        [-0.7403,  0.6048, -0.8557,  0.1613,  2.4707],\n",
       "        [ 0.2431,  0.5341,  0.3026,  2.4493,  0.7642],\n",
       "        [ 0.0070,  0.7105, -1.4244,  1.1010, -1.1259],\n",
       "        [-1.9576,  0.7632, -1.4856, -0.7254, -1.5701],\n",
       "        [ 1.3706,  0.0806, -1.4798, -0.2411,  0.6943],\n",
       "        [ 1.1173, -0.0403, -0.2417,  0.0184, -0.2327],\n",
       "        [-1.7084, -0.3990,  0.7377, -1.5827,  0.5390],\n",
       "        [ 0.9685, -0.8278, -2.3920,  1.2373,  0.3414],\n",
       "        [-1.6850,  0.7525, -0.1728, -0.5159, -0.0392],\n",
       "        [ 0.0588,  0.8172, -0.6796,  0.7952,  0.8796],\n",
       "        [ 0.2003, -0.3870, -0.0535,  1.0632,  0.4295],\n",
       "        [ 1.4390, -0.4410, -0.1607,  0.8904,  0.6431],\n",
       "        [-1.8916,  0.3351, -1.2033,  0.0047, -0.0934],\n",
       "        [-0.5822,  2.2823, -1.1259,  0.5751,  0.6065],\n",
       "        [ 0.2195,  0.6176,  0.5652, -0.2971, -0.0957],\n",
       "        [-0.4216,  2.3764, -0.2780,  0.4108,  0.5031],\n",
       "        [-1.0372,  0.3718, -0.6663, -0.4542, -0.0960],\n",
       "        [-2.3765,  0.7294,  0.1275, -0.0957, -0.0419],\n",
       "        [ 1.9665,  1.0381,  0.1368,  0.4423,  0.3730],\n",
       "        [-0.0258, -1.1976, -0.3174, -0.4778,  0.0146],\n",
       "        [ 1.1019,  0.4838,  0.6461, -0.6091, -2.2925],\n",
       "        [-1.2865,  0.0143,  0.0096, -0.1591, -1.2329],\n",
       "        [ 0.8202, -0.2528, -0.2383,  1.0109,  0.9585],\n",
       "        [-0.7031, -1.5102,  1.3924,  0.7756, -1.4367],\n",
       "        [-0.9446, -0.4286, -1.1895,  0.2917,  0.1026],\n",
       "        [ 0.5147,  1.6818, -0.7263, -0.3577, -1.5457],\n",
       "        [-1.0635,  1.9559,  0.4917, -0.3873,  0.8128],\n",
       "        [ 0.4026,  1.4475,  0.5418, -0.4412, -1.4101],\n",
       "        [-3.1371,  0.4362,  0.6650, -0.4530, -0.4100],\n",
       "        [ 0.2691,  0.4385,  0.5994,  0.6360,  0.3776],\n",
       "        [-1.8712, -0.1546,  0.0229, -1.7217,  0.0239],\n",
       "        [ 1.0145, -0.6298,  0.2579,  1.3348, -0.8259],\n",
       "        [-0.1487, -2.9878,  0.2001,  0.6084, -0.5273],\n",
       "        [ 0.3125,  1.2081, -1.3194,  1.6447,  1.6923],\n",
       "        [ 0.1682, -2.2424,  0.6915,  0.9463,  0.4479],\n",
       "        [-1.2925, -0.2590,  0.6924,  0.6690, -1.1281],\n",
       "        [ 1.5663,  0.1877,  1.1031,  0.4303,  0.1910],\n",
       "        [-0.4145,  0.2635,  0.5683, -0.5345, -0.0351],\n",
       "        [ 0.2262,  0.5992,  0.0192,  0.4922,  1.0821],\n",
       "        [ 0.9912, -0.2289, -0.6704, -0.3079, -0.4793],\n",
       "        [-0.4194,  0.5586,  0.2525,  0.7883,  0.3869],\n",
       "        [-1.3865,  1.1801, -0.6061, -0.6731, -0.9300],\n",
       "        [ 0.0522,  0.2896, -0.1003,  0.4355, -0.8495],\n",
       "        [-0.5295, -0.0907,  0.5595, -0.1523,  0.8939],\n",
       "        [ 0.9611, -1.1328, -1.0664,  0.6977,  0.9635],\n",
       "        [ 0.7716,  0.4343,  0.9468,  0.8006, -0.0537],\n",
       "        [ 0.6585,  0.9966,  0.1852, -1.2469,  0.8352],\n",
       "        [-1.4901,  2.2019, -0.1959, -0.2497, -1.0171],\n",
       "        [ 0.5665, -0.3759,  1.6949, -0.0796,  1.0057],\n",
       "        [ 0.1076,  1.8303,  0.3339, -1.9015,  0.4856],\n",
       "        [-0.8068,  1.2174,  1.0203,  0.3401, -1.6834],\n",
       "        [ 0.6459,  0.2027,  1.1628, -0.4359, -1.2041],\n",
       "        [ 0.3860, -0.3844, -1.1940, -0.6849,  1.2123],\n",
       "        [ 1.0357,  1.2283,  1.0427, -0.3966, -0.1341],\n",
       "        [ 1.6904,  0.4188,  0.3273,  0.3573, -1.3117],\n",
       "        [ 0.4263,  0.3396, -0.0827,  0.6359, -0.2180],\n",
       "        [ 0.5045,  0.1684,  0.2622, -0.6928, -2.4145],\n",
       "        [ 1.3903, -0.5961, -0.6728, -0.4433,  0.5274],\n",
       "        [ 0.3061, -0.6417,  0.1295, -1.1442,  0.6105],\n",
       "        [-0.6046,  0.3662, -0.3077, -2.0325,  0.2736],\n",
       "        [-0.1063,  0.2277,  0.0816,  0.8153, -0.6489],\n",
       "        [ 0.8036,  0.0723, -2.1357, -0.3017,  0.0033],\n",
       "        [ 0.7621,  1.8430,  0.5539, -0.4808,  2.0069],\n",
       "        [-0.2001,  2.2864, -0.6804,  0.2306, -1.9766],\n",
       "        [ 2.6721, -0.5313,  1.4709,  0.6961, -0.7972],\n",
       "        [-1.2467,  0.0533, -0.9280, -1.1418, -0.2071],\n",
       "        [-0.4388,  0.8172, -0.7269,  0.3561, -0.2123],\n",
       "        [-1.0114,  0.2604, -0.6494,  1.1926, -1.2449],\n",
       "        [ 0.0375,  0.2673,  1.5941,  0.7177, -0.3142],\n",
       "        [-1.1418,  1.3276,  0.6723,  1.6058,  1.0087],\n",
       "        [ 0.6304,  1.1253,  0.5382, -1.5953, -0.6990],\n",
       "        [ 0.7825, -0.8750, -0.8656,  0.0116, -1.6728],\n",
       "        [-2.2310,  0.2763,  0.2649, -0.8327, -0.5715],\n",
       "        [ 1.7892,  0.7883,  0.8597,  1.5268,  0.7997],\n",
       "        [-0.7571,  0.7649,  0.1665, -1.4560, -0.3574],\n",
       "        [-0.0868,  0.0945, -0.7004, -0.6642, -0.9295],\n",
       "        [-0.8316, -0.5830, -1.3882,  1.3574, -0.7997],\n",
       "        [-0.2503, -1.2294,  1.2533,  0.5306, -0.3635],\n",
       "        [-0.6037,  0.0113, -1.2717,  0.1765,  0.6441],\n",
       "        [-0.6686,  1.1610, -0.9419, -0.7857,  1.8878],\n",
       "        [-0.8803, -0.5477,  0.3581,  2.3238,  0.7875],\n",
       "        [-0.0500, -0.8845, -0.9540,  0.4657, -1.4970],\n",
       "        [-1.0303, -1.6209, -0.9842,  0.1877, -0.1889],\n",
       "        [ 0.4435, -0.4831,  1.2693,  0.8302, -1.0507],\n",
       "        [-1.5621, -1.4806,  1.9319, -0.1055,  0.4079]], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.Embedding(100, 5, padding_idx=2)\n",
    "a.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477135dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size: int,   # 총 어휘 수\n",
    "            embedding_dim: int,   # Embedding Vector의 차원\n",
    "            hidden_size: int, # GRU의 hidden 개수\n",
    "            bidirectional: bool = True,   # GRU의 양방향 여부\n",
    "            num_layers: int = 1,   # GRU의 layer stack 수 \n",
    "            dropout: float = 0.2   # dropout의 비율\n",
    "        ):\n",
    "            super().__init__()\n",
    "            self.vocab_size = vocab_size\n",
    "            # X -> (Embedding Model) -> (GRU) -> Context Vector -> (Decoder)\n",
    "            # Encoder의 목적은 (질문의) Context Vector를 추출하는 것이 목적. \n",
    "            self.embedding = nn.Embedding(\n",
    "                 vocab_size, \n",
    "                 embedding_dim,  # (vocab_size X embedding_dim)\n",
    "                 padding_idx=0\n",
    "            )\n",
    "\n",
    "            self.gru = nn.GRU(\n",
    "                 input_size=embedding_dim,\n",
    "                 hidden_size=hidden_size,\n",
    "                 num_layers=num_layers,\n",
    "                 bidirectional=bidirectional,\n",
    "                 dropout=dropout if num_layers > 1 else 0.0\n",
    "            )\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X.shape [batch, seq_length]\n",
    "        embedding_vector = self.embedding(X)  # [batch, seq_length]\n",
    "        embedding_vector = embedding_vector.transpose(1, 0) # [seq_length, batch, emb_dim]\n",
    "        out, hidden = self.gru(embedding_vector)  \n",
    "        # out: 모든 time step의 hidden_state, hidden: 마지막 time step의 hidden_state\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85d3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 203, 5872, 3585, 2291,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf51c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 5, 6,  ..., 6, 2, 8],\n",
       "        [1, 4, 9,  ..., 3, 0, 7],\n",
       "        [0, 6, 3,  ..., 4, 9, 8],\n",
       "        ...,\n",
       "        [8, 8, 8,  ..., 6, 2, 5],\n",
       "        [0, 2, 7,  ..., 0, 8, 1],\n",
       "        [5, 7, 8,  ..., 9, 4, 8]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "dummy_input = torch.randint(10, size=(64, 20), dtype=torch.int64)\n",
    "dummy_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6f13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Encoder                                  [20, 64, 40]              --\n",
       "├─Embedding: 1-1                         [64, 20, 100]             100,000\n",
       "├─GRU: 1-2                               [20, 64, 40]              14,640\n",
       "==========================================================================================\n",
       "Total params: 114,640\n",
       "Trainable params: 114,640\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 25.14\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.43\n",
       "Params size (MB): 0.46\n",
       "Estimated Total Size (MB): 1.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(Encoder(1000, 100, 20), input_data=dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8344f-8cf7-45a8-8092-ab20365cdb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24779603-15ac-4ba1-a24c-6e86658b3ad6",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "- Encoder의 출력(context vector)를 받아서 번역 결과 sequence를 출력한다.\n",
    "- Decoder는 매 time step의 입력으로 **이전 time step에서 예상한 단어와 hidden state값이** 입력된다.\n",
    "- Decoder의 처리결과 hidden state를 Estimator(Linear+Softmax)로 입력하여 **입력 단어에 대한 번역 단어가 출력된다.** (이 출력단어가 다음 step의 입력이 된다.)\n",
    "    - Decoder의 첫 time step 입력은 문장의 시작을 의미하는 <SOS>(start of string) 토큰이고 hidden state는 context vector(encoder 마지막 hidden state) 이다.\n",
    "\n",
    "![decoder](figures/seq2seq_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c842666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b3ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=1, bidirectional=False, # Decoder는 생성. 뒤에 토큰들을 알지 못하기 때문에 단방향 처리. \n",
    "                          dropout=0.2\n",
    "                         ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            embedding_dim, \n",
    "            hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            dropout= dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(\n",
    "            hidden_size,   # 입력 - gru의 마지막 hidden state값.\n",
    "            vocab_size     # 출력 - 다중분류: 어휘사전의 단어들 중 다음 단어 한 개를 찾는 다중분류.\n",
    "        )\n",
    "        \n",
    "    def forward(self, X, hidden):\n",
    "        \"\"\"\n",
    "        X: 한 개 토큰. shape: [batch] []\n",
    "        hidden: 이전 처리 hidden state. 첫 번째 time step: Encoder의 context vector\n",
    "                [seq_length: 1, batch, hidden_size]\n",
    "        \"\"\"\n",
    "        # [batch] -> [batch, 1] 1: seq_length\n",
    "        X = X.unsqueeze(1)\n",
    "        embedding_vector = self.embedding(X)   # 입력: int64, [batch, seq_length(1)]\n",
    "        # [batch, seq_length, embedding_dim] -> [seq_length, batch, embedding_dim]\n",
    "        embedding_vector = embedding_vector.transpose(1, 0)\n",
    "\n",
    "        #[seq_length(1), batch, embedding_dim -> out, hidden\n",
    "        # out (모든 time step의 hidden state 모음): [seq_length(1), batch_size, hidden_size]\n",
    "        # hidden (마지막 time step의 hidden state): [num_layers, batch_size, hidden_size]\n",
    "        out, hidden = self.gru(embedding_vector, hidden)\n",
    "\n",
    "        # Linear (분류기) 넣어서 다음 단어를 예측\n",
    "        last_out = self.classifier(out[-1])\n",
    "\n",
    "        # last_out: 다음 단어일 확률, [batch, vocab_size]\n",
    "        # hidden: 다음 단어를 예측할 때 넣어줄 context vector (hidden state)\n",
    "        return last_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07570b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e9182",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Embedding: 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torchinfo/torchinfo.py:295\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1561\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1559\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1561\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mDecoder.forward\u001b[39m\u001b[34m(self, X, hidden)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m#[seq_length(1), batch, embedding_dim -> out, hidden\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# out (모든 time step의 hidden state 모음): [seq_length(1), batch_size, hidden_size]\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# hidden (마지막 time step의 hidden state): [num_layers, batch_size, hidden_size]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m out, hidden = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Linear (분류기) 넣어서 다음 단어를 예측\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1561\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1559\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1561\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1098\u001b[39m, in \u001b[36mGRU.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1096\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m-> \u001b[39m\u001b[32m1098\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:276\u001b[39m, in \u001b[36mRNNBase.check_forward_args\u001b[39m\u001b[34m(self, input, hidden, batch_sizes)\u001b[39m\n\u001b[32m    274\u001b[39m expected_hidden_size = \u001b[38;5;28mself\u001b[39m.get_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_hidden_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:259\u001b[39m, in \u001b[36mRNNBase.check_hidden_size\u001b[39m\u001b[34m(self, hx, expected_hidden_size, msg)\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hx.size() != expected_hidden_size:\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg.format(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx.size())))\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected hidden size (1, 64, 256), got [1, 64, 200]",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# hidden shape: [1-gru layer 개수, 64: batch, 200: hidden_size]\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# gru layer 개수: num_layers * 2 if bidirectional else 1\u001b[39;00m\n\u001b[32m      6\u001b[39m dummy_decoder = Decoder(\u001b[32m10000\u001b[39m, \u001b[32m200\u001b[39m, \u001b[32m256\u001b[39m, num_layers=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_decoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_hidden\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torchinfo/torchinfo.py:223\u001b[39m, in \u001b[36msummary\u001b[39m\u001b[34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[39m\n\u001b[32m    216\u001b[39m validate_user_params(\n\u001b[32m    217\u001b[39m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[32m    218\u001b[39m )\n\u001b[32m    220\u001b[39m x, correct_input_size = process_input(\n\u001b[32m    221\u001b[39m     input_data, input_size, batch_dim, device, dtypes\n\u001b[32m    222\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m summary_list = \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m formatting = FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[32m    227\u001b[39m results = ModelStatistics(\n\u001b[32m    228\u001b[39m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[32m    229\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/08_NLP-자연어처리/.venv/lib/python3.12/site-packages/torchinfo/torchinfo.py:304\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    303\u001b[39m     executed_layers = [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer.executed]\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    305\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Embedding: 1]"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.ones([64], dtype=torch.int64)   # 64: batch\n",
    "dummy_hidden = torch.ones((1, 64, 200), dtype=torch.float32)\n",
    "# hidden shape: [1-gru layer 개수, 64: batch, 200: hidden_size]\n",
    "# gru layer 개수: num_layers * 2 if bidirectional else 1\n",
    "\n",
    "dummy_decoder = Decoder(10000, 200, 256, num_layers=1)\n",
    "summary(dummy_decoder, input_data=(dummy_input, dummy_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word, hidden = dummy_decoder(dummy_input, dummy_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d95199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10000])\n",
      "torch.Size([1, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "print(next_word.shape)\n",
    "print(hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdf137-057b-4e41-95cd-c58219032b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274,\n",
       "        7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274,\n",
       "        7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274,\n",
       "        7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274,\n",
       "        7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274,\n",
       "        7274, 7274, 7274, 7274])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word.max(dim=-1).indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3563f5b2-f18b-42b5-9bd4-f4f8abd767ac",
   "metadata": {},
   "source": [
    "## Seq2Seq 모델\n",
    "\n",
    "- Encoder - Decoder 를 Layer로 가지며 Encoder로 질문의 feature를 추출하고 Decoder로 답변을 생성.\n",
    "\n",
    "### Teacher Forcing\n",
    "- **Teacher forcing** 기법은, RNN계열 모델이 다음 단어를 예측할 때, 이전 timestep에서 예측된 단어를 입력으로 사용하는 대신 **실제 정답 단어(ground truth) 단어를** 입력으로 사용하는 방법.\n",
    "    - 모델은 이전 시점의 출력 단어를 다음 시점의 입력으로 사용한다. 그러나 모델이 학습할 때 초반에는 정답과 많이 다른 단어가 생성되어 엉뚱한 입력이 들어가 학습이 빠르게 되지 않는 문제가 있다.\n",
    "- **장점**\n",
    "    - **수렴 속도 증가**: 정답 단어를 사용하기 때문에 모델이 더 빨리 학습 가능.\n",
    "    - **안정적인 학습**: 초기 학습 단계에서 모델의 예측이 불안정할 때, 잘못된 예측으로 인한 오류가 다음 단계로 전파되는 것을 막아줍니다.\n",
    "- **단점**\n",
    "    - **노출 편향(Exposure Bias) 문제:** 실제 예측 시에는 정답을 제공할 수 없으므로 모델은 전 단계의 출력값을 기반으로 예측해 나가야 한다. 학습 과정과 추론과정의 이러한 차이 때문에 모델의 성능이 떨어질 수있다.\n",
    "        - 이런 문제를 해결하기 학습 할 때 **Teacher forcing을 random하게 적용해 학습시킨다.**\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### colab 에서 실행하기 ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acaa23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SOS_TOKEN = tokenizer.token_to_id(\"<sos>\")\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super.__init__()\n",
    "        self.encoder = encoder.to(device)\n",
    "        self.decoder = decoder.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, inputs, outputs, teacher_forcing_rate=0.99):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            inputs: 질문 (batch, seq_length)\n",
    "            outputs: 답변(정답) (batch, seq_length) -> teacher forcing 때 사용.\n",
    "            teacher_forcing_rate: teacher forcing은 random하게 적용. 적용될 확률. \n",
    "        \"\"\"\n",
    "        # 질문과 답변이 1차원일 경우 2차원으로 reshape\n",
    "        # if [batch] -> [batch(1), seq_length]\n",
    "        if inputs.dim() ==1:\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "        if outputs.dim() == 1:\n",
    "            outputs = outputs.unsqueeze(0)\n",
    "\n",
    "        batch_size, output_length = outputs.shape   # output_length: output의 max_length. 답변 문장의 토큰 수를 여기에 맞출 것. \n",
    "        output_vocab_size = self.encoder.vocab_size\n",
    "\n",
    "\n",
    "        ##############################################################\n",
    "        # 생성된 문장을 저장할 tensor 생성 (모델이 생성한 예측 문장)\n",
    "        # (seq_length, batch_size, vocab_size)\n",
    "        # [나는, 학생, 이다.]\n",
    "        # [\n",
    "        # vocab_size의 각 단어가 \"나는\"일 확률\n",
    "        # vocab_size의 각 단어가 \"학생\"일 확률\n",
    "        # vocab_size의 각 단어가 \"이다\"일 확률\n",
    "        # ]\n",
    "        ##################################\n",
    "\n",
    "        predicted_outputs = torch.zeros(output_length, batch_size, output_vocab_size).to(self.device)\n",
    "\n",
    "        ##############################################################\n",
    "        # 추론\n",
    "        # 1. encoder를 이용해서 context vector 추출 (한번에 처리)\n",
    "        # 2. decoder를 이용해서 답변 문장을 생성 (개별 토큰 별로 생성) 반복.\n",
    "        ##############################################################\n",
    "        # encode를 이용해 context vector 추출\n",
    "        \n",
    "        encoder_out, _ = self.encoder(inputs)   # encoder_out: 전체 hidden state 모음\n",
    "\n",
    "        # context vector == encoder_out[-1] => Decoder의 첫 번째 time step의 hidden으로 입력.\n",
    "        decoder_hidden = encoder_out[-1].unsqueeze(0)\n",
    "        # decoder에 입력할 첫 번째 time step값: <sos> 토큰 ID\n",
    "        decoder_input = torch.full([batch_size], fill_value=SOS_TOKEN, device=self.device)\n",
    "\n",
    "        ####################################\n",
    "        # Decoder를 이용해서 한 단어 (토큰)씩 생성\n",
    "        ####################################\n",
    "        for t in range(output_length):\n",
    "            decoder_out, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            predicted_outputs = decoder_out  # t번째 예측 단어.\n",
    "\n",
    "            # 다음 time step의 input을 생성 (decoder_input 값을 생성)\n",
    "            # teacher forcing 적용 -> t번째 정답 토큰 \n",
    "            #                 적용 안 함 -> Decoder가 생성한 decoder_out에서 token id값.\n",
    "            # teacher_forcing_rate 비율로 teacher forcing을 적용\n",
    "            teacher_forcing = teacher_forcing_rate > random.random()\n",
    "            teacher_forcing_rate *= 0.99  # 반복하면서 teacher forcing 적용 확률을 줄여나간다. \n",
    "\n",
    "            top1 = decoder_out.argmax(dim=-1)     # 다음 단어일 확률이 가장 높은 단어의 토큰 ID\n",
    "            decoder_input = outputs[:, t] if teacher_forcing else top1\n",
    "\n",
    "\n",
    "        return predicted_outputs.transpose(1, 0)   # [seq_length <-> batch, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e3ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 29)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.encode(\"안녕하세요. 반가워요.\").ids\n",
    "# b, o = [64, 29]\n",
    "# b, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56953ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = torch.tensor([[1, 2], [3, 4]])\n",
    "# a.shape\n",
    "# a[-1].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c178a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.random()  # 0~1 사이의 실수 반환. 모든 실수는 같은 확률로 나온다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89fed5-b059-4371-b836-c3eb59bebdfb",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7",
   "metadata": {},
   "source": [
    "## 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter 정의\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "encoder_bidirectional = True  # encoder는 양방향\n",
    "encoder_hidden_size = 200\n",
    "\n",
    "# encoder의 hidden(context vector)과 decoder hidden을 맞춰준다.\n",
    "decoder_hidden_size = encoder_hidden_size * 2 if encoder_bidirectional else encoder_hidden_size\n",
    "\n",
    "embedding_dim = 256\n",
    "teacher_forcing_rate = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce8d66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hidden_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 모델 생성 \u001b[39;00m\n\u001b[32m      2\u001b[39m encoder = Encoder(\n\u001b[32m      3\u001b[39m     vocab_size = vocab_size,\n\u001b[32m      4\u001b[39m     embedding_dim = embedding_dim,\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     hidden_size = \u001b[43mhidden_size\u001b[49m,\n\u001b[32m      6\u001b[39m     num_layers = \u001b[32m1\u001b[39m,\n\u001b[32m      7\u001b[39m     bidirectional=encoder_bidirectional\n\u001b[32m      8\u001b[39m )\n\u001b[32m      9\u001b[39m decoder = Decoder(\n\u001b[32m     10\u001b[39m     vocab_size = vocab_size,\n\u001b[32m     11\u001b[39m     embedding_dim = embedding_dim,\n\u001b[32m     12\u001b[39m     hidden_size = decoder_hidden_size,\n\u001b[32m     13\u001b[39m     num_layers = \u001b[32m1\u001b[39m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m seq2seq = Seq2Seq(encoder, decoder, device)\n",
      "\u001b[31mNameError\u001b[39m: name 'hidden_size' is not defined"
     ]
    }
   ],
   "source": [
    "# 모델 생성 \n",
    "encoder = Encoder(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim = embedding_dim,\n",
    "    hidden_size = encoder_hidden_size,\n",
    "    num_layers = 1,\n",
    "    bidirectional=encoder_bidirectional\n",
    ")\n",
    "decoder = Decoder(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim = embedding_dim,\n",
    "    hidden_size = decoder_hidden_size,\n",
    "    num_layers = 1\n",
    ")\n",
    "seq2seq = Seq2Seq(encoder, decoder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_input = torch.zeros((64, 30), dtype=torch.int64)\n",
    "\n",
    "summary(seq2seq, input_data=(d_input, d_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba83263-e042-4579-9784-2403eb3c3fa1",
   "metadata": {},
   "source": [
    "## loss함수, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8000c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "model = seq2seq(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a659df1-87a2-4fe0-a095-e031ed130e68",
   "metadata": {},
   "source": [
    "## train/evaluation 함수 정의\n",
    "\n",
    "### train 함수정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d12a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_fn, device, teacher_forcing_rate=0.9):\n",
    "    model.train()\n",
    "    train_loss=0.0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X, y, teacher_forcing_rate)  # seq2seq\n",
    "        # pred: [batch, seq_length, vocab_size]\n",
    "        # pred: [batch, seq_length, vocab_size]\n",
    "        y_hat = pred.reshape(-1, pred.shape[2])  # loss 계산을 위해서\n",
    "        y = y.reshape(-1)   # [batch, seq_length] -> [batch * seq_length]\n",
    "        # CrossEntropyLoss입력: 정답 - [batch,], 추론: [batch, class 개수 - vocab_size]\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()   # gradient 계산.\n",
    "        optimizer.step()  # update\n",
    "        optimizer.sero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return train_loss / len (dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981388d-ad33-4318-844b-29a5a434d2a7",
   "metadata": {},
   "source": [
    "### Test 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model (X, y, teacher_forcing_rate=0.0)  # teacher_forcing 적용하면 안 됨\n",
    "        y_hat = pred.reshape(-1, pred.shape[-1])\n",
    "        y = y.reshape(-1)\n",
    "        eval_loss += loss_fn(y_hat, y).item()\n",
    "\n",
    "    return eval_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71e20c-8a03-44f4-bbbc-8f4e51b85636",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model_save_path = \"saved_models/chatbot_seq2seq.pth\"\n",
    "# 가장 validation loss가 좋은 모델을 저장.\n",
    "best_loss = torch.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, loss_fn, device, teacher_forcing_rate)\n",
    "    eval_loss = eval(model, test_loader, loss_fn, device)\n",
    "\n",
    "    if best_loss > eval_loss:  # 성능 개선\n",
    "        torch.save(model, model_save_path)\n",
    "        print(epoch+1, \"에서 저장 -------------\")\n",
    "        best_loss = eval_loss\n",
    "\n",
    "    print(epoch+1, train_loss, eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 저장 모델 Load\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# map_location=device : 다른 device에 학습/저장한 모델을 읽어올 때 현재 device를 지정해서  현재 device에 맞춰 load하도록한다.\n",
    "best_model = torch.load(model_save_path, weights_only=False, map_location=device)\n",
    "best_model.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5280dca7-029c-4eb6-b079-39963d7b7932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fe0585a-eb35-47dd-88bf-276d749f5f00",
   "metadata": {},
   "source": [
    "# 결과확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b94a1-bc0a-474a-8415-57dc5ea4b894",
   "metadata": {},
   "source": [
    "- Sampler:\n",
    "    -  DataLoader가 Datatset의 값들을 읽어서 batch를 만들때 index 순서를 정해주는 객체.\n",
    "    -  DataLoader의 기본 sampler는 SequentialSampler 이다. shuffle=True 일경우 RandomSampler: 랜덤한 순서로 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = Dataset(...)\n",
    "\n",
    "# d_loader = DataLoader(ds, 200, shuffle=True)\n",
    "# index = [0~999]\n",
    "# 1. new_idx = shuffle(index) [920, 1, 87, 234, ...] 0~199, 200~399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_special_tokens(decoded_string):\n",
    "    \"\"\"\n",
    "    Subword 처리\n",
    "    subword는 단어의 시작으로 쓰인 것과 중간 부분(연결)에 사용된 두가지 subword가 있다.  연결 subword는 `#`과 같은 특수문자로 시작 한다.\n",
    "    tokenizer.decode() 결과 문자열은 subword의 특수문자('##')을 처리하지 않는다. 이것을 처리하는 함수\n",
    "    ex) \"이 기회 ##는 내 ##꺼 ##야\" ==> \"이 기회는 내꺼야\"\n",
    "    \n",
    "    Parameter\n",
    "        decoded_string: str - Tokenizer가 decode한 중간 subword의 특수문자 처리가 안된 문자열. \n",
    "    Return\n",
    "        str: subword 특수문자 처리한 문자열\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = decoded_string.split() # 공백기준으로 토큰화.\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.startswith(\"##\"): # 연결 토큰\n",
    "            if new_tokens: # len(new_tokens) != 0 원소가 하나라도 있으면\n",
    "                # 토큰에서 ##을 제거하고 리스트의 마지막 원소(문자열) 뒤에 붙인다.\n",
    "                new_tokens[-1] += token[2:]\n",
    "            else: # new_tokens가 빈 리스트. 현재 token이 첫번째 단어. ##을 지우고 append\n",
    "                new_tokens.append(token[2:])\n",
    "        else: # 단어의 시작인 토큰. (##이 없는 토큰) -> list에 추가.\n",
    "            new_tokens.append(' '+token)\n",
    "        \n",
    "    return \"\".join(new_tokens) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0822c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler\n",
    "# sampler는 “Dataset에서 어떤 순서로 index를 뽑을지 결정하는 객체”이다. DataLoader는 sampler가 제공하는 index를 이용해 Dataset에서 데이터를 추출한다.\n",
    "## shuffle=True 이면 RandomSampler가 사용된다. False이면 SequentialSampler가 사용된다.\n",
    "\n",
    "\n",
    "#  dataset에서 일부 데이터들을 가지고 확인\n",
    "def random_evaluation(model, dataset, device, n=10):\n",
    "    \"\"\"\n",
    "    Dataset에서 일부 질문-답변 쌍들을 가져다 모델에 질문을 넣어 추론한 결과와 함께 확인.\n",
    "    Parameter\n",
    "        model: 학습된 seq2seq 모델\n",
    "        dataset: 질문-답변 쌍울 추출할 dataset\n",
    "        device\n",
    "        n: int - 추출할 질문-답변 쌍 개수 default: 10\n",
    "    \"\"\"\n",
    "    ## 평가할 데이터셋을 만들기\n",
    "    n_samples = len(dataset)       # Dataset의 총 데이터개수\n",
    "    # index = list(range(n_samples)) # Dataset의 index만들기.  [0, 1, 2, ...., dataset_length]\n",
    "    # np.random.shuffle(index)       # 값들을 랜덤하게 섞어준다. [100, 23, 590, 10, ...] \n",
    "    # sample_index = index[ : n]     # 평가할 데이터 개수만큼 index 생성.\n",
    "\n",
    "\n",
    "    sample_index = torch.randint(0, n_samples, size=[n])\n",
    "    \n",
    "    # Dataloader 생성\n",
    "    # SubsetRandomSampler: 지정한 index들 안에서 random한 순서로 제공.\n",
    "    # sample_index=[1, 20, 4, 5, 100], dataset에서 [1, 20, 4, 5, 100] index의 값만 추출\n",
    "    sampler = SubsetRandomSampler(sample_index)\n",
    "    sample_loader = DataLoader(dataset, batch_size=n, sampler=sampler)\n",
    "    \n",
    "    ## 추론 후 확인\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in sample_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X, y, 0.0) # [batch, seq_len, vocab_size]\n",
    "\n",
    "            # torch.Tensor -> ndarray (tokenizer decode에 넣기 위해.)\n",
    "            ## tensor를 cpu로 이동후 변환가능.\n",
    "            ### tensor가 grad를 가지고 있으면(계산그래프에 포함돼 있으면)\n",
    "            ####                               -> tensor.detach().cpu().ndarray()\n",
    "\n",
    "            pred = output.cpu().numpy()  # X.to(\"cpu\") # 모델추정 답변\n",
    "            X = X.cpu().numpy()   # 정답-질문\n",
    "            y = y.cpu().numpy()   # 정답-답변 (batch, seq_len, vocab)\n",
    "\n",
    "            for i in range(n):\n",
    "                q = handle_special_tokens(tokenizer.decode(X[i]))\n",
    "                a = handle_special_tokens(tokenizer.decode(y[i]))\n",
    "                p = handle_special_tokens(tokenizer.decode(pred[i].argmax(-1)))\n",
    "                print(f\"질문: {q}\")\n",
    "                print(f\"정답: {a}\")\n",
    "                print(f\"예측: {p}\")\n",
    "                print('==================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476eae22-4c6a-4f55-8dd2-87f8dd1ba46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_evaluation(model, train_set, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4965d1-a305-4465-8f64-f689d55490ac",
   "metadata": {},
   "source": [
    "# 학습모델을 이용한 대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5dea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotInputDataset(Dataset):\n",
    "    \"\"\"\n",
    "    질문만 받아서 생성하는 Dataset\n",
    "    - 새로운 데이터 추론용.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, question_texts, max_length, tokenizer):\n",
    "        \"\"\"\n",
    "        parameter\n",
    "            question_texts: list[str] - 질문 texts 목록. 리스트에 질문들을 담아서 받는다. [\"질문1\", \"질문2\", ...]\n",
    "            max_length: 개별 문장의 token 개수. 모든 문장의 토큰수를 max_length에 맞춘다.\n",
    "            tokenizer: Tokenizer\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "    \n",
    "    def __pad_token_sequence(self, token_sequence): \n",
    "        \"\"\"\n",
    "        max_length 길이에 맞춰 token_id 리스트를 구성한다.\n",
    "        max_length 보다 길면 뒤에를 자르고 max_length 보다 짧으면 [PAD] 토큰을 추가한다.\n",
    "        \n",
    "        Parameter\n",
    "            token_sentence: list[int] - 길이를 맞출 한 문장 token_id 목록\n",
    "        Return\n",
    "            list[int] - length가 max_length인 token_id 목록\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('<pad>')\n",
    "        seq_len = len(token_sequence) # 입력 문장의 토큰수\n",
    "        if seq_len > self.max_length: # 문장 최대 토큰수 보다 길다면.\n",
    "            return token_sequence[:self.max_length]\n",
    "        else:\n",
    "            return token_sequence + ([pad_token] * (self.max_length - seq_len))\n",
    "    \n",
    "    def __process_sequence(self, text): \n",
    "        \"\"\"\n",
    "        한 문장(str)을 받아서 padding이 추가된 token_id 리스트로 변환 후 반환\n",
    "        Parameter\n",
    "            text: str - token_id 리스트로 변환할 한 문장\n",
    "        Return\n",
    "            list[int] - 입력받은 문장에 대한 token_id 리스트\n",
    "        \"\"\"\n",
    "        # encoding\n",
    "        encode = self.tokenizer.encode(text) # \"........\" => [. , . , .]\n",
    "        # max_length 크기에 맞춘다.\n",
    "        token_ids = self.__pad_token_sequence(encode.ids) #[3400, 20, 6, 0, 0, 0 ..]\n",
    "        return token_ids\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.question_texts)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 질문만 반환.\n",
    "        q = self.question_texts[index]  # List\n",
    "        \n",
    "        # List->LongTensor. nn.Embedding()의 입력(정수타입)으로 들어간다. \n",
    "        return torch.tensor(q, dtype=torch.int64) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [\n",
    "    \"난 가족들과 주말에 여행갈 거야.\", \n",
    "    \"와! 내일 주말이다.\",\n",
    "    \"너무 피곤하네요.\",\n",
    "    \"지금 몇시에요?\",\n",
    "    \"여자 친구와 데이트 약속했어.\"    \n",
    "]\n",
    "input_dataset = ChatbotInputDataset(input_data, max_length, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b72a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for X in dataset:  # Dataset에서 한 질문씩을 조회\n",
    "            X = X.to(device)\n",
    "            output = model(X.unsqueeze(0), X.unsqueeze(0), 0.0)\n",
    "            pred = output.cpu().numpy()\n",
    "            X = X.cpu().numpy()\n",
    "            q = handle_special_tokens(tokenizer.decode(X))\n",
    "            a = handle_special_tokens(tokenizer.decode(pred[0].argmax(-1)))\n",
    "            print(f\"질문: {q}\")\n",
    "            print(f\"예상답: {a}\")\n",
    "            print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c89f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(input_dataset, model, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
