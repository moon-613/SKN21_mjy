{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15df675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/5(금) 9:20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8389555c-17d0-41ed-abfc-42046bf8aeaa",
   "metadata": {},
   "source": [
    "# Encoder–Decoder 구조\n",
    "\n",
    "- Encoder–Decoder 구조는 어떤 형태의 입력 시퀀스를 받아 **의미를 해석**한 뒤, 새로운 **출력 시퀀스를 생성**해야 하는 거의 모든 AI 문제를 해결하는 딥러닝 모델 구조다.\n",
    "- 이 구조는 Encoder와 Decoder 두개의 딥러닝 모델을 연결한 구조로 **입력 데이터를 하나의 표현으로 압축한 뒤, 이를 다시 출력 데이터로 변환하는 방식**으로 동작한다.\n",
    "\n",
    "- **Encoder Network**\n",
    "  - 입력 데이터를 해석(이해)하는 역할을 수행.\n",
    "  - 입력 시퀀스에 담긴 의미적 정보를 하나의 고정된 벡터 형태로 요약.\n",
    "\n",
    "- **Decoder Network**\n",
    "  - Encoder가 생성한 요약 정보를 바탕으로 최종 출력을 생성.\n",
    "  - 즉, Encoder의 “이해 결과”를 이용해 새로운 시퀀스를 만들어낸다.\n",
    "\n",
    "## Seq2Seq (Sequence-to-Sequence)\n",
    "\n",
    "Seq2Seq 모델: **Encoder–Decoder 구조를 RNN(Recurrent Neural Network) 계열에 적용한 대표적인 시퀀스 변환 모델**.  \n",
    "입력과 출력이 모두 “시퀀스(sequence)” 형태라는 점에서 *Sequence-to-Sequence*라는 이름이 붙었다.\n",
    "\n",
    "### Encoder의 역할: 입력 시퀀스 이해 및 Context Vector 생성\n",
    "\n",
    "Encoder는 입력으로 들어온 **전체 시퀀스**(sequence)를 순차적으로 처리한 뒤,  그 의미를 **하나의 고정 길이 벡터**(Vector)로 압축하여 출력한다.  \n",
    "이 벡터를 **Context Vector**(컨텍스트 벡터)라고 한다.\n",
    "- **Context Vector란?**  \n",
    "  - 입력 시퀀스 전체의 의미, 문맥, 핵심 정보를 요약해 담고 있는 벡터 표현이다.\n",
    "  - **기계 번역**(Machine Translation)의 경우  \n",
    "    - 번역할 원문 문장에서 **번역 결과를 생성하는 데 필요한 핵심 의미 정보**(feature)\n",
    "  - **챗봇**(Chatbot)의 경우  \n",
    "    - 사용자가 입력한 질문에서 **적절한 답변을 생성하는 데 필요한 의미 정보**(feature)\n",
    "\n",
    "### Decoder의 역할: Context Vector를 바탕으로 출력 시퀀스 생성\n",
    "\n",
    "Decoder는 Encoder가 출력한 **Context Vector를 입력으로 받아**, 이를 바탕으로 **목표 출력 시퀀스**를 한 토큰(token)씩 순차적으로 생성.\n",
    "\n",
    "- **기계 번역**(Machine Translation)의 경우  \n",
    "  - 입력 문장의 의미를 반영한 **번역 문장** 생성.\n",
    "- **챗봇**(Chatbot)  \n",
    "  - 질문에 대한 **자연스러운 답변 문장** 생성.\n",
    "\n",
    "Decoder는 매 시점(time step)마다\n",
    "  - 이전에 생성한 단어\n",
    "  - 그리고 Context Vector에 담긴 입력 문맥\n",
    "을 함께 고려해 다음 단어를 예측.\n",
    "\n",
    "\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887d108-2ac6-425e-9643-d351e44282c7",
   "metadata": {},
   "source": [
    "# Seq2Seq 를 이용한 Chatbot 모델 구현\n",
    "- Encoder를 이용해 질문의 특성을 추출하고 Decoder를 이용해 답변을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec7aee-1d3b-4990-b934-a4254a6e17ef",
   "metadata": {},
   "source": [
    "# Chatbot Dataset\n",
    "\n",
    "- https://github.com/songys/Chatbot_data\n",
    "- columns\n",
    "    - Q: 질문\n",
    "    - A: 답\n",
    "    - label: 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2\n",
    "- **Download**\n",
    "\n",
    "![dataset](figures/chatbot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa75cf8-9cd9-4a72-a610-4392b80ca6b5",
   "metadata": {},
   "source": [
    "# Chatbot Dataset Loading 및 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd0c3c-2b8f-4a4c-b90c-a0fa6d828c4c",
   "metadata": {},
   "source": [
    "## 데이터셋 다운로드 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876b85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\"\n",
    "res = requests.get(url)\n",
    "if res.status_code == 200:\n",
    "    with open(\"data/chatbot_data.csv\", \"wt\", encoding=\"utf-8\") as fw:\n",
    "        fw.write(res.text)\n",
    "else:\n",
    "    print(\"다운 실패:\", res.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "395565ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/chatbot_data.csv\", encoding=\"utf-8\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56432716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf714bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd68f4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Q",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "c3610f60-fd0e-4cd8-991b-ea233d526fe4",
       "rows": [
        [
         "0",
         "12시 땡!",
         "하루가 또 가네요."
        ],
        [
         "1",
         "1지망 학교 떨어졌어",
         "위로해 드립니다."
        ],
        [
         "2",
         "3박4일 놀러가고 싶다",
         "여행은 언제나 좋죠."
        ],
        [
         "3",
         "3박4일 정도 놀러가고 싶다",
         "여행은 언제나 좋죠."
        ],
        [
         "4",
         "PPL 심하네",
         "눈살이 찌푸려지죠."
        ],
        [
         "5",
         "SD카드 망가졌어",
         "다시 새로 사는 게 마음 편해요."
        ],
        [
         "6",
         "SD카드 안돼",
         "다시 새로 사는 게 마음 편해요."
        ],
        [
         "7",
         "SNS 맞팔 왜 안하지ㅠㅠ",
         "잘 모르고 있을 수도 있어요."
        ],
        [
         "8",
         "SNS 시간낭비인 거 아는데 매일 하는 중",
         "시간을 정하고 해보세요."
        ],
        [
         "9",
         "SNS 시간낭비인데 자꾸 보게됨",
         "시간을 정하고 해보세요."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SD카드 망가졌어</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n",
       "      <td>잘 모르고 있을 수도 있어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Q                   A\n",
       "0                   12시 땡!          하루가 또 가네요.\n",
       "1              1지망 학교 떨어졌어           위로해 드립니다.\n",
       "2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.\n",
       "3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.\n",
       "4                  PPL 심하네          눈살이 찌푸려지죠.\n",
       "5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.\n",
       "6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.\n",
       "7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.\n",
       "8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.\n",
       "9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6273de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Q",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "cccc8613-5a35-41ce-8876-c75a783782ae",
       "rows": [
        [
         "11813",
         "회사에 좋아하는 남자가 생겼어 어떡하지?",
         "사랑하기 힘든 관계인가봐요."
        ],
        [
         "11814",
         "회사에서 어떤 사람이랑 자꾸 눈 마추쳐.",
         "눈 마주치는 게 우연인지 잘 살펴 보세요."
        ],
        [
         "11815",
         "회식 중이라고 하는데 연락이 안돼.",
         "정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요."
        ],
        [
         "11816",
         "회식하는데 나만 챙겨줘. 썸임?",
         "호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요."
        ],
        [
         "11817",
         "후회 없이 사랑하고 싶어",
         "진심으로 다가가 보세요."
        ],
        [
         "11818",
         "훔쳐보는 것도 눈치 보임.",
         "티가 나니까 눈치가 보이는 거죠!"
        ],
        [
         "11819",
         "훔쳐보는 것도 눈치 보임.",
         "훔쳐보는 거 티나나봐요."
        ],
        [
         "11820",
         "흑기사 해주는 짝남.",
         "설렜겠어요."
        ],
        [
         "11821",
         "힘든 연애 좋은 연애라는게 무슨 차이일까?",
         "잘 헤어질 수 있는 사이 여부인 거 같아요."
        ],
        [
         "11822",
         "힘들어서 결혼할까봐",
         "도피성 결혼은 하지 않길 바라요."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11813</th>\n",
       "      <td>회사에 좋아하는 남자가 생겼어 어떡하지?</td>\n",
       "      <td>사랑하기 힘든 관계인가봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11814</th>\n",
       "      <td>회사에서 어떤 사람이랑 자꾸 눈 마추쳐.</td>\n",
       "      <td>눈 마주치는 게 우연인지 잘 살펴 보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11815</th>\n",
       "      <td>회식 중이라고 하는데 연락이 안돼.</td>\n",
       "      <td>정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>회식하는데 나만 챙겨줘. 썸임?</td>\n",
       "      <td>호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11817</th>\n",
       "      <td>후회 없이 사랑하고 싶어</td>\n",
       "      <td>진심으로 다가가 보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                                            A\n",
       "11813   회사에 좋아하는 남자가 생겼어 어떡하지?                              사랑하기 힘든 관계인가봐요.\n",
       "11814   회사에서 어떤 사람이랑 자꾸 눈 마추쳐.                      눈 마주치는 게 우연인지 잘 살펴 보세요.\n",
       "11815      회식 중이라고 하는데 연락이 안돼.  정신 없이 바쁠지도 몰라요. 조금만 더 기다려보고 물어보는게 좋을 것 같아요.\n",
       "11816        회식하는데 나만 챙겨줘. 썸임?          호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.\n",
       "11817            후회 없이 사랑하고 싶어                                진심으로 다가가 보세요.\n",
       "11818           훔쳐보는 것도 눈치 보임.                           티가 나니까 눈치가 보이는 거죠!\n",
       "11819           훔쳐보는 것도 눈치 보임.                                훔쳐보는 거 티나나봐요.\n",
       "11820              흑기사 해주는 짝남.                                       설렜겠어요.\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?                     잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "11822               힘들어서 결혼할까봐                           도피성 결혼은 하지 않길 바라요."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b75b95d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "191059d5-e74a-4d7e-bbc0-fff3d9592961",
       "rows": [
        [
         "Q",
         "0"
        ],
        [
         "A",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "Q    0\n",
       "A    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aad072-2245-41e8-9863-a0b451262fdd",
   "metadata": {},
   "source": [
    "# Dataset, DataLoader 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e0b8d-ee13-488b-ae6e-2a7d4189fd6c",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "### Subword방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67feeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화를 위해서 문장을 q + a 형식으로 만든다. \n",
    "# 어휘사전을 만들 때 Q와 A에 있는 모든 단어들이 다 들어가게 하기 위해.\n",
    "question_texts = df['Q']\n",
    "answer_texts = df['A']\n",
    "\n",
    "all_texts = list(question_texts+\" \"+answer_texts)  # series + 문자열 + series (원소 단위 연산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d1990cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡! 하루가 또 가네요.',\n",
       " '1지망 학교 떨어졌어 위로해 드립니다.',\n",
       " '3박4일 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " '3박4일 정도 놀러가고 싶다 여행은 언제나 좋죠.',\n",
       " 'PPL 심하네 눈살이 찌푸려지죠.',\n",
       " 'SD카드 망가졌어 다시 새로 사는 게 마음 편해요.',\n",
       " 'SD카드 안돼 다시 새로 사는 게 마음 편해요.',\n",
       " 'SNS 맞팔 왜 안하지ㅠㅠ 잘 모르고 있을 수도 있어요.',\n",
       " 'SNS 시간낭비인 거 아는데 매일 하는 중 시간을 정하고 해보세요.',\n",
       " 'SNS 시간낭비인데 자꾸 보게됨 시간을 정하고 해보세요.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d96bf6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    BPE(unk_token=\"<unk>\")\n",
    ")\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=10_000,    # 최대 어휘 수\n",
    "    min_frequency=5,      # 어휘사전에 등록할 단어의 최소 빈도 수 (5회 이상은 나와야 등록)\n",
    "    continuing_subword_prefix='##',    # 연결 subword 앞에 붙일 접두어를 ##로 지정. cowork: co + ##work\n",
    "    special_tokens=[\"<pad>\", \"<unk>\", \"<sos>\"]   # <sos>는 문장의 시작을 의미하는 특수 토큰\n",
    ")\n",
    "tokenizer.train_from_iterator(all_texts, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d70ae898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 어휘 수: 7043\n"
     ]
    }
   ],
   "source": [
    "print(\"총 어휘 수:\", tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3b6d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = tokenizer.encode(\"오늘 날씨가 너무 좋습니다. 이런 날씨에 뭘 하면 좋을까요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0dfbd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오늘', '날씨가', '너무', '좋습니다', '.', '이런', '날씨', '##에', '뭘', '하면', '좋을까요', '?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78448374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2290, 3852, 2258, 5914, 8, 2752, 2841, 1260, 527, 2530, 5533, 20]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b85dffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2530"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_token(1500)  # id로 토큰 문자열 조회\n",
    "tokenizer.token_to_id(\"하면\") # 토큰 문자열로 id (정수)를 조회"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80caf0b3-01d5-4631-87c1-f48ab2f5bafc",
   "metadata": {},
   "source": [
    "### Tokenizer 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a8eea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save(\"saved_models/chatbot_bpe.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d3e5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_tokenizer = Tokenizer.from_file(\"saved_models/chatbot_bpe.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b068c-ead0-4f75-bd01-4a0ebf486774",
   "metadata": {},
   "source": [
    "## Dataset, DataLoader 정의\n",
    "\n",
    "\n",
    "### Dataset 정의 및 생성\n",
    "- 모든 문장의 토큰 수는 동일하게 맞춰준다.\n",
    "    - DataLoader는 batch 를 구성할 때 batch에 포함되는 데이터들의 shape이 같아야 한다. 그래야 하나로 묶을 수 있다.\n",
    "    - 문장의 최대 길이를 정해주고 **최대 길이보다 짧은 문장은 `<PAD>` 토큰을 추가**하고 **최대길이보다 긴 문장은 최대 길이에 맞춰 짤라준다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92338cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"mps\"  # 맥 M1 이상 쓰는 사람들 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6418051",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotDataset(Dataset):\n",
    "\n",
    "    def __init__(self, question_texts, answer_texts, max_length, tokenizer):\n",
    "        # __init__ 함수는 ChatbotDataset 객체를 만들 때 가장 먼저 실행. 필요한 모든 준비물 생성. \n",
    "        \"\"\"\n",
    "        Args:\n",
    "            question_texts (list[str]): 질문 text 리스트. [\"질문1\", \"질문2\", ..]\n",
    "            answer_texts (list[str]): 답변 text 리스트. [\"답변1\", \"답변2\", ...]\n",
    "            max_length (int): 개별 문장의 최대 토큰 수\n",
    "            tokenizer (Tokenzier): 위에서 훈련시킨 토크나이저 도구 (텍스트 -> 숫자 ID 변환)\n",
    "        \"\"\"\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        # \"질문\" -> Tensor(토큰 id)\n",
    "        self.question_texts = [self.__process_sequence(q) for q in question_texts]\n",
    "        self.answer_texts = [self.__process_sequence(a) for a in answer_texts]\n",
    "\n",
    "    def __pad_token_sequence(self, token_sequence):\n",
    "        \"\"\"\n",
    "        token_sequence를 self.max_length 길이에 맞추는 메소드.\n",
    "        max_length보다 적으면 <pad>를 추가, 크면 잘라낸다.\n",
    "        Args:\n",
    "            token_sequence (list[int]): 한 문장의 토큰 id 리스트. [2334, 7100, 257, ..]\n",
    "        Returns:\n",
    "            list[int]: 길이를 max_length에 맞춘 토큰 id 리스트\n",
    "        \"\"\"\n",
    "        pad_token = self.tokenizer.token_to_id('<pad>')\n",
    "        seq_length = len(token_sequence)\n",
    "        if seq_length > self.max_length: #잘라내기\n",
    "            result = token_sequence[:self.max_length]\n",
    "        else: # <pad> 추가 (padding 처리)\n",
    "            result = token_sequence + [pad_token] * (self.max_length - seq_length)\n",
    "    \n",
    "        return result\n",
    "    \n",
    "    def __process_sequence(self, text):\n",
    "        # 텍스트를 숫자로 변환하고 길이 맞추기 \n",
    "        # 하나의 텍스트(str)를 받아서 모델이 이해할 수 있는 숫자 형태의 텐서로 변환하는 메인 처리 과정.\n",
    "        \"\"\"\n",
    "        한 문장(text-str)을 받아서 token화 한 뒤 max_length에 개수를 맞춰서 반환.\n",
    "        max_length에 맞추는 작업은 __pad_token_sequence() 를 이용\n",
    "        Args:\n",
    "            text (str): 토큰화할 문장\n",
    "        Returns:\n",
    "            torch.Tensor[int64]: 토큰화한 토큰 id 리스트\n",
    "        \"\"\"\n",
    "        encode = self.tokenizer.encode(text)\n",
    "        token_ids = encode.ids # \"나는 학생이다.\" -> [4020, 1003, 3932]\n",
    "        # [4020, 1003, 3932] -> [4020, 1003, 3932, 0, 0, 0 ] 패딩 처리.\n",
    "        return torch.tensor(self.__pad_token_sequence(token_ids), dtype=torch.int64)\n",
    "        #torch.tensor(...): 파이토치 모델이 학습할 수 있는 자료형인 텐서(torch.Tensor)로 최종 변환하여 반환\n",
    "\n",
    "    def __len__(self):    # 총 몇 쌍의 질문-답변 데이터가 있는지 반환. \n",
    "        return len(self.question_texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index를 입력 받으면, 해당 위치의 질문과 답변 쌍 반환. \n",
    "        \"\"\"\n",
    "        index의 (question, answer) 쌍을 반환.\n",
    "        Args:\n",
    "            index (int) : 몇번 질문-답변 쌍인지 index\n",
    "        Return:\n",
    "            tuple[Tensor(int64), Tensor(int64)]\n",
    "        \"\"\"\n",
    "        q = self.question_texts[index]\n",
    "        a = self.answer_texts[index]\n",
    "        return q, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801ef2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_length. 가장 긴 문장의 토큰 수 \n",
    "max([len(tokenizer.encode(sent).ids) for sent in question_texts]) # 결과: 21. 제일 긴 토큰 수 21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0fe94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.encode(sent).ids) for sent in answer_texts]) # 결과: 29. 제일 긴 토큰 수 29."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adcf7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 29   # 단순히 함수나 메소드의 입력값 (매개변수)이거나 내부에서만 생성되고 사용되는 지역변수 (local variable)\n",
    "# self.max_length는 인스턴스 변수. 클래스로 만들어진 객체 (메소드)에 영구적으로 소속되는 변수\n",
    "#    - 객체의 모든 메소드 (__init__, __pad_token_sequence, __process_sequence에서 self.접두사를 통해 접근하고 사용 가능.\n",
    "dataset = ChatbotDataset(\n",
    "    list(question_texts),\n",
    "    list(answer_texts),\n",
    "    max_length,\n",
    "    tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d34e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3659c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  10, 1645, 1383,  368,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0]),\n",
       " tensor([6120,  378,   47, 2252,    8,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d2b6f-ccf7-4aec-9c08-176a2456e813",
   "metadata": {},
   "source": [
    "### Trainset / Testset 나누기\n",
    "train : test = 0.95 : 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c8fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11231, 592)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(dataset) * 0.95)\n",
    "test_size = len(dataset) - train_size\n",
    "train_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b45594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataset.Subset, torch.utils.data.dataset.Subset)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_set), type(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a490e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11231, 592)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b274f-8c8a-4aa6-af6d-a66bf5c38210",
   "metadata": {},
   "source": [
    "### DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad8cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a596315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdaf424-c7de-46be-b74b-88a3efcdf352",
   "metadata": {},
   "source": [
    "# 모델 정의\n",
    "\n",
    "## Seq2Seq 모델 정의\n",
    "- Seq2Seq 모델은 Encoder와 Decoder의 입력 Sequence의 길이와 순서가 자유롭기 때문에 챗봇이나 번역에 이상적인 구조다.\n",
    "    - 단일 RNN은 각 timestep 마다 입력과 출력이 있기 때문에 입/출력 sequence의 개수가 같아야 한다.\n",
    "    - 챗봇의 질문/답변이나 번역의 대상/결과 문장의 경우는 사용하는 어절 수가 다른 경우가 많기 때문에 단일 RNN 모델은 좋은 성능을 내기 어렵다.\n",
    "    - Seq2Seq는 **입력처리(질문,번역대상)처리 RNN과 출력 처리(답변, 번역결과) RNN 이 각각 만들고 그 둘을 연결한 형태로 길이가 다르더라도 상관없다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d7410-a73e-4be1-b41d-9ea07d6b0911",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "Encoder는 하나의 Vector를 생성하며 그 Vector는 **입력 문장의 의미**를 N 차원 공간 저장하고 있다. 이 Vector를 **Context Vector** 라고 한다.    \n",
    "![encoder](figures/seq2seq_encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8e8f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.3751, -0.5268, -0.1819,  1.7952, -0.6563],\n",
       "        [ 0.3008, -0.8662, -0.3099, -0.9598, -0.2278],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.9915, -0.0244, -0.6340, -2.4864,  0.2138],\n",
       "        [ 0.2982, -0.9788, -0.3059, -0.5149,  0.7750],\n",
       "        [-0.8230,  0.0431, -0.6844, -0.5528, -0.8285],\n",
       "        [ 0.0696, -0.0222, -0.4396,  0.1937,  0.6414],\n",
       "        [-1.2851,  0.5748, -0.8906,  1.8530,  0.8418],\n",
       "        [ 0.4609,  0.5353, -0.7965,  0.3555,  0.0384],\n",
       "        [-0.9223, -1.8108, -0.7850,  0.8259, -2.2753],\n",
       "        [-0.2735,  0.4747, -0.5025, -0.2595,  1.3061],\n",
       "        [ 0.2806, -1.3418,  0.0204,  0.3421,  1.8096],\n",
       "        [ 0.0584,  0.1531,  0.1285, -0.0605, -0.5910],\n",
       "        [-0.6032,  0.6141,  0.7549, -1.1722,  0.4523],\n",
       "        [ 0.0058, -0.8617,  0.0254, -1.6709, -0.1087],\n",
       "        [-0.8339, -1.0143, -0.3793, -0.9381, -0.1466],\n",
       "        [-1.1543,  0.3183,  0.4321, -0.7659,  0.7734],\n",
       "        [ 0.0482, -1.1790,  1.0443,  2.4028, -0.4019],\n",
       "        [-1.1197, -1.2267, -0.9394,  0.3304,  0.0963],\n",
       "        [-2.8458,  0.3732, -0.9828,  1.2236, -1.0613],\n",
       "        [-1.8833,  0.1172,  1.0531,  0.3139, -0.5170],\n",
       "        [-0.0846,  1.3587,  0.9522,  1.2422, -0.9507],\n",
       "        [ 0.8825,  0.3458, -0.2074,  0.1558, -1.1815],\n",
       "        [ 0.6958,  1.1646, -0.7211, -0.3611, -1.3272],\n",
       "        [ 0.3318,  0.1272, -1.6305,  1.1150,  0.4222],\n",
       "        [-2.4149,  1.5345,  1.0310,  1.2059, -0.0670],\n",
       "        [ 1.1839,  0.5628, -0.9981, -1.6479, -0.2400],\n",
       "        [-1.6546,  0.9386,  0.3437, -0.4489,  0.0198],\n",
       "        [-0.5557,  0.3247,  0.2497, -1.2982,  1.4725],\n",
       "        [ 0.2298, -0.7884, -0.2004, -0.1847,  1.4606],\n",
       "        [ 0.2408,  1.4343, -1.0844,  0.5732, -1.3170],\n",
       "        [ 0.6109, -2.7516,  0.9101,  0.7301, -0.3621],\n",
       "        [ 0.0514,  0.1545, -0.0771,  0.4838,  0.3693],\n",
       "        [ 0.7298,  0.1005, -0.9554,  1.7675,  1.4634],\n",
       "        [ 0.4451,  1.3555,  1.3045, -1.3225,  1.2391],\n",
       "        [-0.8695,  0.3072, -1.0412,  1.0129, -0.9348],\n",
       "        [-1.1000, -0.9753, -1.3627,  0.6277, -0.2107],\n",
       "        [-0.8278, -0.0281,  1.3047, -0.0321, -1.2631],\n",
       "        [-0.0561, -0.7581,  0.3804, -0.2772, -0.3774],\n",
       "        [ 1.5465, -0.5188,  0.8162,  0.0086, -0.9844],\n",
       "        [ 0.3894,  1.3963,  2.7751,  0.0373, -1.1392],\n",
       "        [-0.2826, -1.0690, -0.7604,  0.1730, -1.9677],\n",
       "        [ 1.2636,  0.9460,  0.3028, -0.7445,  1.8907],\n",
       "        [ 1.3270, -0.1035, -1.8492,  0.7740, -1.6451],\n",
       "        [-0.1722,  0.7549,  0.9981, -2.0693,  0.5448],\n",
       "        [-0.7822,  1.2171, -0.0820,  0.7723, -1.0135],\n",
       "        [-0.3461,  0.5558, -0.6467, -0.8885, -1.7671],\n",
       "        [ 1.3936,  0.2033, -0.9524,  0.3699,  1.8164],\n",
       "        [ 0.6614,  0.4112, -0.8467,  0.3793,  1.6253],\n",
       "        [ 2.6682, -1.3010, -0.5457, -0.8889,  0.6708],\n",
       "        [-1.4088,  0.2006,  0.3049,  2.6301,  1.3358],\n",
       "        [-0.8790,  1.7159, -0.3638,  1.7877,  1.1960],\n",
       "        [-0.5467,  1.1926,  1.8805,  0.4044,  0.0131],\n",
       "        [-0.9956,  0.6367, -0.9679, -0.3942,  0.7754],\n",
       "        [ 0.2528, -0.0772,  0.5037, -2.3263, -0.5049],\n",
       "        [-1.3585, -0.2143,  0.9182,  1.1989, -0.4899],\n",
       "        [-0.3142,  0.7392, -0.3030, -0.7301,  0.8564],\n",
       "        [-1.8108, -1.8809,  0.4223, -1.3597, -0.3607],\n",
       "        [ 0.4298, -0.3552, -1.9970,  0.2148,  1.1159],\n",
       "        [ 0.9736, -0.5761,  1.3400,  1.3648, -0.1613],\n",
       "        [ 1.2342,  1.5910, -0.4049,  0.3533,  1.6694],\n",
       "        [-0.4272, -0.2141,  0.1784,  1.5867, -1.0617],\n",
       "        [-0.5406, -0.5718, -1.6230, -0.5803,  0.2330],\n",
       "        [-0.1776, -0.5071, -0.1288, -0.4730,  1.9029],\n",
       "        [-0.1082,  1.1041,  1.4855,  2.0045,  0.1842],\n",
       "        [-0.2927, -0.1449,  1.5462,  1.9570,  0.5075],\n",
       "        [ 0.7170, -0.3653, -0.2721,  0.0832, -0.1702],\n",
       "        [ 0.8036,  0.2307,  0.1464, -1.5858, -0.8277],\n",
       "        [-2.3998, -2.0264,  0.4357,  2.4370, -1.5156],\n",
       "        [-0.0711,  0.9643,  0.5201,  1.0210,  1.7294],\n",
       "        [ 0.1896, -0.1535, -1.2067,  1.3784, -1.1966],\n",
       "        [-0.3512,  0.2548,  1.6515,  0.8453, -0.9757],\n",
       "        [-1.4680,  0.1650,  0.0257,  0.3870, -0.6000],\n",
       "        [ 0.5266,  0.0777,  1.5858, -0.3850,  1.6585],\n",
       "        [ 0.2093,  0.3133, -0.5486, -0.2790,  0.6204],\n",
       "        [ 0.9658,  0.3256,  2.2448,  0.2133, -1.2046],\n",
       "        [ 0.2416, -0.5058, -0.2347, -2.2226, -2.1876],\n",
       "        [-0.0592, -1.7028,  0.2431, -0.2027, -0.3092],\n",
       "        [ 0.8919,  0.9037, -1.2351,  0.4719, -0.8385],\n",
       "        [-0.4184,  0.7430, -1.2282,  0.6842,  0.8240],\n",
       "        [-0.3288,  0.4360, -0.1491,  0.8995, -0.4565],\n",
       "        [ 0.1187, -0.3851, -0.4621, -0.2013, -0.0408],\n",
       "        [ 1.0328, -0.0374, -1.4919, -1.5082, -0.8221],\n",
       "        [-1.3532, -0.3498, -1.7152,  1.3304,  1.0831],\n",
       "        [-1.0809,  0.9309,  0.2122, -0.8923, -2.0931],\n",
       "        [-1.0155,  1.1447, -0.3869,  1.6327,  0.6010],\n",
       "        [ 0.8527,  2.5488,  0.0308, -0.1473, -1.4562],\n",
       "        [-1.5202,  1.2403, -0.4178,  0.4020,  0.2469],\n",
       "        [-2.2366, -0.0061, -0.3384, -0.0455,  0.7995],\n",
       "        [-1.5789,  0.0617, -0.0354,  0.4111,  0.5073],\n",
       "        [-1.4482, -0.9123, -0.6100,  0.6652,  2.3502],\n",
       "        [ 0.0402, -2.2307, -0.6934,  1.4346,  0.5794],\n",
       "        [-0.3151, -1.3509,  0.2016, -2.1625,  1.2827],\n",
       "        [-0.6749,  0.2510, -0.7505,  0.3835, -0.6122],\n",
       "        [-0.4588,  1.1043, -1.3517, -0.5711,  0.7469],\n",
       "        [-2.2203, -0.7923, -0.9866, -0.3290, -1.1840],\n",
       "        [ 0.3146, -0.0583,  0.7472, -0.1253, -1.6858],\n",
       "        [-0.1256,  0.6599, -0.7238, -1.8295, -0.1775],\n",
       "        [-1.0716,  0.4437,  0.2732,  2.0537, -0.1641],\n",
       "        [ 0.0973, -1.3974, -2.0907, -0.0410, -0.0851]], requires_grad=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.Embedding(100, 5, padding_idx=2)\n",
    "a.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477135dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size: int,   # 총 어휘 수\n",
    "            embedding_dim: int,   # Embedding Vector의 차원\n",
    "            hidden_size: int, # GRU의 hidden 개수\n",
    "            bidirectional: bool = True,   # GRU의 양방향 여부\n",
    "            num_layers: int = 1,   # GRU의 layer stack 수 \n",
    "            dropout: float = 0.2   # dropout의 비율\n",
    "        ):\n",
    "            super().__init__()\n",
    "            self.vocab_size = vocab_size\n",
    "            # X -> (Embedding Model) -> (GRU) -> Context Vector -> (Decoder)\n",
    "            # Encoder의 목적은 (질문의) Context Vector를 추출하는 것이 목적. \n",
    "            self.embedding = nn.Embedding(\n",
    "                 vocab_size, \n",
    "                 embedding_dim,  # (vocab_size X embedding_dim)\n",
    "                 padding_idx=0\n",
    "            )\n",
    "\n",
    "            self.gru = nn.GRU(\n",
    "                 input_size=embedding_dim,\n",
    "                 hidden_size=hidden_size,\n",
    "                 num_layers=num_layers,\n",
    "                 bidirectional=bidirectional,\n",
    "                 dropout=dropout if num_layers > 1 else 0.0\n",
    "            )\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X.shape [batch, seq_length]\n",
    "        embedding_vector = self.embedding(X)  # [batch, seq_length]\n",
    "        embedding_vector = embedding_vector.transpose(1, 0) # [seq_length, batch, emb_dim]\n",
    "        out, hidden = self.gru(embedding_vector)  \n",
    "        # out: 모든 time step의 hidden_state, hidden: 마지막 time step의 hidden_state\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85d3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 761, 2436,  547, 1321, 2258,  752, 2712,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf51c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 3, 9,  ..., 4, 4, 1],\n",
       "        [0, 7, 6,  ..., 3, 4, 3],\n",
       "        [8, 7, 4,  ..., 0, 2, 6],\n",
       "        ...,\n",
       "        [2, 0, 5,  ..., 0, 2, 5],\n",
       "        [5, 1, 4,  ..., 9, 8, 0],\n",
       "        [8, 2, 0,  ..., 4, 2, 3]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "dummy_input = torch.randint(10, size=(64, 20), dtype=torch.int64)\n",
    "dummy_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6f13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Encoder                                  [20, 64, 40]              --\n",
       "├─Embedding: 1-1                         [64, 20, 100]             100,000\n",
       "├─GRU: 1-2                               [20, 64, 40]              14,640\n",
       "==========================================================================================\n",
       "Total params: 114,640\n",
       "Trainable params: 114,640\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 25.14\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.43\n",
       "Params size (MB): 0.46\n",
       "Estimated Total Size (MB): 1.90\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(Encoder(1000, 100, 20), input_data=dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8344f-8cf7-45a8-8092-ab20365cdb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24779603-15ac-4ba1-a24c-6e86658b3ad6",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "- Encoder의 출력(context vector)를 받아서 번역 결과 sequence를 출력한다.\n",
    "- Decoder는 매 time step의 입력으로 **이전 time step에서 예상한 단어와 hidden state값이** 입력된다.\n",
    "- Decoder의 처리결과 hidden state를 Estimator(Linear+Softmax)로 입력하여 **입력 단어에 대한 번역 단어가 출력된다.** (이 출력단어가 다음 step의 입력이 된다.)\n",
    "    - Decoder의 첫 time step 입력은 문장의 시작을 의미하는 <SOS>(start of string) 토큰이고 hidden state는 context vector(encoder 마지막 hidden state) 이다.\n",
    "\n",
    "![decoder](figures/seq2seq_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c842666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b3ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=1, bidirectional=False, # Decoder는 생성. 뒤에 토큰들을 알지 못하기 때문에 단방향 처리. \n",
    "                          dropout=0.2\n",
    "                         ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            embedding_dim, \n",
    "            hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            dropout= dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(\n",
    "            hidden_size,   # 입력 - gru의 마지막 hidden state값.\n",
    "            vocab_size     # 출력 - 다중분류: 어휘사전의 단어들 중 다음 단어 한 개를 찾는 다중분류.\n",
    "        )\n",
    "        \n",
    "    def forward(self, X, hidden):\n",
    "        \"\"\"\n",
    "        X: 한 개 토큰. shape: [batch] []\n",
    "        hidden: 이전 처리 hidden state. 첫 번째 time step: Encoder의 context vector\n",
    "                [seq_length: 1, batch, hidden_size]\n",
    "        \"\"\"\n",
    "        # [batch] -> [batch, 1] 1: seq_length\n",
    "        X = X.unsqueeze(1)\n",
    "        embedding_vector = self.embedding(X)   # 입력: int64, [batch, seq_length(1)]\n",
    "        # [batch, seq_length, embedding_dim] -> [seq_length, batch, embedding_dim]\n",
    "        embedding_vector = embedding_vector.transpose(1, 0)\n",
    "\n",
    "        #[seq_length(1), batch, embedding_dim -> out, hidden\n",
    "        # out (모든 time step의 hidden state 모음): [seq_length(1), batch_size, hidden_size]\n",
    "        # hidden (마지막 time step의 hidden state): [num_layers, batch_size, hidden_size]\n",
    "        out, hidden = self.gru(embedding_vector)\n",
    "\n",
    "        # Linear (분류기) 넣어서 다음 단어를 예측\n",
    "        last_out = self.classifier(out[-1])\n",
    "\n",
    "        # last_out: 다음 단어일 확률, [batch, vocab_size]\n",
    "        # hidden: 다음 단어를 예측할 때 넣어줄 context vector (hidden state)\n",
    "        return last_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07570b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e9182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Decoder                                  [64, 10000]               --\n",
       "├─Embedding: 1-1                         [64, 1, 200]              2,000,000\n",
       "├─GRU: 1-2                               [1, 64, 256]              351,744\n",
       "├─Linear: 1-3                            [64, 10000]               2,570,000\n",
       "==========================================================================================\n",
       "Total params: 4,921,744\n",
       "Trainable params: 4,921,744\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 314.99\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 5.35\n",
       "Params size (MB): 19.69\n",
       "Estimated Total Size (MB): 25.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.ones([64], dtype=torch.int64)   # 64: batch\n",
    "dummy_hidden = torch.ones((1, 64, 200), dtype=torch.float32)\n",
    "# hidden shape: [1-gru layer 개수, 64: batch, 200: hidden_size]\n",
    "# gru layer 개수: num_layers * 2 if bidirectional else 1\n",
    "\n",
    "dummy_decoder = Decoder(10000, 200, 256, num_layers=1)\n",
    "summary(dummy_decoder, input_data=(dummy_input, dummy_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word, hidden = dummy_decoder(dummy_input, dummy_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d95199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10000])\n",
      "torch.Size([1, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "print(next_word.shape)\n",
    "print(hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdf137-057b-4e41-95cd-c58219032b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274,\n",
       "        7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274,\n",
       "        7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274,\n",
       "        7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274,\n",
       "        7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274, 7274,\n",
       "        7274, 7274, 7274, 7274])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word.max(dim=-1).indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3563f5b2-f18b-42b5-9bd4-f4f8abd767ac",
   "metadata": {},
   "source": [
    "## Seq2Seq 모델\n",
    "\n",
    "- Encoder - Decoder 를 Layer로 가지며 Encoder로 질문의 feature를 추출하고 Decoder로 답변을 생성.\n",
    "\n",
    "### Teacher Forcing\n",
    "- **Teacher forcing** 기법은, RNN계열 모델이 다음 단어를 예측할 때, 이전 timestep에서 예측된 단어를 입력으로 사용하는 대신 **실제 정답 단어(ground truth) 단어를** 입력으로 사용하는 방법.\n",
    "    - 모델은 이전 시점의 출력 단어를 다음 시점의 입력으로 사용한다. 그러나 모델이 학습할 때 초반에는 정답과 많이 다른 단어가 생성되어 엉뚱한 입력이 들어가 학습이 빠르게 되지 않는 문제가 있다.\n",
    "- **장점**\n",
    "    - **수렴 속도 증가**: 정답 단어를 사용하기 때문에 모델이 더 빨리 학습 가능.\n",
    "    - **안정적인 학습**: 초기 학습 단계에서 모델의 예측이 불안정할 때, 잘못된 예측으로 인한 오류가 다음 단계로 전파되는 것을 막아줍니다.\n",
    "- **단점**\n",
    "    - **노출 편향(Exposure Bias) 문제:** 실제 예측 시에는 정답을 제공할 수 없으므로 모델은 전단계의 출력값을 기반으로 예측해 나가야 한다. 학습 과정과 추론과정의 이러한 차이 때문에 모델의 성능이 떨어질 수있다.\n",
    "        - 이런 문제를 해결하기 학습 할 때 **Teacher forcing을 random하게 적용하여 학습시킨다.**\n",
    "![seq2seq](figures/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acaa23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SOS_TOKEN = tokenizer.token_to_id(\"<sos>\")\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super.__init__()\n",
    "        self.encoder = encoder.to(device)\n",
    "        self.decoder = decoder.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, inputs, outputs, teacher_forcing_rate=0.99):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            inputs: 질문 (batch, seq_length)\n",
    "            outputs: 답변(정답) (batch, seq_length) -> teacher forcing 때 사용.\n",
    "            teacher_forcing_rate: teacher forcing은 random하게 적용. 적용될 확률. \n",
    "        \"\"\"\n",
    "        # 질문과 답변이 1차원일 경우 2차원으로 reshape\n",
    "        # if [batch] -> [batch(1), seq_length]\n",
    "        if inputs.dim() ==1:\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "        if outputs.dim() == 1:\n",
    "            outputs = outputs.unsqueeze(0)\n",
    "\n",
    "        batch_size, output_length = outputs.shape   # output_length: output의 max_length. 답변 문장의 토큰 수를 여기에 맞출 것. \n",
    "        output_vocab_size = self.encoder.vocab_size\n",
    "\n",
    "\n",
    "        ##############################################################\n",
    "        # 생성된 문장을 저장할 tensor 생성 (모델이 생성한 예측 문장)\n",
    "        # (seq_length, batch_size, vocab_size)\n",
    "        # [나는, 학생, 이다.]\n",
    "        # [\n",
    "        # vocab_size의 각 단어가 \"나는\"일 확률\n",
    "        # vocab_size의 각 단어가 \"학생\"일 확률\n",
    "        # vocab_size의 각 단어가 \"이다\"일 확률\n",
    "        # ]\n",
    "        ##################################\n",
    "\n",
    "        predicted_outputs = torch.zeros(output_length, batch_size, output_vocab_size).to(self.device)\n",
    "\n",
    "        ##############################################################\n",
    "        # 추론\n",
    "        # 1. encoder를 이용해서 context vector 추출 (한번에 처리)\n",
    "        # 2. decoder를 이용해서 답변 문장을 생성 (개별 토큰 별로 생성) 반복.\n",
    "        ##############################################################\n",
    "        # encode를 이용해 context vector 추출\n",
    "        \n",
    "        encoder_out, _ = self.encoder(inputs)   # encoder_out: 전체 hidden state 모음\n",
    "\n",
    "        # context vector == encoder_out[-1] => Decoder의 첫 번째 time step의 hidden으로 입력.\n",
    "        decoder_hidden = encoder_out[-1].unsqueeze(0)\n",
    "        # decoder에 입력할 첫 번째 time step값: <sos> 토큰 ID\n",
    "        decoder_input = torch.full([batch_size], fill_value=SOS_TOKEN, device=self.device)\n",
    "\n",
    "        ####################################\n",
    "        # Decoder를 이용해서 한 단어 (토큰)씩 생성\n",
    "        ####################################\n",
    "        for t in range(output_length):\n",
    "            decoder_out, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "            predicted_outputs = decoder_out  # t번째 예측 단어.\n",
    "\n",
    "            # 다음 time step의 input을 생성 (decoder_input 값을 생성)\n",
    "            # teacher forcing 적용 -> t번째 정답 토큰 \n",
    "            #                 적용 안 함 -> Decoder가 생성한 decoder_out에서 token id값.\n",
    "            # teacher_forcing_rate 비율로 teacher forcing을 적용\n",
    "            teacher_forcing = teacher_forcing_rate > random.random()\n",
    "            teacher_forcing_rate *= 0.99  # 반복하면서 teacher forcing 적용 확률을 줄여나간다. \n",
    "\n",
    "            top1 = decoder_out.argmax(dim=-1)     # 다음 단어일 확률이 가장 높은 단어의 토큰 ID\n",
    "            decoder_input = outputs[:, t] if teacher_forcing else top1\n",
    "\n",
    "\n",
    "        return predicted_outputs.transpose(1, 0)   # [seq_length <-> batch, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e3ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 29)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.encode(\"안녕하세요. 반가워요.\").ids\n",
    "# b, o = [64, 29]\n",
    "# b, o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56953ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = torch.tensor([[1, 2], [3, 4]])\n",
    "# a.shape\n",
    "# a[-1].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c178a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.random()  # 0~1 사이의 실수 반환. 모든 실수는 같은 확률로 나온다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89fed5-b059-4371-b836-c3eb59bebdfb",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac7b8a-935e-4f3a-9fa5-efbacbfc19d7",
   "metadata": {},
   "source": [
    "## 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter 정의\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "encoder_bidirectional = True  # encoder는 양방향\n",
    "encoder_hidden_size = 200\n",
    "\n",
    "# encoder의 hidden(context vector)과 decoder hidden을 맞춰준다.\n",
    "decoder_hidden_size = encoder_hidden_size * 2 if encoder_bidirectional else encoder_hidden_size\n",
    "\n",
    "embedding_dim = 256\n",
    "teacher_forcing_rate = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce8d66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hidden_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 모델 생성 \u001b[39;00m\n\u001b[32m      2\u001b[39m encoder = Encoder(\n\u001b[32m      3\u001b[39m     vocab_size = vocab_size,\n\u001b[32m      4\u001b[39m     embedding_dim = embedding_dim,\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     hidden_size = \u001b[43mhidden_size\u001b[49m,\n\u001b[32m      6\u001b[39m     num_layers = \u001b[32m1\u001b[39m,\n\u001b[32m      7\u001b[39m     bidirectional=encoder_bidirectional\n\u001b[32m      8\u001b[39m )\n\u001b[32m      9\u001b[39m decoder = Decoder(\n\u001b[32m     10\u001b[39m     vocab_size = vocab_size,\n\u001b[32m     11\u001b[39m     embedding_dim = embedding_dim,\n\u001b[32m     12\u001b[39m     hidden_size = decoder_hidden_size,\n\u001b[32m     13\u001b[39m     num_layers = \u001b[32m1\u001b[39m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m seq2seq = Seq2Seq(encoder, decoder, device)\n",
      "\u001b[31mNameError\u001b[39m: name 'hidden_size' is not defined"
     ]
    }
   ],
   "source": [
    "# 모델 생성 \n",
    "encoder = Encoder(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim = embedding_dim,\n",
    "    hidden_size = hidden_size,\n",
    "    num_layers = 1,\n",
    "    bidirectional=encoder_bidirectional\n",
    ")\n",
    "decoder = Decoder(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim = embedding_dim,\n",
    "    hidden_size = decoder_hidden_size,\n",
    "    num_layers = 1\n",
    ")\n",
    "seq2seq = Seq2Seq(encoder, decoder, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_input = torch.zeros((64, 30), dtype=torch.int64)\n",
    "\n",
    "summary(seq2seq, input_data=(d_input, d_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba83263-e042-4579-9784-2403eb3c3fa1",
   "metadata": {},
   "source": [
    "## loss함수, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8000c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "model = seq2seq(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a659df1-87a2-4fe0-a095-e031ed130e68",
   "metadata": {},
   "source": [
    "## train/evaluation 함수 정의\n",
    "\n",
    "### train 함수정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d12a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_fn, device, teacher_forcing_rate=0.9):\n",
    "    model.train()\n",
    "    train_loss=0.0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X, y, teacher_forcing_rate)  # seq2seq\n",
    "        # pred: [batch, seq_length, vocab_size]\n",
    "        # pred: [batch, seq_length, vocab_size]\n",
    "        y_hat = pred.reshape(-1, pred.shape[2])  # loss 계산을 위해서\n",
    "        y = y.reshape(-1)   # [batch, seq_length] -> [batch * seq_length]\n",
    "        # CrossEntropyLoss입력: 정답 - [batch,], 추론: [batch, class 개수 - vocab_size]\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        loss.backward()   # gradient 계산.\n",
    "        optimizer.step()  # update\n",
    "        optimizer.sero_grad()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    return train_loss / len (dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981388d-ad33-4318-844b-29a5a434d2a7",
   "metadata": {},
   "source": [
    "### Test 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model (X, y, teacher_forcing_rate=0.0)  # teacher_forcing 적용하면 안 됨\n",
    "        y_hat = pred.reshape(-1, pred.shape[-1])\n",
    "        y = y.reshape(-1)\n",
    "        eval_loss += loss_fn(y_hat, y).item()\n",
    "\n",
    "    return eval_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71e20c-8a03-44f4-bbbc-8f4e51b85636",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model_save_path = \"saved_models/chatbot_seq2seq.pth\"\n",
    "# 가장 validation loss가 좋은 모델을 저장.\n",
    "best_loss = torch.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, loss_fn, device, teacher_forcing_rate)\n",
    "    eval_loss = eval(model, test_loader, loss_fn, device)\n",
    "\n",
    "    if best_loss > eval_loss:  # 성능 개선\n",
    "        torch.save(model, model_save_path)\n",
    "        print(epoch+1, \"에서 저장 -------------\")\n",
    "        best_loss = eval_loss\n",
    "\n",
    "    print(epoch+1, train_loss, eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627557f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5280dca7-029c-4eb6-b079-39963d7b7932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fe0585a-eb35-47dd-88bf-276d749f5f00",
   "metadata": {},
   "source": [
    "# 결과확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b94a1-bc0a-474a-8415-57dc5ea4b894",
   "metadata": {},
   "source": [
    "- Sampler:\n",
    "    -  DataLoader가 Datatset의 값들을 읽어서 batch를 만들때 index 순서를 정해주는 객체.\n",
    "    -  DataLoader의 기본 sampler는 SequentialSampler 이다. shuffle=True 일경우 RandomSampler: 랜덤한 순서로 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6bedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0822c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476eae22-4c6a-4f55-8dd2-87f8dd1ba46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c4965d1-a305-4465-8f64-f689d55490ac",
   "metadata": {},
   "source": [
    "# 학습모델을 이용한 대화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5dea07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313038f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c89f81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
