{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63189da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/11(목) 11:08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06541a-3111-46cb-a3be-4b50d8267e1a",
   "metadata": {},
   "source": [
    "# Transformers AutoClass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d4825a-fe9f-4d1e-b9e0-7bb78745b840",
   "metadata": {},
   "source": [
    "### Tokenizer, Model Loading\n",
    "- Huggingface 모델 허브에서 제공하는 처리 모델을 다운받아 로딩.\n",
    "- 다운로드된 모델은 `사용자 home 디렉토리\\.cache\\huggingface` 에 저장.\n",
    "- 미리 학습된 언어 모델을 다운받아 사용할 때는 그 언어모델이 사용한 tokenizer를 같이 받아서 사용.\n",
    "\n",
    "### [Auto Classes](https://huggingface.co/docs/transformers/model_doc/auto)\n",
    "- Huggingface 에서 제공하는 다양한 모델들은 손쉽게 불러오고 사용할 수 있도록 설계된 유틸리티 클래스들을 말한다.\n",
    "- 미리 학습된 특정 모델의 이름(모델 허브상에서 제공되는 이름)이나 저장된 local 경로를 제공하면 해당 모델에 맞는 적절한 클래스와 구성 요소를 자동으로 로드한다.\n",
    "- 사용자는 모델을 사용하기 위한 정확한 클래스를 몰라도 쉽게 다양한 종류의 모델을 사용할 수있다.\n",
    "\n",
    "#### 주요 Auto Class\n",
    "- 기본 모델 Loading\n",
    "    1. **AutoModel**\n",
    "       - 주어진 모델 이름에 맞는 사전 학습된 모델 자동으로 로드.\n",
    "       - 예: `AutoModel.from_pretrained(\"bert-base-uncased\")`: BERT 모델 로드.\n",
    "    2. **AutoTokenizer**\n",
    "       - 해당 모델에 적합한 토크나이저를 자동으로 로드.\n",
    "       - 예: `AutoTokenizer.from_pretrained(\"bert-base-uncased\")`: BERT 모델에 맞는 토크나이저를 로드.\n",
    "    3. **AutoConfig**\n",
    "       - 모델의 설정(config)을 자동으로 로드. 모델 설정에는 모델의 하이퍼파라미터와 모델 구조 정보가 포함된다. 이 설정을 이용해 모델 생성할 수있다.\n",
    "       - 예: `AutoConfig.from_pretrained(\"bert-base-uncased\")`\n",
    "- Task 처리 모델 Loading\n",
    "    - Pretrained backbone 모델에 각 task 에 맞는 estimator layer를 추가한 모델 생성해 제공.\n",
    "    - 주요 모델들\n",
    "        1. **AutoModelForSequenceClassification**\n",
    "           - 시퀀스(Text) 분류 작업을 위한 모델 자동으로 로드.\n",
    "           - 예: `AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")`\n",
    "        2. **AutoModelForQuestionAnswering**\n",
    "           - 질문-응답 작업을 위한 모델 자동으로 로드.\n",
    "           - 예: `AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")`\n",
    "        3. **AutoModelForTokenClassification**\n",
    "           - 토큰 분류 작업(예: 개체명 인식)을 위한 모델 자동으로 로드.\n",
    "           - 예: `AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "712789f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>\n",
      "<class 'transformers.models.bert.modeling_bert.BertModel'>\n",
      "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "\n",
    "model_id = \"bert-base-uncased\"\n",
    "# model_id = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "print(type(tokenizer))\n",
    "\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "print(type(model))\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "print(type(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b629b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert.modeling_bert.BertModel"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config.json - 모델 아키텍쳐 관련 메타정보파일\n",
    "# config\n",
    "model2 = AutoModel.from_config(config) # 학습이 안 된 모델\n",
    "type(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e268665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "b_model = BertModel.from_pretrained(model_id)\n",
    "b_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dbbd01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# raw-text -> (Tokenizer) ==> token ids ==> (model) ==> 결과 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcbcde2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 2572, 1037, 2879, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer\n",
    "raw_text = \"I am a boy.\"\n",
    "\n",
    "# 토큰화\n",
    "token = tokenizer(raw_text)\n",
    "\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f711e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token (결과)의 key들 조회\n",
    "dict(token).keys()\n",
    "# 결과: input_ids': 입력 토큰 id값. \n",
    "# 'token_type_ids': 입력이 문장 쌍일 때 문장을 구분하는 id. 0: 첫 번째 문장, 1: 두 번째 문장. \n",
    "#                   각 토큰이 어느 문장에 속했는지 토큰 별로 지정됨. \n",
    "#                   문장 쌍: QA(질문-지문)\n",
    "# 'attention_mask': 실제 문장이 토큰과 Padding을 구분한다. 토큰 위치 별로 지정. 0: padding, 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d37d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1045, 2572, 1037, 2879, 1012, 102]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abacc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a995c53",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m###################### \u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# token 결과 -> model\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# keyword 가변 인자에 맞춰서 name = value 형태로 입력. input_ids=[.....],\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# model에 맞춤 타입으로 입력. (pytorch 모델: torch.tensor)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m context_vector = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# BertModel -> feature extract\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/09_Huggingface_transformers/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/09_Huggingface_transformers/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SKN21_mjy/09_Huggingface_transformers/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:911\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    909\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    910\u001b[39m     \u001b[38;5;28mself\u001b[39m.warn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[32m--> \u001b[39m\u001b[32m911\u001b[39m     input_shape = \u001b[43minput_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m()\n\u001b[32m    912\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    913\u001b[39m     input_shape = inputs_embeds.size()[:-\u001b[32m1\u001b[39m]\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "###################### \n",
    "# token 결과 -> model\n",
    "\n",
    "# keyword 가변 인자에 맞춰서 name = value 형태로 입력. input_ids=[.....],\n",
    "# model에 맞춤 타입으로 입력. (pytorch 모델: torch.tensor)\n",
    "context_vector = model(**token) # BertModel -> feature extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vector.last_hidden_state.shape\n",
    "# 모든 입력 토큰들의 hidden state들\n",
    "# [batch:1, seq_len: 7, hidden_size(embedding vector): 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c54182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 문장 (문서)에 대한 context vector - 문장(문서)의 특성값. \n",
    "## Bert는 last_hidden_state에서 첫 번째 토큰 값을 가공(특성 추출)해서 context vector로 사용.\n",
    "token['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d1323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5a02d44-7271-4db4-b8c0-7c14037dce3a",
   "metadata": {},
   "source": [
    "## kcbert\n",
    "- BERT 모델을 한글 텍스트로 학습 시킨 Pretrained model.\n",
    "    - BERT는 Transformer의 Encoder 부분을 이용해 구현된 언어모델\n",
    "    - https://arxiv.org/abs/1810.04805 \n",
    "- https://huggingface.co/beomi/kcbert-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0af872e-410e-4a3c-8ec3-2b1e1a680ad6",
   "metadata": {},
   "source": [
    "### 토크나이저, 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ed8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_id = \"beomi/kcbert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6763b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf5087a1-04bb-4b36-912f-c1c5bdd77101",
   "metadata": {},
   "source": [
    "### 입력값 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78342de-1a9c-4b70-a997-c7bca15432ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"안녕\",\n",
    "    \"Hugging Face는 인공지능(AI)과 자연어 처리(NLP) 분야에서 혁신적인 도구와 모델을 제공하는 AI 스타트업이다.\",\n",
    "    \"2016년에 설립된 이 회사는 주로 오픈소스 라이브러리와 사전 학습된 NLP 모델을 제공을 제공한다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8539917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99565463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19acd0fe-5952-4ee6-97ee-e4fcf41ec093",
   "metadata": {},
   "source": [
    "### BERT 모델을 이용해 context vector 추출\n",
    "#### Model 추론결과\n",
    "- **last_hidden_state**\n",
    "    - 모든 token들에 대한 feature\n",
    "    - 출력이 **many**인 작업에 사용한다.\n",
    "- **pooler_output**\n",
    "    - 입력 문장, 텍스트에 대한 context vector 이다.\n",
    "    - 이 값은 **문장을 입력받아 처리하는 task**(ex: 문서분류-감정분석,문장카테고리분류, 문장유사도 분석)의 입력으로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ce7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787c1df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad062b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
